{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!---\n",
    "Latex Macros\n",
    "-->\n",
    "$$\n",
    "\\newcommand{\\bar}{\\,|\\,}\n",
    "\\newcommand{\\Xs}{\\mathcal{X}}\n",
    "\\newcommand{\\Ys}{\\mathcal{Y}}\n",
    "\\newcommand{\\y}{\\mathbf{y}}\n",
    "\\newcommand{\\weights}{\\mathbf{w}}\n",
    "\\newcommand{\\balpha}{\\boldsymbol{\\alpha}}\n",
    "\\newcommand{\\bbeta}{\\boldsymbol{\\beta}}\n",
    "\\newcommand{\\aligns}{\\mathbf{a}}\n",
    "\\newcommand{\\align}{a}\n",
    "\\newcommand{\\source}{\\mathbf{s}}\n",
    "\\newcommand{\\target}{\\mathbf{t}}\n",
    "\\newcommand{\\ssource}{s}\n",
    "\\newcommand{\\starget}{t}\n",
    "\\newcommand{\\repr}{\\mathbf{f}}\n",
    "\\newcommand{\\repry}{\\mathbf{g}}\n",
    "\\newcommand{\\x}{\\mathbf{x}}\n",
    "\\newcommand{\\prob}{p}\n",
    "\\newcommand{\\vocab}{V}\n",
    "\\newcommand{\\params}{\\boldsymbol{\\theta}}\n",
    "\\newcommand{\\param}{\\theta}\n",
    "\\DeclareMathOperator{\\perplexity}{PP}\n",
    "\\DeclareMathOperator{\\argmax}{argmax}\n",
    "\\DeclareMathOperator{\\argmin}{argmin}\n",
    "\\newcommand{\\train}{\\mathcal{D}}\n",
    "\\newcommand{\\counts}[2]{\\#_{#1}(#2) }\n",
    "\\newcommand{\\length}[1]{\\text{length}(#1) }\n",
    "\\newcommand{\\indi}{\\mathbb{I}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>Setup 1</font>: Load Libraries\n",
    "This cell loads libraries important for evaluation and assessment of your model. **Do not change, move or copy it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-20T12:04:56.249298",
     "start_time": "2016-12-20T12:04:54.376398"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "#! SETUP 1 - DO NOT CHANGE, MOVE NOR COPY\n",
    "import sys, os\n",
    "_snlp_book_dir = \"../../../../../\"\n",
    "sys.path.append(_snlp_book_dir)\n",
    "# docker image contains tensorflow 0.10.0rc0. We will support execution of only that version!\n",
    "import statnlpbook.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import argparse\n",
    "# For report:\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MODEL COMPONENTS\n",
    "class WordEmbedder(object):\n",
    "    def __init__(self, w_size, vocab_size=None):\n",
    "        embed_path = 'embeddings/glove{}.npy'.format(w_size)\n",
    "        if os.path.exists(embed_path):\n",
    "            init_embed = np.load(embed_path).astype(np.float32)\n",
    "            self.vocab_size = init_embed.shape[0]\n",
    "        else:\n",
    "            self.vocab_size = vocab_size\n",
    "            init_embed = tf.zeros([vocab_size, w_size], dtype=np.float32)\n",
    "        with tf.variable_scope(\"WordEmbedder\", reuse=None):\n",
    "            self.embeddings = tf.get_variable('W', initializer=init_embed, trainable=False)\n",
    "\n",
    "    def embed(self, story):\n",
    "        batch_size = get_this_batch_size(story)\n",
    "        sentences = [tf.reshape(x, [batch_size, -1]) for x in\n",
    "                     tf.split(1, 5, story)]  # 5 times [batch_size x max_length]\n",
    "\n",
    "        # [batch_size x max_seq_length x input_size]\n",
    "        words_embedded = [tf.nn.embedding_lookup(self.embeddings, sentence) for sentence in sentences]\n",
    "\n",
    "        return words_embedded\n",
    "\n",
    "    \n",
    "class NonLinearClassifier(object):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        hidden_size = input_size\n",
    "        self.target_size = 5\n",
    "        initializer = tf.contrib.layers.xavier_initializer(uniform=True, seed=None, dtype=tf.float32)\n",
    "        with tf.variable_scope('NonLinear', reuse=None, initializer=initializer):\n",
    "            with tf.variable_scope('Hidden', reuse=None):\n",
    "                self.w0 = tf.get_variable('Weights', [input_size, hidden_size])\n",
    "                self.b0 = tf.get_variable('Biases', [1, hidden_size])\n",
    "            with tf.variable_scope('Output', reuse=None):\n",
    "                self.w1 = tf.get_variable('Weights', [hidden_size, output_size])\n",
    "                self.b1 = tf.get_variable('Biases', [1, output_size])\n",
    "\n",
    "    def classify(self, logits):\n",
    "        logits_flat = tf.reshape(logits, [-1, self.input_size])\n",
    "        nl = tf.matmul(tf.nn.relu(tf.matmul(logits_flat, self.w0) + self.b0), self.w1) + self.b1\n",
    "        return tf.reshape(nl, [-1, self.target_size, self.target_size])\n",
    "\n",
    "    @property\n",
    "    def l2_loss(self):\n",
    "        return tf.nn.l2_loss(self.w0) + tf.nn.l2_loss(self.w1)\n",
    "\n",
    "    \n",
    "class SentenceEmbedder(object):\n",
    "    def __init__(self, cell_size):\n",
    "        self.cell_size = cell_size\n",
    "        self.initializer = tf.contrib.layers.xavier_initializer(uniform=True, seed=None, dtype=tf.float32)\n",
    "        with tf.variable_scope('SentEmbedder', reuse=None):\n",
    "            self.embed_cell = tf.nn.rnn_cell.GRUCell(cell_size, activation=tf.nn.relu)\n",
    "\n",
    "    @property\n",
    "    def l2_loss(self):\n",
    "        return 0\n",
    "\n",
    "    def embed(self, inputs, seq_lens, state):\n",
    "        \"\"\"\n",
    "        :param inputs: List of input arrays 5*[batch_size x sent_len x word_embed_size]\n",
    "        :param seq_lens:\n",
    "        :param state:\n",
    "        :return: 5-lists output_list, all_output_list; [sent_embed_size x cell_size] state\n",
    "        \"\"\"\n",
    "        batch_size = get_this_batch_size(inputs[0])\n",
    "        sent_len = tf.shape(inputs[0])[1]\n",
    "        output_list = []\n",
    "        all_output_list = []\n",
    "        reuse_scope=None\n",
    "\n",
    "        for i in range(len(inputs)):\n",
    "            if i > 0:\n",
    "                reuse_scope = True\n",
    "            with tf.variable_scope('SentEmbedder', reuse=reuse_scope) as scope:\n",
    "                output, state = tf.nn.dynamic_rnn(\n",
    "                    self.embed_cell, inputs[i],\n",
    "                    sequence_length=seq_lens[:, i],\n",
    "                    initial_state=state,\n",
    "                    dtype=tf.float32,\n",
    "                    scope=scope)\n",
    "            # [batch_size x sent_len x cell_size]\n",
    "            all_output_list.append(output)\n",
    "            # Flatten from a vector per sentence in array to flat\n",
    "            output_flat = tf.reshape(output, [-1, output.get_shape()[2].value])\n",
    "            # Index the last output row for each\n",
    "            index = tf.range(0, batch_size) * sent_len + seq_lens[:, i] - 1\n",
    "            # Append the array containing [batch_size x cell_size]\n",
    "            output_list.append(tf.gather(output_flat, index))\n",
    "\n",
    "        return output_list, all_output_list, state\n",
    "\n",
    "\n",
    "class AttnSentenceEmbedder(SentenceEmbedder):\n",
    "    def __init__(self, cell_size):\n",
    "        SentenceEmbedder.__init__(self, cell_size)\n",
    "\n",
    "        with tf.variable_scope('SentEmbedder', reuse=None):\n",
    "            # Add additional variables not defined by SentenceEmbedder class\n",
    "            self.Wy = tf.get_variable('W_y', [cell_size, cell_size], dtype=tf.float32, initializer=self.initializer)\n",
    "            self.Wh = tf.get_variable('W_h', [cell_size, cell_size], dtype=tf.float32, initializer=self.initializer)\n",
    "            self.Wm = tf.get_variable('W_m', [cell_size, 1], dtype=tf.float32, initializer=self.initializer)\n",
    "            self.Wp = tf.get_variable('W_p', [cell_size, cell_size], dtype=tf.float32, initializer=self.initializer)\n",
    "            self.Wx = tf.get_variable('W_x', [cell_size, cell_size], dtype=tf.float32, initializer=self.initializer)\n",
    "            self.skipW = tf.get_variable('W_skip', dtype=tf.float32, initializer=[0.5, 0.5])\n",
    "\n",
    "    @property\n",
    "    def l2_loss(self):\n",
    "        # Override the SentenceEmbedder base l2_loss, which is 0\n",
    "        return (tf.nn.l2_loss(self.Wm) +\n",
    "                tf.nn.l2_loss(self.Wh) +\n",
    "                tf.nn.l2_loss(self.Wp) +\n",
    "                tf.nn.l2_loss(self.Wx) +\n",
    "                tf.nn.l2_loss(self.Wy))\n",
    "\n",
    "    def embed_with_attention(self, inputs, seq_lens, state, skip=False):\n",
    "\n",
    "        batch_size = get_this_batch_size(inputs[0])\n",
    "        sent_len = tf.shape(inputs[0])[1]\n",
    "        output_list, all_output_list, final_state = self.embed(inputs, seq_lens, state)\n",
    "        sent_rep = [None for _ in range(len(output_list))]\n",
    "\n",
    "        with tf.variable_scope('SentEmbedder', reuse=True):\n",
    "            # Need to batch_matmul if the data in is matrix (Y, M)\n",
    "            Wy_batch = tf.tile(tf.expand_dims(self.Wy, 0), [batch_size, 1, 1])  # batch_size x [cell_size x cell_size]\n",
    "            Wh = self.Wh\n",
    "            Wm = tf.tile(tf.expand_dims(self.Wm, 0), [batch_size, 1, 1])  # batch_size x [cell_size x 1]\n",
    "\n",
    "        for t in range(len(sent_rep)):\n",
    "            Y = all_output_list[t]  # [batch_size x sent_len x cell_size]\n",
    "            next_t = t + 1\n",
    "            if t == len(sent_rep) - 1:\n",
    "                next_t = 0\n",
    "\n",
    "            h = output_list[next_t]  # [batch_size x cell_size]\n",
    "\n",
    "            # batch_size * [sent_len x cell_size] x [cell_size x cell_size] => [batch_size x sent_len x cell_size]\n",
    "            M1 = tf.batch_matmul(Y, Wy_batch)\n",
    "            # batch_size * [1 x cell_size] x [cell_size x cell_size] => # batch_size x [sent_len x cell_size]\n",
    "            M2 = tf.tile(tf.expand_dims(tf.matmul(h, Wh), 1), [1, sent_len, 1])\n",
    "            M = tf.nn.relu(tf.add_n([M1, M2]))  # [sent_len x cell_size]\n",
    "\n",
    "            # batch_size * [sent_len x cell_size] * [cell_size x 1]\n",
    "            # => batch_size * [sent_len x 1] => <squeeze+softmax> batch_size x sent_len\n",
    "            # => <expand> batch_size x 1 x sent_len\n",
    "            alphas = tf.expand_dims(tf.nn.softmax(tf.squeeze(tf.batch_matmul(M, Wm))), 1)\n",
    "\n",
    "            # representation r = Y*alphas^T : batch_size * [1 x sent_len] x [sent_len x cell_size]\n",
    "            r = tf.squeeze(tf.batch_matmul(alphas, Y))\n",
    "            h_ = tf.nn.relu(tf.matmul(r, self.Wp) + tf.matmul(final_state, self.Wx))\n",
    "\n",
    "            # representation r [batch_size x cell_size]\n",
    "            sent_rep[next_t] = h_\n",
    "\n",
    "        if skip:\n",
    "            return sent_rep, output_list, final_state\n",
    "        else:\n",
    "            return sent_rep, final_state\n",
    "\n",
    "    def embed_with_skip(self, inputs, seq_lens, state):\n",
    "        embed_attn, embed_init, final_state = self.embed_with_attention(inputs, seq_lens, state, skip=True)\n",
    "        assert len(embed_attn) == len(embed_init)\n",
    "\n",
    "        skipW = self.skipW / tf.reduce_sum(self.skipW)\n",
    "        embed = [skipW[0] * embed_attn[i] + skipW[1] * embed_init[i] for i in range(len(embed_attn))]\n",
    "        return embed, final_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BASIC MODEL CLASS\n",
    "class Model(object):\n",
    "    def __init__(self, args_dict, save_path, use_own_sess=True):\n",
    "        \"\"\"\n",
    "        Initialize the model object.\n",
    "        :param args_dict: must have keys and corresponding values for\n",
    "        word_embed_size, sent_embed_size, attn_scorer_size, read_cycles\n",
    "        \"\"\"\n",
    "        self.target_size = 5\n",
    "        self.word_embed_size = args_dict['word_embed_size']\n",
    "        self.sent_embed_size = args_dict['sent_embed_size']\n",
    "        self.attn_scorer_size = args_dict['attn_scorer_size']\n",
    "        self.read_cycles = args_dict['read_cycles']\n",
    "        self.encoder_size = args_dict['encoder_size']\n",
    "        self.reg = args_dict['reg']\n",
    "        self.vocab_size = args_dict['vocab_size']\n",
    "        \n",
    "        # Placeholders\n",
    "        self.story, self.order, self.seq_lens, self.pos_order = self.make_placeholders()\n",
    "\n",
    "        # Model components\n",
    "        # self.worder = None\n",
    "        self.worder = None\n",
    "        self.embedder = None\n",
    "        self.encoder = None\n",
    "\n",
    "        # Ops defined when model is built\n",
    "        self.loss_op = None\n",
    "        self.predict_op = None\n",
    "\n",
    "        # Session for model to use\n",
    "        if use_own_sess:\n",
    "            self.sess = tf.Session()\n",
    "        else:\n",
    "            self.sess = None\n",
    "\n",
    "        # Used for saves and importing\n",
    "        self.saver = None\n",
    "        self.save_path = save_path\n",
    "        self.saved_path = args_dict['saved_path']\n",
    "\n",
    "    def make_placeholders(self):\n",
    "        \"\"\"\n",
    "        Make placeholders.\n",
    "        Cannot specify batch_size ahead of time since this screws up prediction.\n",
    "        :return: tuple of placeholders\n",
    "        \"\"\"\n",
    "        story = tf.placeholder(tf.int32, [None, self.target_size, None], \"story\")  # [batch_size x 5 x max_length]\n",
    "        order = tf.placeholder(tf.int32, [None, self.target_size], \"order\")  # [batch_size x 5]\n",
    "        seq_lens = tf.placeholder(tf.int32, [None, self.target_size], \"seq_lens\")  # [batch_size x 5]\n",
    "        pos_order = tf.placeholder(tf.int32, [self.target_size, None], \"pos_order\")  # [5 x batch_size]\n",
    "\n",
    "        return story, order, seq_lens, pos_order\n",
    "\n",
    "    def build(self):\n",
    "        self.worder = WordEmbedder(self.word_embed_size, self.vocab_size)\n",
    "        self.embedder = AttnSentenceEmbedder(self.sent_embed_size)\n",
    "        self.classifier = NonLinearClassifier(5*self.sent_embed_size, 25)\n",
    "\n",
    "        static_batch_size = self.story.get_shape()[0].value\n",
    "\n",
    "        # WORD EMBEDDINGS: list 5 *[batch_size x word_embed_size]\n",
    "        words_embedded = self.worder.embed(self.story)\n",
    "\n",
    "        # SENTENCE EMBEDDINGS: list 5*[batch_size x sent_embed_size]\n",
    "        output_list, _ = self.embedder.embed_with_skip(words_embedded, self.seq_lens, None)\n",
    "        embedded = tf.pack(output_list, axis=1)\n",
    "        embedded.set_shape([static_batch_size, self.target_size, self.sent_embed_size])\n",
    "        embedded = self.classifier.classify(embedded)\n",
    "\n",
    "        reg_loss = self.reg * (\n",
    "            self.classifier.l2_loss + self.embedder.l2_loss)\n",
    "\n",
    "        self.loss_op = self.simple_loss(embedded, self.order) + reg_loss\n",
    "        self.predict_op = self.simple_predict(embedded)\n",
    "\n",
    "        return None\n",
    "\n",
    "    def train(self, args_dict, train_feed_dict, dev_feed_dict, batch_list, write_to=None, verbose=True):\n",
    "\n",
    "        learn_rate = args_dict['learn_rate']\n",
    "        batch_size = args_dict['batch_size']\n",
    "        n_epochs = args_dict['n_epochs']\n",
    "\n",
    "        train_batches = batch_list[0]\n",
    "        train_batch_orders = batch_list[1]\n",
    "        train_batch_sent_len = batch_list[2]\n",
    "        train_batch_pos_orders = batch_list[3]\n",
    "\n",
    "        # TRAINING\n",
    "        opt_op = tf.train.AdamOptimizer(learn_rate).minimize(self.loss_op)\n",
    "        if verbose:\n",
    "            self.print_trainables(write_to)\n",
    "        print('Epoch', 'Train Loss', 'Train Accuracy', 'Dev Accuracy', 'Time Elapsed', file=write_to, sep=',')\n",
    "        if write_to is not None:\n",
    "            write_to.flush()\n",
    "\n",
    "        # Load session: initialize all variables and restore saved variables\n",
    "        self.load()\n",
    "\n",
    "        N = len(train_batches) * batch_size\n",
    "        start = time.time()\n",
    "        train_acc_list = []\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            # print('----- Epoch', epoch, '-----')\n",
    "            total_loss = 0\n",
    "            for i in range(len(train_batches)):\n",
    "                inst_story = train_batches[i]\n",
    "                inst_order = train_batch_orders[i]\n",
    "                inst_seq_len = train_batch_sent_len[i]\n",
    "                inst_pos_order = train_batch_pos_orders[i]\n",
    "                feed_dict = {self.story: inst_story, self.order: inst_order,\n",
    "                             self.seq_lens: inst_seq_len, self.pos_order: inst_pos_order}\n",
    "                _, current_loss = self.sess.run([opt_op, self.loss_op], feed_dict=feed_dict)\n",
    "                total_loss += current_loss\n",
    "\n",
    "            train_predicted = self.sess.run(self.predict_op, feed_dict=train_feed_dict)\n",
    "            train_accuracy = nn.calculate_accuracy(train_feed_dict[self.order], train_predicted)\n",
    "            train_acc_list.append(train_accuracy)\n",
    "\n",
    "            dev_predicted = self.sess.run(self.predict_op, feed_dict=dev_feed_dict)\n",
    "            dev_accuracy = nn.calculate_accuracy(dev_feed_dict[self.order], dev_predicted)\n",
    "\n",
    "            print(epoch, total_loss / N, train_accuracy, dev_accuracy,\n",
    "                  '{:6.2f}'.format((time.time()-start)/60), file=write_to, sep=',')\n",
    "\n",
    "            if write_to is not None:\n",
    "                write_to.flush()\n",
    "\n",
    "            if args_dict['save_flag']:\n",
    "                if epoch % 5 == 0 and epoch > 0:\n",
    "                    self.save(epoch)\n",
    "                    if args_dict['stop_flag'] is True and (\n",
    "                                np.mean(train_acc_list[-5:]) < np.mean(train_acc_list[-10:-5]) + 5e-3):\n",
    "                        break\n",
    "\n",
    "    def save(self, epoch=None):\n",
    "        # SAVING: saver must be made after graph is built\n",
    "        if self.saver is None:\n",
    "            self.saver = tf.train.Saver(var_list=tf.all_variables(), keep_checkpoint_every_n_hours=1.0)\n",
    "\n",
    "        saved_to = self.saver.save(self.sess, self.save_path, global_step=epoch)\n",
    "        print('Model saved to: ', saved_to)\n",
    "\n",
    "    def load(self):\n",
    "        if self.saver is None:\n",
    "            if self.saved_path is not None and self.saved_path.endswith('.meta'):\n",
    "                self.saver = tf.train.import_meta_graph(self.saved_path)\n",
    "            else:\n",
    "                self.saver = tf.train.Saver()\n",
    "\n",
    "        if self.saved_path is not None:\n",
    "            if self.saved_path.endswith('.meta'):\n",
    "                saved_path = self.saved_path.replace('.meta', '')\n",
    "            else:\n",
    "                saved_path = self.saved_path\n",
    "            self.saver.restore(self.sess, saved_path)\n",
    "        else:\n",
    "            self.sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    def predict(self, feed_dict):\n",
    "        return self.sess.run(self.predict_op, feed_dict=feed_dict)\n",
    "\n",
    "    @staticmethod\n",
    "    def print_trainables(write_to=None):\n",
    "        # OPTIONAL: checking variables and number of training parameters\n",
    "        # print('All variables: ', [var.name for var in tf.all_variables()])\n",
    "        trainables = tf.trainable_variables()\n",
    "        print('===== Trainable variables =====', file=write_to)\n",
    "        print('Number of trainable parameters:', np.sum([np.prod(var.get_shape()) for var in trainables]),\n",
    "              file=write_to)\n",
    "        [print(var.name, var.get_shape()) for var in trainables]\n",
    "\n",
    "    @staticmethod\n",
    "    def simple_loss(logits, order):\n",
    "        return tf.reduce_sum(tf.nn.sparse_softmax_cross_entropy_with_logits(logits, order))\n",
    "\n",
    "    @staticmethod\n",
    "    def simple_predict(logits):\n",
    "        # story x output sentence position x probabilities of input sentence indices\n",
    "        # need to unpack and repack because can't specify axis for softmax\n",
    "        softmaxed_logits = tf.pack([tf.nn.softmax(tensor) for tensor in tf.unpack(logits, axis=1)], axis=1)\n",
    "\n",
    "        # what is the most likely position for each of my input sentences?\n",
    "        # NOT what is the most likely sentence for each position\n",
    "        predict = tf.arg_max(softmaxed_logits, 2)\n",
    "        return predict\n",
    "\n",
    "    @staticmethod\n",
    "    def simple_sentence_embedder(words_embedded, word_embed_size, sent_embed_size):\n",
    "        \"\"\"\n",
    "        Sums word embeddings of a whole sentence, then projects linearly to the sentence embedding size.\n",
    "        :param word_embed_size:\n",
    "        :param sent_embed_size:\n",
    "        :param words_embedded: list of 5*[batch_size x max_seq_length x word_embed_size]\n",
    "        :return: 5-list of [batch_size x sent_embed_size=word_embed_size]\n",
    "        \"\"\"\n",
    "        hs = [tf.reduce_sum(sentence, 1) for sentence in words_embedded]  # 5 times [batch_size x input_size]\n",
    "\n",
    "        with tf.variable_scope('SentEmbedder', reuse=None):\n",
    "            P = tf.get_variable('Word2Sent', [word_embed_size, sent_embed_size], dtype=tf.float32)\n",
    "            embedded = [tf.matmul(embed, P) for embed in hs]  # 5 * batch_size x sent_embed_size\n",
    "\n",
    "        return embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convenience function\n",
    "def get_this_batch_size(tensor):\n",
    "    return tf.shape(tensor)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Preprocess(object):\n",
    "    def __init__(self, batch_size=100, n_train=None, n_dev=None, permute=0, permute_frac=0):\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.n_train = n_train\n",
    "        self.n_dev = n_dev\n",
    "        self.permute = permute\n",
    "        self.permute_frac = permute_frac\n",
    "\n",
    "        if n_dev is not None:\n",
    "            assert n_dev >= batch_size\n",
    "\n",
    "        self.vocab_size = None\n",
    "        self.data_train = None\n",
    "        self.data_dev = None\n",
    "        self.vocab = None\n",
    "\n",
    "    def build_vocab(self, data):\n",
    "        \"\"\"\n",
    "        Tokenisation and listification pipeline\n",
    "        :param data:\n",
    "\n",
    "        \"\"\"\n",
    "        vocab = self.vocab\n",
    "\n",
    "        is_ext_vocab = True\n",
    "\n",
    "        if vocab is None:\n",
    "            is_ext_vocab = False\n",
    "            vocab = {'<PAD>': 0, '<OOV>': 1}\n",
    "\n",
    "        data_sentences = []  # A list of lists of integer-ised sentences\n",
    "        data_orders = []  # A list of lists of orders\n",
    "        data_sent_lens = []  # A list of lists of sentence lengths\n",
    "        # data_sent_lens[i][j] is length of jth sentence in ith story\n",
    "\n",
    "        for instance in data:\n",
    "            sents = []\n",
    "            for sentence in instance['story']:\n",
    "                sent = []\n",
    "                tokenized = self.tokenize(sentence)\n",
    "                for token in tokenized:\n",
    "                    if not is_ext_vocab and token not in vocab:\n",
    "                        vocab[token] = len(vocab)\n",
    "                    if token not in vocab:\n",
    "                        token_id = vocab['<OOV>']\n",
    "                    else:\n",
    "                        token_id = vocab[token]\n",
    "                    sent.append(token_id)\n",
    "                sents.append(sent)\n",
    "            data_sentences.append(sents)\n",
    "            data_orders.append(instance['order'])\n",
    "            data_sent_lens.append([len(sent) for sent in sents])\n",
    "\n",
    "        self.vocab = vocab\n",
    "        self.vocab_size = len(vocab)\n",
    "\n",
    "        return data_sentences, data_orders, data_sent_lens\n",
    "\n",
    "    def bucket(self, data_sent_lens):\n",
    "\n",
    "        batch_size = self.batch_size\n",
    "\n",
    "        # BUCKETING\n",
    "        # Get the maximum sentence length for each story\n",
    "        story_max_sent_lens = [max(sent_lens) for sent_lens in data_sent_lens]\n",
    "        # Sort instances by maximum sentence length, return sorted indices\n",
    "        sorted_by_len = np.argsort(np.array(story_max_sent_lens))\n",
    "\n",
    "        # Split sorted indices into sublists of batch_size (drop trailing end)\n",
    "        n_batches = int(math.floor(len(sorted_by_len) / batch_size))\n",
    "        batches = [list(sorted_by_len[(i * batch_size):((i + 1) * batch_size)]) for i in range(n_batches)]\n",
    "\n",
    "        return batches, story_max_sent_lens  # indices, a list of lists\n",
    "\n",
    "    def bucket_and_batch(self, *args):\n",
    "        return self.batch(*args, bucket=True)\n",
    "\n",
    "    def batch(self, data_sentences, data_orders, data_sent_lens, bucket=True):\n",
    "        \"\"\"\n",
    "        :param data_sentences:\n",
    "        :param data_orders:\n",
    "        :param data_sent_lens:\n",
    "        :param bucket\n",
    "\n",
    "        :return: batch_list: a list of arrays [batch_size x 5 x max_sent_len]\n",
    "        :return: batch_orders: a list of arrays [batch_size x 5]\n",
    "        :return: batch_sent_len: a list of arrays [batch_size x 5]\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size = self.batch_size\n",
    "\n",
    "        if bucket:\n",
    "            batches, story_max_sent_lens = self.bucket(data_sent_lens)\n",
    "        else:\n",
    "            n_batches = int(math.floor(len(data_sentences) / batch_size))\n",
    "            story_max_sent_lens = [max(sent_lens) for sent_lens in data_sent_lens]\n",
    "            batches = [list(range(i*batch_size,(i+1)*batch_size)) for i in range(n_batches)]\n",
    "\n",
    "        # BATCHING\n",
    "        batch_list = []\n",
    "        batch_orders = []\n",
    "        batch_sent_len = []\n",
    "        batch_pos_orders = []\n",
    "\n",
    "        # For each batch, create an np array of words coded as integers\n",
    "        # and a corresponding np array of true order vectors\n",
    "        for batch in batches:\n",
    "            # Collect all maximum sentence lengths for stories in this batch\n",
    "            sent_lens = [story_max_sent_lens[story_idx] for story_idx in batch]\n",
    "            # Find the maximum sentence length in whole batch\n",
    "            max_sent_len = max(sent_lens)\n",
    "            # Retrieve the length of each sentence as a list for every story in the batch\n",
    "            # batch_sent_len.append([data_sent_lens[story_idx] for story_idx in batch])\n",
    "\n",
    "            out_sentences = np.full(\n",
    "                [batch_size, 5, max_sent_len], self.vocab['<PAD>'], dtype=np.int32)\n",
    "            out_orders = np.zeros([batch_size, 5], dtype=np.int8)\n",
    "            out_sent_lens = np.zeros([batch_size, 5], dtype=np.int32)\n",
    "\n",
    "            # For every example in the batch\n",
    "            for story_ctr in range(batch_size):\n",
    "                elem = data_sentences[batch[story_ctr]]\n",
    "                # For each sentence in the example\n",
    "                # Fill a row of the orders array\n",
    "                out_orders[story_ctr, :] = data_orders[batch[story_ctr]]\n",
    "                out_sent_lens[story_ctr, :] = data_sent_lens[batch[story_ctr]]\n",
    "                for sent_ctr, sent in enumerate(elem):\n",
    "                    # Fill a row with the sentence\n",
    "                    out_sentences[story_ctr, sent_ctr, 0:len(sent)] = sent\n",
    "\n",
    "            # After filling sentences and orders for every example in the batch\n",
    "            # add the np arrays of orders and sentences to the corresponding lists\n",
    "            batch_list.append(out_sentences)\n",
    "            batch_orders.append(out_orders)\n",
    "            batch_sent_len.append(out_sent_lens)\n",
    "            batch_pos_orders.append(self.position_orders(out_orders))\n",
    "\n",
    "        # Return a list of arrays in sent_len: each element is batch_size x 5\n",
    "        # sent_len[i][j,k] returns length of kth sentence in jth story in ith batch\n",
    "\n",
    "        return [batch_list, batch_orders, batch_sent_len, batch_pos_orders]\n",
    "\n",
    "    def pipeline(self):\n",
    "        data_train, data_dev = self.load_data()\n",
    "\n",
    "        # Permute training stories if required\n",
    "        if self.permute > 0:\n",
    "            for i in range(self.permute):\n",
    "                data_train.extend(self.permute_orders(data_train))\n",
    "\n",
    "        if self.permute_frac > 0:\n",
    "            data_train.extend(self.add_permutes(data_train, self.permute_frac))\n",
    "\n",
    "        # Build vocab and extract: story, order, sent_len in own lists\n",
    "        train_lists = self.build_vocab(data_train)\n",
    "        dev_lists = self.build_vocab(data_dev)\n",
    "\n",
    "        # Batch and bucket\n",
    "        train_batches = self.bucket_and_batch(*train_lists)\n",
    "        dev_batches = self.batch(*dev_lists)\n",
    "        return train_batches, dev_batches\n",
    "\n",
    "    def test_pipeline(self, data, model):\n",
    "        data_lists = self.build_vocab(data)\n",
    "        batches = self.batch(*data_lists, bucket=True)\n",
    "        feed_dict = self.stack_batches(*batches, model=model, restrict=False)\n",
    "        return feed_dict, feed_dict[model.order]\n",
    "\n",
    "    def validate(self, folds=5):\n",
    "        data_train, data_dev = self.resplit_data(folds)\n",
    "        data_train.extend(self.add_permutes(data_train, self.permute_frac))\n",
    "        train_batches = self.bucket_and_batch(*self.build_vocab(data_train))\n",
    "        dev_batches = self.bucket_and_batch(*self.build_vocab(data_dev))\n",
    "        return train_batches, dev_batches\n",
    "\n",
    "    def stack_batches(self, batches, batch_orders, batch_sent_len, batch_pos_orders, model, restrict=True):\n",
    "        \"\"\"\n",
    "        Fills the feed dictionary by combining the batches provided\n",
    "        :param batches: a list containing the batch arrays\n",
    "        :param batch_orders: a list containing the order arrays\n",
    "        :param batch_sent_len: a list containing the sentence length arrays\n",
    "        :param batch_pos_orders:\n",
    "        :param model\n",
    "        :param restrict\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size = self.batch_size\n",
    "        if restrict is True and (len(batches) * batch_size > 1000):\n",
    "            max_batches = int(math.floor(1000 / batch_size))\n",
    "            train_sample = list(np.random.randint(0, len(batches), max_batches))\n",
    "            batches = [batches[i] for i in train_sample]\n",
    "            batch_orders = [batch_orders[i] for i in train_sample]\n",
    "            batch_sent_len = [batch_sent_len[i] for i in train_sample]\n",
    "            batch_pos_orders = [batch_pos_orders[i] for i in train_sample]\n",
    "\n",
    "        max_sent_len = max([x.shape[2] for x in batches])\n",
    "        stories_list = []\n",
    "        for batch in batches:\n",
    "            missing_len = max_sent_len - batch.shape[2]\n",
    "            stories_list.append(\n",
    "                np.concatenate([batch,\n",
    "                                np.zeros([batch_size, 5, missing_len], dtype=np.int32)\n",
    "                                ], 2))\n",
    "\n",
    "        stories = np.concatenate(stories_list, 0)\n",
    "        orders = np.vstack(batch_orders)\n",
    "        pos_orders = np.concatenate(batch_pos_orders, 1)\n",
    "        sent_lens = list(itertools.chain.from_iterable(batch_sent_len))\n",
    "\n",
    "        return {model.story: stories, model.order: orders, model.seq_lens: sent_lens, model.pos_order: pos_orders}\n",
    "\n",
    "    def resplit_data(self, k):\n",
    "        data_train, data_dev = self.load_data()\n",
    "        data_train.extend(data_dev)\n",
    "        np.random.shuffle(data_train)\n",
    "        fold_size = int(np.floor(len(data_train)/k))\n",
    "        data_dev = data_train[:fold_size]\n",
    "        data_train = data_train[fold_size:]\n",
    "        return data_train, data_dev\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Load data. If n_train and n_dev specified, return samples of specified sizes.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        data_path = _snlp_book_dir + \"data/nn/\"\n",
    "        data_train = nn.load_corpus(data_path + \"train.tsv\")\n",
    "        data_dev = nn.load_corpus(data_path + \"dev.tsv\")\n",
    "        # assert (len(data_train) == 45502)\n",
    "\n",
    "        if self.n_train is None:\n",
    "            return data_train, data_dev\n",
    "        elif self.n_dev is None:\n",
    "            self.n_dev = max([np.floor(self.n_train / 40), self.batch_size])\n",
    "\n",
    "        data_train = [data_train[x] for x in list(\n",
    "            np.random.randint(0, len(data_train), self.n_train))]\n",
    "        data_dev = [data_dev[x] for x in list(\n",
    "            np.random.randint(0, len(data_dev), self.n_dev))]\n",
    "        return data_train, data_dev\n",
    "\n",
    "    @staticmethod\n",
    "    def permute_orders(data):\n",
    "        \"\"\"\n",
    "        Takes the standard data format, a dictionary per story with keys 'order' and 'story'\n",
    "        :param data:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        shuffled = []\n",
    "        for datum in data:\n",
    "            while True:\n",
    "                perm = np.random.permutation(datum['order'])\n",
    "                if all(perm == datum['order']) is False:\n",
    "                    break\n",
    "            perm_story = [datum['story'][i] for i in perm]\n",
    "            shuffled.append({'order': perm, 'story': perm_story})\n",
    "        return shuffled\n",
    "\n",
    "    @staticmethod\n",
    "    def add_permutes(data, frac):\n",
    "        shuffled = []\n",
    "        n_permutes = int(frac * len(data))\n",
    "        idx = np.random.choice(len(data), n_permutes, replace=False)\n",
    "        for i in idx:\n",
    "            datum = data[i]\n",
    "            while True:\n",
    "                perm = np.random.permutation(datum['order'])\n",
    "                if all(perm == datum['order']) is False:\n",
    "                    break\n",
    "            perm_story = [datum['story'][i] for i in perm]\n",
    "            shuffled.append({'order': perm, 'story': perm_story})\n",
    "        return shuffled\n",
    "\n",
    "    @staticmethod\n",
    "    def tokenize(inputs):\n",
    "        \"\"\"\n",
    "        Tokenize strings\n",
    "        :param inputs: string to be tokenized\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        tokenized = re.compile('[\\s.,!;\\\\W+]').split(inputs)\n",
    "        return [token.lower() for token in tokenized]\n",
    "\n",
    "    @staticmethod\n",
    "    def position_orders(orders, target_size=5):\n",
    "        \"\"\"\n",
    "        Generate the fill for pos_order\n",
    "        :param orders:\n",
    "        :param target_size:\n",
    "        :return: [target_size x batch_size]\n",
    "        \"\"\"\n",
    "        index_stack = np.transpose([np.arange(target_size)[orders[i]] for i in range(orders.shape[0])])\n",
    "        return index_stack\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>Setup 2</font>: Load Training Data\n",
    "\n",
    "This cell loads the training data. **Do not edit the next cell, nor copy/duplicate it**. Instead refer to the variables in your own code, and slice and dice them as you see fit (but do not change their values). \n",
    "For example, no one stops you from introducing, in the corresponding task section, `my_train` and `my_dev` variables that split the data into different folds.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-20T12:04:57.110195",
     "start_time": "2016-12-20T12:04:56.251082"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#! SETUP 2 - DO NOT CHANGE, MOVE NOR COPY\n",
    "data_path = _snlp_book_dir + \"data/nn/\"\n",
    "data_train = nn.load_corpus(data_path + \"train.tsv\")\n",
    "data_dev = nn.load_corpus(data_path + \"dev.tsv\")\n",
    "assert(len(data_train) == 45502)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Retrieve arguments\n",
    "model_path = 'model/model.checkpoint'\n",
    "args_dict = {'word_embed_size': 100, \n",
    "             'sent_embed_size': 75,\n",
    "             'attn_scorer_size': None,\n",
    "             'read_cycles': None,\n",
    "             'encoder_size': None,\n",
    "             'saved_path': model_path,\n",
    "              'vocab_size': None,\n",
    "             'reg': 0.1, 'batch_size': 25, 'n_epochs':5, 'learn_rate': 0.003,  # not used\n",
    "             'save_flag': False,'save_dir': 'model/',  # not used\n",
    "             'write_flag': False, 'write_dir': 'res/',  # not used\n",
    "             'permute': 0, 'permute_frac': 0, # not used\n",
    "             'stop_flag': True,'full_run_flag': True,  # not used?\n",
    "            }\n",
    "\n",
    "\n",
    "# ===== DATA LOADING ======\n",
    "pipeline = Preprocess(args_dict['batch_size'])\n",
    "# Use both data and dev set to define vocabulary\n",
    "all_data = []\n",
    "all_data.extend(data_train)\n",
    "all_data.extend(data_dev)\n",
    "_ = pipeline.build_vocab(all_data)\n",
    "args_dict['vocab_size'] = pipeline.vocab_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== FINALLY, START MODELLING =====\n",
    "# Initialise model (starts a session)\n",
    "model = Model(args_dict, save_path=None, use_own_sess=False)\n",
    "# model = AttnSkipEncoderModel(args_dict, save_path=None, use_own_sess=False)\n",
    "\n",
    "# Build model \n",
    "model.build()\n",
    "predict = model.predict_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Assessment 1</font>: Assess Accuracy (50 pts) \n",
    "\n",
    "We assess how well your model performs on an unseen test set. We will look at the accuracy of the predicted sentence order, on sentence level, and will score them as followis:\n",
    "\n",
    "* 0 - 20 pts: 45% <= accuracy < 50%, linear\n",
    "* 20 - 40 pts: 50% <= accuracy < 55\n",
    "* 40 - 70 pts 55 <= accuracy < Best Result, linear\n",
    "\n",
    "The **linear** mapping maps any accuracy value between the lower and upper bound linearly to a score. For example, if your model's accuracy score is $acc=54.5\\%$, then your score is $20 + 20\\frac{acc-50}{55-50}$.\n",
    "\n",
    "The *Best-Result* accuracy is the maximum of the best accuracy the course organiser achieved, and the submitted accuracies scores.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code loads your model, computes accuracy, and exports the result. **DO NOT** change this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD THE DATA\n",
    "data_test = nn.load_corpus(data_path + \"dev.tsv\")\n",
    "test_feed_dict, test_orders = pipeline.test_pipeline(data_test, model)\n",
    "dev_orders = test_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-20T12:05:55.116609",
     "start_time": "2016-12-20T12:05:54.758571"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53978378378378378"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#! ASSESSMENT 1 - DO NOT CHANGE, MOVE NOR COPY\n",
    "with tf.Session() as sess:\n",
    "    # LOAD THE MODEL\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, './model/model.checkpoint')\n",
    "    \n",
    "    # RUN TEST SET EVALUATION\n",
    "    dev_predicted = sess.run(predict, feed_dict=test_feed_dict)\n",
    "    dev_accuracy = nn.calculate_accuracy(dev_orders, dev_predicted)\n",
    "\n",
    "dev_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='orange'>Mark</font>:  Your solution to Task 1 is marked with ** __ points**. \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Task 2</font>: Describe your Approach\n",
    "\n",
    "Enter a 750 words max description of your approach **in this cell**.\n",
    "Make sure to provide:\n",
    "- an **error analysis** of the types of errors your system makes\n",
    "- compare your system with the model we provide, focus on differences and draw useful comparations between them\n",
    "\n",
    "Should you need to include figures in your report, make sure they are Python-generated. For that, feel free to create new cells after this cell (before Assessment 2 cell). Link online images at your risk.\n",
    "\n",
    "## REPORT\n",
    "#### Dataset preparation: \n",
    "- Randomly shuffled the data. \n",
    "- Split into training and development sets for generic experimentation. \n",
    "- Estimated generalisation performance of production models by 5-fold cross validation. \n",
    "- Trained final model on the full data set.\n",
    "\n",
    "#### Word Embeddings: \n",
    "-  Due to the small size of the corpus, to avoid over-fitting, we did not train embedding vectors but rather imported GloVe pre-trained embeddings vectors. \n",
    "- Experimented with three different embedding dimensions (50-100-300), selected the one that resulted in highest performance (100-dimensional).\n",
    "\n",
    "#### Pre-processing: \n",
    "-\tImproved tokenization (conservatively) until we were able to achieve a ~98% match of our vocabulary to the imported GloVe vectors. Visually inspected missing words for obvious mistakes, checked frequency of occurrence in the corpus and mostly replaced them with the OOV token (the embedding of which was obtained as the average – per dimension – of all words in our dictionary, i.e. effectively representing an uninformative prior). \n",
    "-\tSorted the stories according to sentence size and created a vector that contained the length of each sentence (required for efficient RNN calculations)\n",
    "-\tBucketed stories according to size and split into batches according to the selected batch size.\n",
    "\n",
    "#### Model: \n",
    "-\tExperimented with several different architectures, based on the set to sequence models introduced by [Vinyals et al, ICLR2016] and further developed by [Logeswaran et al, ICLR2017], supplemented with ideas for conditional encoding and sentence embedding attention by [Rocktaschel et al, ICLR2016]. \n",
    "-\t**Implemented model**: linear combination of conditional sentence encoding with and without sentence-by-sentence attention, followed by a non-linear (affine + RELU) layer.\n",
    "\n",
    "*Model architecture:*\n",
    "- **a.\tSentence embedding:** Five RNNs (GRU) cells with shared state vectors and sentence by sentence attention mechanism.\n",
    "- **b.\tEncoder:** RNNs (GRU) coupled with a sentence attention mechanism. The GRUs receive no input and their hidden state is a concatenation of the output of the previous hidden state and the attention readout. The process is repeated a number of times (read cycles) in order to achieve a representation that is feed-order invariant. The final state of the encoder initialises the hidden state of the decoder. \t\n",
    "- **c.\tDecoder:** RNNs (GRU) with an affine layer which attends the decoder output and the sentence embeddings and produces the output. \n",
    "- **d.\tSkip connections:** We introduced skip connections between the sentence embedding (a weighted sum of the non-attentive and the attentive part) and the decoder (i.e. bypassing the encoder).\n",
    "\n",
    "**N.B.**: Although the original works that our model is based upon used LSTMs, due to limited computational resources, we resorted to the more efficient GRUs. According to [Jozefowicz at al, 2015], both units have comparable performance andthe GRU’s often outperform LSTMs. For the same reason, in the affine decoder, we replaced the tanh activation function with ReLU.\n",
    "\n",
    "#### Data augmentation: \n",
    "- Fed models with all random permutations of sentence orderings, which increased robustness and literally eliminated over-fitting (calculated training set accuracy was consistently lower than dev-set accuracy) but came at a large computational penalty (huge increase in training time). Final model injects a random sample of a fraction of permutations (hyperparameter).\n",
    "\n",
    "#### Other Considerations: \n",
    "-  Implemented L2 regularisation using a sum of L2 norms of selected weight matrices. On the model submitted, two variants were compared (see figures below): regularisation on final non-linear classifier only, or regularisation of classifier and of weight matrices (as defined in Rocktaschel, see appendix) in sentence-by-sentence attention.\n",
    "\n",
    "-\tInvestigated model sizes between 60 thousand and 10 million parameters. Final model has: 212577 parameters (excluding the pre-trained word embeddings) and a vocabulary of 26837 words.\n",
    "   \n",
    "   *Also implemented but discarded (see code graveyard below):*\n",
    "-\tBi-directional RNNs (for both sentence and story embeddings)\n",
    "-\tWeighted encoder-decoder \n",
    "-\tDrop-out (model proved to complex to properly implement drop out)\n",
    "\n",
    "#### Model hyperparameters: \n",
    "learning rate, batch size, training epochs, word embedding size, sentence embedding size, encoder & attention scorer size, decoder size, affine layer size, num of read cycles, data augmentation size (num. of injected permutations), L2 regularisation parameter. \n",
    "\n",
    "Performed an informal and necessarily  limited parameter search for most due to lack of computational resources, by varying 1-3 parameters at a time and observing the error in the dev set. Word embedding size, sentence embedding size and regularisation parameter were more thoroughly cross-validated (5-fold, see boxplots below).\n",
    "\n",
    "#### Optimisation:\n",
    "We used the ADAM optimizer with a learning rate of 0.001, a first momentum coefficient of 0.9 and a second momentum coefficient of 0.999. Regularisation strength was set to 0.1. \n",
    "\n",
    "#### Implementation: \n",
    "All components were implemented using a highly flexible class structure. Hyper-parameter tuning was carried out by calling the various models from a command line interface and automatically saving the results to files for post processing. \n",
    "Training was carried out using AWS CPU's. \n",
    "\n",
    "#### Differences between our model and the provided model (notebook):\n",
    "The baseline notebook model is relatively simple. It learns a word embedding from the training set, calculates the mean of each sentences’ word vectors (the sentence embedding) and predicts with a linear combination of the stacked sentence vectors (however, with some tuning, even this simple model could achieve dev-set accuracy above 50%).  Our model implements a state-of-the-art method (encoder-attention-decoder-affine layer model), additionally experimenting with skip connections and data augmentation. \n",
    "\n",
    "However, we did not manage to get the full potential of our model nor replicate the results of the literature. The model proved difficult to build (and debug) and with the limited computational resources that we had access to, we were unable to tune it within the available time-frame. The maximum CV accuracy that we achieved with the full model was 54.6 which forced us to take a more conservative approach and *submit our report with a model that omits the story encoding and decoding stage and which achieved better performance (1.3% higher) and, being less complex, should generalise better*.\n",
    "\n",
    "#### Error analysis and improvements:\n",
    "\n",
    "We did not impose a consistency check, thus our model occasionally predicts multiple instances of the same label. Inspecting sentences with 4/5 classification accuracy we realised that this proves to be a considerable bottleneck. Given more time, we would have experimented with a different output set-up which would have allowed us to extract top-k most likely predictions which would have helped to alleviate that issue. \n",
    "We also observed that the most common mistake that our model makes is to flip around two sentence positions resulting in 3/5 accuracy. Although this is reducing the accuracy of the model by two points in each story it is in essence a single mistake, and the model seems to correctly capture the general sentence ordering, which is satisfactory. \n",
    "\n",
    "Lastly, by inspecting the errors, we did observe that some stories themselves have ambiguous true labels, for instance in story 5 of the dev set the order [0, 4, 2, 3, 1] is equally plausible as the ‘true’ order [1, 4, 2, 3, 0] and could therefore be miss-classified even by humans.\n",
    "Based on the gradual but constant increase in performance that we observed during the model tunning phase (and what we have read in the literature) we have strong reasons to believe that with more fine-tunning and longer training, the full model has the potential to achieve a much higher level of accuracy.  \n",
    "\n",
    "### References:\n",
    "\n",
    "* L. Logeswaran,H.Lee, Dragomir Radev, “Sentence Ordering Using RNN”, ICLR, 2017\n",
    "* O. Vinyuals, S. Bengio, M. Kudlur, \"Order matters: Sequence to sequence models for sets\", ICLR 2016\n",
    "* T. Rocktaschel, E. Grefenstette, K.M. Hermann, T. Kocisky, P.Blunsom, \"Reasoning with entailment with neural attention\", ICLR 2016\n",
    "* Rafal Jozefowicz, Wojciech Zaremba, Ilya Sutskever,”Evolving Recurrent Neural Network Architectures”,JMLR 2015.\n",
    "* Wojciech Zaremba_Ilya Sutskever, Oriol Vinyals, , “Recurrent Neural Network Regularization”, ICLR 2015\n",
    "\n",
    "### Appendix A:\n",
    "\n",
    "##### Encoder attention mechanism, from [Logeswaran et al, ICLR2017]:\n",
    "\n",
    "$\\quad \\overline{ h_{enc}^{t}}, c_{enc}^{t} = LSTM( h_{enc}^{t}, c_{enc}^{t}) \\\\ \\\\\n",
    "    \\quad e_{enc}^{t,i} = f(s_i, \\overline{ h_{enc}^{t}}); i\\in{1,...,n} \\\\ \\\\\n",
    "    \\quad a_{enc}^{t} = Softmax( e_{enc}^{t})  \\\\ \\\\\n",
    "    \\quad s_{att}^{t} = \\sum  a_{enc}^{t,i}s_{i} \\\\ \\\\\n",
    "    \\quad { h_{enc}^{t}} = [\\overline{h_{enc}^{t}}, s_{att}^{t}]    \\\\ \\\\$\n",
    "\n",
    "** Where:**\n",
    "${ h_{enc}^{t}}, c_{enc}^{t}$: hidden state of LSTM, $e_{enc}^{t,i}$:encoder output, $ s_{att}^{t}$: attention readout vector, $f()$: scoring function, $[\\overline{h_{enc}^{t}}, s_{att}^{t}]$: concatenation of encoder hidden state and attention readout vector\n",
    "\n",
    "##### Sentence-by-sentence attention mechanism,  from [Rocktaschel et al, ICLR2016]:\n",
    "\n",
    "$ M_{t}= \\tanh (W^{y}Y+ (W^{h}h_{t} + W^{r}r_{t-1})\\otimes e_{L}) \\quad  M_{t}\\in\\mathbb{R^{k\\times L}}  \\\\$\n",
    "  \n",
    "  $\\alpha_{t}= softmax(w^{T}M_{t}); \\quad \\alpha_{t}\\in\\mathbb{R^{L}} \\\\ \\\\$\n",
    "  \n",
    "  $ r_{t}=Y\\alpha_{t}^{T}+\\tanh(W^{t}r_{t-1});\\quad r_{t}\\in\\mathbb{R^{k}}\\\\ \\\\$\n",
    "  \n",
    "  $ h^{*}=tanh(W^{p}r_{N}+W^{x}h_{N}; \\quad h^{*}\\in\\mathbb{R^{k}}\\\\ $\n",
    "  \n",
    " ** Where:**\n",
    " $M_{t}$:attention matrix, $W^{y}$, $W^{h}$, $W^{r}$: trained projection matrices, $e_{L}\\in\\mathbb{R^L}$: unit vector,\n",
    " $w^{k}\\in\\mathbb{R^{k}}$: trained parameter vector, $alpha$: attention weights, $r_{t}$: attention representation (corresponding to current sentence) \n",
    "\n",
    "### Appendix B: Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f228ef09d30>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3wAAAFfCAYAAAAVs86TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5Q6fmZmZmZlZSbnDZ2ZmZmZmVlL/AwO51yjG8cBAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f228eddd080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Results from the regularization exercize\n",
    "L2a_75 = [[0.50126380599999998, 0.51171999999999995, 0.518111557],[0.490903806, 0.50136000000000003, 0.51232758899999997],[0.47854380600000002, 0.48899999999999999, 0.49525619700000001],[0.45634380600000002, 0.46679999999999999, 0.52116193499999997]]\n",
    "L2a_100 = [[0.50534380599999995, 0.51580000000000004, 0.52766423200000001],[0.48926380600000002, 0.49972, 0.50878818599999998],[0.48634380599999999, 0.49680000000000002, 0.50287618300000003],[0.48290380599999999, 0.49336000000000002, 0.50129649799999998]]\n",
    "L2a_125 = [[0.49922380599999999, 0.50968000000000002, 0.51991874999999999],[0.500503806, 0.51095999999999997, 0.52067534900000001],[0.47218380599999998, 0.48264000000000001, 0.51013596299999997],[0.45226380599999999, 0.46272000000000002, 0.50480149200000002]]\n",
    "L2b_75 = [[0.51262380600000002, 0.52307999999999999, 0.53898509400000005],[0.50766380600000005, 0.51812000000000002, 0.52798265700000002],[0.47994380599999997, 0.4904, 0.50085657699999997],[0.45938380600000001, 0.46983999999999998, 0.47821305200000003]]\n",
    "L2b_100 = [[0.50138380599999999, 0.51183999999999996, 0.51763378999999998],[0.505503806, 0.51595999999999997, 0.52466218399999998],[0.481023806, 0.49147999999999997, 0.50400565399999997]]\n",
    "\n",
    "# L2a\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15,5))\n",
    "plt.suptitle('Regularisation Classifier Only', fontsize=20)\n",
    "\n",
    "bplot1 = axes[0].boxplot(L2a_75,vert=True,patch_artist=True)   \n",
    "axes[0].set_xlabel('Regularisation constant, R')\n",
    "axes[0].set_ylabel('Test Set Accuracy')\n",
    "axes[0].set_title('Word Embedding Size: 75')\n",
    "\n",
    "bplot1 = axes[1].boxplot(L2a_100,vert=True,patch_artist=True)  \n",
    "axes[1].set_xlabel('Regularisation constant, R')\n",
    "axes[1].set_ylabel('Test Set Accuracy')\n",
    "axes[1].set_title('Word Embedding Size: 100')\n",
    "\n",
    "bplot1 = axes[2].boxplot(L2a_125,vert=True,patch_artist=True)   \n",
    "axes[2].set_xlabel('Regularisation constant, R')\n",
    "axes[2].set_ylabel('Test Set Accuracy')\n",
    "axes[2].set_title('Word Embedding Size: 125')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f228c1d72e8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAFfCAYAAACMQoJKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naxEHVmZmZmYt8v/bnnniR4RAkgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f228f1b81d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# L2b\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
    "plt.suptitle('Regularisation Classifier + Attentive Embedder', fontsize=20)\n",
    "bplot1 = axes[0].boxplot(L2b_75,vert=True,patch_artist=True)   \n",
    "axes[0].set_xlabel('Regularisation constant, R')\n",
    "axes[0].set_title('Word Embedding Size: 75')\n",
    "bplot1 = axes[1].boxplot(L2b_100,vert=True,patch_artist=True)  \n",
    "plt.xlabel('Regularisation constant, R')\n",
    "axes[1].set_ylabel('Test Set Accuracy')\n",
    "axes[1].set_title('Word Embedding Size: 100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf4AAAH9CAYAAAD7+x6LAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXlclVX6wL+HVXAE7kVBQEBTMK00w1QU1xpzyVJJA3Mn\nfxqZWVNp2rhUY2bLZM04OVQqjfuSaO5lbqVpM7jklpossriwiBuynd8f7+XtXrhsCoJyvp/P/dz7\nnvU5zz3v+7xnF1JKFAqFQqFQ1A5sqlsAhUKhUCgUdw5l+BUKhUKhqEUow69QKBQKRS1CGX6FQqFQ\nKGoRyvArFAqFQlGLUIZfoVAoFIpahDL8ijuCEKKeEOJTIcRZIUSuECJfCNGquuWqCoQQC4UQBUII\nv+qW5VYRQsQJIX6vhHQKhBDbK0MmRekIIXYIIQqqWw5FzUcZfkWJmB7a+ZWU3AfAeOAwMAuYCaRW\nUto1DWn6lAshxAKTrguEEDNKCTfCLFxVG9Nq3eBDCNFcCPGZEOKIECJTCHFTCJEkhPhWCDFaCOFQ\nnfLVUCSgDL+iTOyqWwBFraEvcFJK+XR1C1KDyQVGCSFmSus7az1vCnNP37dCiGnANEAAe4HvgSuA\nJ9AFiALGAe2qS8YayjDAubqFUNR87ukHiKJG4Q3srG4hajAS+BboD/QCNpl7CiHuBzoBa4CBd1y6\nO4QQYgowA4gHBkkpf7ESpifwxh0WrcYjpTxX3TIo7g5UV7+iQggh/E1dzV+Zfi8TQlwUQtwQQhwQ\nQvQtEv4Hs3HHbta6qoXGOCHEfiHEFSHEVdPvcUIIYUWGAiHEdiGEpxDiCyHEOSFEnhBiuMm/cIzd\nXwgxXghx1CTfWSHEm2bpDBJC/GzK77ypa7mOlfz6CyG+FkKcNIW9KoT4RQjxkjX5boPFQDYwxorf\n/6G9HHxRUmQhhIMQYrIQ4rAQ4poQ4rIQYpcQYlApccYLIX416eecSQcupQkphAg3/a8ZpnjHhBBT\nb7f7XQjhD0wHcoA+1ow+gJRyK9DbSvzBpvJmCiGum/Qw2ZpchXMYhBB1hRB/F0IkmOLECiGeNoWx\nNZXrN1M5TwshXrSSVldTfZsmhOgghPjOJEOWEGKzECLIShwvU/g9QogUs6GMxUKIFtZ0Y3bfBQgh\nlpvqbL4QoospjNUxfqENEf0ohLhgKkeCSa7BVsI+IoRYbUo726SnfwohGloJq89lEUKMNen7hhAi\nVQgxv6x6pKg+VItfcas0BvYDZ4BowAg8C6wVQjwupSxs3S8AfkBrxcUBC03ucWZp/QcIBxLQunEl\nMACYh9bKHWYlfyOwD60LeDXa2OZ5k1/hGPtHQFdgPbAFeAr4m8kQZADvAd8Au4A/Ay+ivQwXfbi/\nB+Sb8ksCXIEewFygLTCiRC1VjExgJRAuhPCQUl4AzaCj6WAHcMpaRCGEPbAVrSv8OPAPtG7fZ4Dl\nQojWUsq3isSZC7wEJAPz0YYRngbaAw7ATSv5fAWMBBKBVSaZOwDvAD2EEH+WUt7qOPNowB5YIqU8\nXlpAKWVuEblmAZOBi2gvUFfRXg5mAT2FED2llHnmSZjy2gYYgLVoZQ4HVgkhnkCrB4+i9b7cBAYB\nnwohLkgpV1oRqwMwxZTmP4BmaL0zu016+dEsbBe0Xosf0PR4FQgAQoGnhBAdpZRHrOTRDPgZOIl2\n3zgBWWZlshgiMtPL78By4DLgZSrXM8AKs7BPmmTB9B0PBAEvmGQKkVLGF9GhRJu/05M/7rPuaC+v\nTYHHrZRBUd1IKdVHfax+0IxpfhE3/0J34K0ifj1Nft+WkNZ2K+7hJr8DgJOZu5PJLR8IsyYX2kuF\njZU0F5jC/A40NHN3RTMMV9FeEgLN/OyBo8ANoH6R9JqUoJ+FJjketZJ/PuBXTj0Xhu+B9qJTAEwy\n8w8zuYWhPUyL6RJ40+S+3lwnQH3grCn9DmbuwabwJwFXM3cH4KdC/RXJY6TJfSXgUMRvmimPl8rz\nv5egh+9MaYyuYD3tYMrnLNDAzN0GWGdKc3KROIU6WQvYm7mHmNJKQzOw9czrAdoLwH+LpNXVrE6+\nUMSvX6Gei7jXB+paKctDaC+zG0q5794pQQ8/UPx+vYT2Qu1oJbzR7HddU5lzgY5Fwr1uyntzCfdZ\nHOBTRO87TbK2rch/qT535lPtAqhPzf1QuuH/HRBW4sQBF0pIy5rh32Z6QDxmxa+HKd53VtIqZqDN\n/AsN6Ugrfl+a/KZb8Ss0Xp3LqZ9HTLIUfQG6ZcNvuj4GnDLz/970AHegZMN/CsgDAqykP9oU5wsz\ntyhTnsOthC80ZEUNfyya4XOxEscG7aVqX3n+9xL0cNQkU88K1tPCskRY8Qsw6eV0EfdCw9/YSpwz\nJr+uVvy2m3QgzNwK9XWyBPl+qGC9igGuA7ZmboX3XTJmLyrW8inidslUHocy8hxiSv9rK362aPd7\nPtDISr0dZSXOSFN6kRX5L9XnznxUV7/iVjkoTXd4ERLRWmDlpQ3aA8LaxL/CVkMbK35xUspLZaT9\nXytuyabv/1nxSzJ9NzJ3FEIY0bplewP3obWOCpGATxlyVJQo4EMhRHe01lo3YK6UMsfalAIhxJ/Q\nXgjOSSmtDQUUzqcw12Ph711Wwu9B07t5Hk5AKzTj/ooVOQSaQSw2Pn0HKCzLD0U9pJSnhBDngCZC\niHpSyitm3plSyjgr6SWjDWWVVEfsgIZAShG/3SXItwOta7+NeRihzYcZh9adXh/LoVdpcjuPJYdk\nkWGOMliMtoz2mBBiBdo9tVdKmVUk3COmPK3pMF8IsQttuKkNUHQSobX7LNH0baiArIo7hDL8ilsl\nswT3PCo2adQVSJeW46+A/sC5BDSwEq88ewBcLkG+svzsCx2EEK7AL2gtrv3AIiDdFNYNmAg4lkOW\nihCNNjb9PJrhh1Im9aHpEIobIoq4u1mJU9SwmOvdHAOacW+A1jNSEtZeBstLCnA/FX+RKk/5fdHK\nb274rdUBMNWDIi8JFn6Y1REziunSRCqa7grlRAjxMvB3tLq0De1/vs4f81taYb1eVXTvi4loLf5R\nwCS08f48IcRG4C9SyjOmcLdShwqx9iwo1JNtBeVV3AGU4VdUN5cBoxDCVkpZtJVpi9bqKdo6gTu3\nwcwYtNbfdCnlO+YeQogOaA/WSkVKmSaE+AZtYlgWWgvtWClRCg1YsZnXJryKhDP/7YnlREtzvSda\nCR8rpWxbagFunT1owzuPoXUjlxfz8p+14m+t/FWBZwnuDdHq62XQ9TsdzZi2kaZJnIUIITqWkkeF\n6r2pV+5TtEmJ9dHmMIQBg4GWQogHTD0It1KHFHcpajmforqJRauHXaz4dUVrMVjrSrxTNEV72K6x\n4tetCvONQmvx1Qf+XVpAKeVVtFadjxCiqZUgPUzf5nos7MbuaiV8Z4q01KSU19DG4B8QQlhr9VUG\nC9Aml4UKbd+CEimyRC/W9N3NSrimaEM3Z610b1c2ISW4dzd9F8pZH63l/JMVo18Xrdu90pFSXpJS\nrpVShqEN/zQFHjSTTWBdh7ZodQKsD38o7jKU4VdUN1+hPXDeM40jA/qY8mw0o/tlNckGWmu42ANR\nCNEGrdu0SnoepJQ/oC0/HIC2DKssvkK7nz8QQuj3tamV91eTnOat6IVo5ZoqhDCYha+DtnzRGh+j\nvYwsMA2BWCCEcDPp5ZaQ2lKxGaY8Nlpb/27Kpzew2cypsA69ZSpvYTgbtCWdgtKHSiqLgKLr/E17\nAnRBm6xZOL5/Aa1bP8hk6AvD2qG1zutTCQhtX4divQempZ/upsvrpu+1aMMO4UKI9kWivIK2omGb\nVJsE3ROorn5FtSKlXGp6OA4Cjgoh1qIZqf5oXezLpJTL7qBIRWetRaMtZ5orhOiBNns+AHgSbf+A\nsKoSREr5bQWCf4g2+fBp4JBpDNcZTa8NgPellD+Zpf2TEOIztIlfvwohVvHHOv50rIz1SikXCCEe\nASKBM0KILWhj00Y0w9AFzQhHVrSsZnm8Z9YVfkAI8RPaHIur/LFlbwDafIvCOHuFEHPQ/qfCslwz\n6eMBtAl1H96qTBVgM9qkzN7AIZOcA9BWoIw2k1cKIT5FG3M/IoSIQVux0R1tLsUPVE5vkhOwRwhx\nGq23Jx6og7Znxf1AjJTypEmma0KI0Wjr+ncKIVai/bdBaMt0k9EmIiruAVSLX1EW1lq0sgT3W4pj\n6np8EW3p0f8BY9GMz4tSyuduIf+SZCgPFvGklCloXbjfoq2xfxHwQ3sIvlmKLFU5B6FYnqZx2seB\nqSa/8cBwtHX64VLKKcUSkfJltA18MtH0Hoa2Wc3jaLvnFSuDlPIltLXpP6GNxb9iunYB3gc+KUvW\nMgsn5btoXdCfmdIdCbwG9AFOoxnRzkXiTEbbE+I3tNnnL2Hq0UBbHlhs8mgZct2K389oBtsBrZ48\ngbY3QWfzly4TbwF/QWtx/x/aC8J+tPMHEkrIo6L1/hraapRTaPs2TEDT0WW0+muxc5+Uch1aHd+A\nZuz/gvaCMA9tPX5cGfndiryKakBYX5FViRkI0QvtYWADfCmlfN9KmG5oM1ztgYtSyu7ljatQKBTV\niRCiK6bdKaWUb1e3PApFWVRpV79pjO0faC2DZLSuuxgp5QmzMK7AP9HeypMKx+jKE1ehUCgUCkXF\nqOqu/nZok1riTV2Ry9DGEM0ZAqyWUiaBNvO0AnEVCoVCoVBUgKo2/D5YrgU+R/HNOQLR1nH/ILTT\n3YZVIK5CoVDUBNR4tuKuoSbM6rdDW7faA20r1L1CiL0VSUAIoW44hUJR3bwthFBj/Io7hpTylo4F\nr+oWfxLaDOhCGvHHfuiFnAO2SCmzpZRpaHuHty5nXJ3qPvTgbvhMnz692mW4Gz5KT0pXSk9KVzX9\ncztUteE/ADQTQvibdtoKQzsm05wYIEQIYSuEcEY7C/x4OeMqKkBcXFx1i3BXoPRUfpSuyofSU/lR\nuqp6qrSrX2qHfYwHtvLHkrzjQoixmrf8t5TyhGkjkMNoJ4L9W5r2JbcWtyrlVSgUCoXiXqfK1/Hf\nCYQQ8l4oR1WzY8cOunXrVt1i1HiUnsqP0lX5UHoqP0pX5UMIgbzFMX5l+BUKhUKhuMu4HcNfE2b1\nVxmNGzcmPj6+usVQKBSK28Lf37/WjH2rFn/Vc08b/vj4+Nue/ahQKBTVjRC31LBTKKxyT3f1m7pC\nqkEihUKhqDzUs0xRlNvp6len8ykUCoVCUYtQhl+hUCgUNYYdO3ZUtwj3PMrwKxQKhUJRi1CGvxbT\nvXt3vvrqq+oWo0bSp08fvv766+oW466hSZMmbN++vVLSGjVqFNOmTSvR38bGht9//71S8lLUPNSM\n/qpHGX4rpKWlsXHjNhYuXM2ePT9x48aNSs+jcePGODs74+LiQr169XBxcWHChAmVns/dQlxcHLa2\ntrz44ovF/Io+6Hfu3Imvr2+l5T1z5kyGDx9u4bZx40aGDRtWQoxbJyYmhjZt2uDm5oaHhwePP/54\npSw5tVaG0oiPj8fGxgYXFxeLOrhy5crblqWqUTPcFYrb455ezmcNKSVnz57l8OETCCF4+OGW+Pn5\n6Q+TkydP8tFHMeTmPkKdOgHs2HGG9es/Z/LkkRgMBot0srOzsbe3x86u4moUQrBhwwa6d+9eaWW7\nU+Tn52Nra1tqmO7duzNz5ky6dOlSrjSjo6MxGo0sX76cTz75BHt7e92v6INeSnlXPvzPnDnDiBEj\nWLt2Ld26dePatWts3bq1TF1WFUIILl++fNfp8lZnt5en3iqqH7WOv+qpVS1+KSXLlsUwc+ZG1q93\nJSamHtOnx/DNN5uQUpKfn8/8+eupWzccf//H8fRsRePGA7h06VHWrNmqp3Pq1CnefvtzIiM/ITJy\nDkuXrr2lXoGSHmCLFi2ic+fOvP766xiNRpo2bcrmzZt1/4yMDEaPHo2Pjw/u7u4MHDhQ94uKiiIg\nIID69evTv39/UlJSdL9t27bRokULDAYDL730UrH8v/rqK1q2bIm7uzu9e/cmISFB97OxsWHevHkE\nBgYSGBhY4bKWRXR0NO+++y729vasX79ed+/atStSSlq1aoWLiwvR0dH06dOH5ORkvZWampqKlJLZ\ns2fTrFkzGjRoQFhYGJmZmcAfrdvo6Gj8/f3x8PBg1qxZAGzZsoVZs2axfPly6tWrR5s2bYA/hkFy\ncnIwGAwcO3ZMl+nSpUs4Oztz6dIlAL799lvatGmDwWAgJCSEI0eOWC3jwYMHue+++/SHWt26dRkw\nYACNGjUCqPQylIeS6uCoUaN48cUX6dOnD/Xq1aNz586cP3+eV155BaPRSMuWLTl06JBFnP379/PA\nAw/g7u5OREQEOTk5ul9pOoqNjSUoKAhXV1fCwsLIzs62SPeDDz7A29ubRo0asWDBAosXlZycHF57\n7TX8/f3x8vIiMjKSmzdvAn/0DM2ZMwcvLy9Gjx5dbr0oFPcytcrwnzx5ks2bU/DzG4uvbyf8/EJo\n1GgsMTGniYuLIzExkcxMV1xdLbuRvbweZe/e3ygoKCA+Pp7Zs2NIS/szfn6TadBgIlu22POvfy2p\n1HW2+/fvp0WLFqSlpfH6668TERGh+w0dOpQbN25w/PhxLly4wCuvvALA9u3bmTJlCqtWrSIlJQU/\nPz/CwsIAzViFhoYya9YsLl26RNOmTfnxxx/1NGNiYpg9ezZr167l4sWLdO7cmfDwcAuZYmJiOHDg\ngIURrAx2795NUlISYWFhDBo0iEWLFul+O3fuBODIkSNkZWUxfPhwNm3ahLe3N1euXCErK4uGDRvy\n6aefsm7dOnbv3k1ycjIGg4HIyEiLfH788UdOnTrFd999x9tvv83Jkyd54oknmDJlCs8++yxXrlwh\nNjbWIo6DgwOhoaEsXbpUd1uxYgXdunWjfv36xMbGEhERQVRUFOnp6YwdO5annnqK3NzcYuV85JFH\nOHHiBK+++io7duzg2rVrFv5VVYbSKK3Orly5klmzZpGWloaDgwPBwcG0bduWtLQ0QkND9XpXyJIl\nS9i2bRtnzpzh5MmTvPvuuwCl6ig3N5cBAwYwYsQI0tPTGTRoEKtXr9bT3Lx5Mx9//DHff/+9Xm5z\nJk2axOnTpzl8+DCnT58mKSmJt99+W/dPTU0lMzOThIQE/v3vf5dbL4rqQ7X2q55aZfgPHDiGo+Oj\n2Nr+0Y1sZ+eInV1bYmPLZ8w2bfoRO7seGI3NEEJgb++Mv38fDh/OrvBYbf/+/TEajRgMBoxGI19+\n+aXu5+/vz+jRoxFCMGLECFJSUrhw4QKpqals2bKF+fPn4+Ligq2tLZ07dwa0B29ERAStW7fG3t6e\n9957j3379pGQkMCmTZt48MEHGTBgALa2tkycOJGGDRvq+c2fP58333yTwMBAbGxsmDx5MgcPHiQx\nMVEPM2XKFFxdXXF0dCxX+cr7IlTYind1dWXIkCFs3rxZb02XN6358+fzt7/9DS8vL+zt7Zk2bRqr\nVq2ioKAA0Lq1Z8yYgYODA61ataJ169bFWqwlER4ebmH4lyxZwnPPPQdoPSzjxo2jbdu2CCEYNmwY\njo6O7Nu3r1g6TZo0YceOHSQnJ/Pss8/SoEEDRo0axfXr16u8DNaQUtKgQQOLOnjy5Endf8CAATz8\n8MM4ODgwYMAAnJyceO655xBC8Oyzz3Lw4EGL9F566SW8vb1xc3Nj6tSpus5K09G+ffvIy8tjwoQJ\n2NraEhoayqOPPqqnuXLlSkaNGkWLFi1wcnJixowZFnUhKiqKv//977i6ulK3bl0mT55s8V/Z2toy\nc+ZM7O3ty11vFYp7nVpl+PPzCxCi+BifELbk5xfg6+uLm9tlLl9OtPBPSTlAcLBmEM+cuYCbW5Mi\n8QVCNObChQsVkicmJob09HQyMjJIT0+3aNWbG2UnJycArl69SmJiIkajERcXl2LpJScn4+/vr1/X\nrVsXo9FIUlISycnJxSbEmV/Hx8fz8ssvYzQaMRqNuLu7I4QgKSlJD1PYJV0ShcbDYDCwZ88e+vXr\np7vNmTPHapzs7GxWrlzJkCFDAOjQoQO+vr4sWbKk1LyKEh8fz4ABA3T5W7Zsib29PefPn9fDeHp6\n6r+dnZ25evVqudLu3r07N27c4MCBA8THx3Po0CH69++v5/vRRx/p+RoMBs6dO0dycrLVtNq1a8ey\nZcs4f/48u3fvZteuXfztb3+r8jJYQwhBWlqaRR1s3ry51bycnJyKXRfN27x++Pv76zooTUfJycn4\n+PhYpGNeh4vWW3O/ixcvcv36dYKCgvS0e/fuTVpamh6mQYMGFvNFFDUftY6/6qlVhj8oqDk3bvwP\nKQt0t4KCPHJzY2ndujm2traMHduPa9eWkpDwHefPHyY+/hvq1z/AwIE9AfD2duPq1RQrqafi5uZW\nIXluZWjA19eX9PR0srKyivl5e3tb9Dpcu3aNtLQ0fHx88PLyshizByxa876+vsyfP5/09HTdEFy9\nepUOHTroYcqaBFZoPDIyMujcuTMbNmzQ3d544w2rcb755huysrKIjIzEy8sLLy8vkpOTLbr7i2JN\nDj8/PzZt2mQh/7Vr1/Dy8ipV5vKUy8bGhsGDB7NkyRKWLl3Kk08+Sd26dQFNb1OnTi2mt2effbbM\nfIOCghg4cCC//vprlZehJCpzeMq8PsXHx+Pt7Q2UriMvLy+Ll0vAop56eXkVS7ewrPXr18fZ2Zmj\nR4/qaWdmZnL58mU9/N02cVGhuBPUKsP/wAMP0KlTHc6eXcj584dJTT1IXNwCevRwJyAgAIDmzZvz\n3nsRPPOMpH37U0REeDJjxjh9Rn+vXu25cuU7rl/XWhVSFpCUtBc/v+s0a9asysvQsGFDevfuTWRk\nJJmZmeTl5bF7925A65JesGABhw8f5ubNm0yZMoUOHTrg5+dH3759OXbsGGvXriU/P5+5c+eSmpqq\npztu3DhmzZqlj99fvnyZVatW3bKcUspyGZVFixYRERHBkSNHOHToEIcOHWLPnj0cPHiQo0eP6mU2\nX87n6elJWlqaxcvP2LFjmTJlim40Ll68yLp16yzkKQlPT0/i4uJKDRMeHs7y5ctZsmSJ3jsBMGbM\nGD7//HP2798PaC9bGzduLDZ+D9r4/BdffMHFixcBOHHiBOvWrSM4OPiOlKEo5f2PSotvzj//+U+S\nkpJIT09n1qxZ+vyS0nQUHByMnZ0dn332GXl5eaxZs0YPBzB48GAWLlzI8ePHuX79usX4vRCCMWPG\nMHHiRF2nSUlJbN26FcXdixrjr3pqleG3sbHh+efDeO21tgQFnaBdu1O88UYww4aFWrQM3N3d6dPn\nz4wcGUpISEe9qx2gRYsWvPBCB27c+JKEhPkkJHxC8+bHmDhxKDY2FVNnv3799HXULi4uhIaGlhjW\nXL6vv/4aOzs77r//fjw9PZk7dy4Ajz32GO+88w4DBw7Ex8eHs2fPsmzZMr1MK1euZNKkSdSvX58z\nZ84QEhKip9m/f38mT55MWFgYbm5utGrVymIlQUVbTuUJn5yczPbt23nllVfw8PDQP4888gi9e/fW\nW/3Tp09n+PDhGI1GVq1aRfPmzQkPD+e+++7DaDSSmprKyy+/zNNPP03Pnj1xdXWlY8eOFgakqDzm\n14MGDUJKibu7O23btrUavl27dtStW5eUlBR69+6tuwcFBREVFcX48eMxGo0EBgaW2Fvh5ubGunXr\neOihh3BxcaFPnz6Ehoby+uuvA1R6GV544YVikwOLxjcYDBbr+D/55JMSw1uLb/57yJAh9OzZk2bN\nmhEQEMDUqVPL1JG9vT1r1qxhwYIFeh01vw969erFxIkT6dGjB4GBgTz22GMWMrz//vs0a9aMDh06\n4ObmRs+ePfntt9/KXQaFojaiTue7RXJzczl//jxOTk64u7tXSR4KhUIBtet0PrWOv3zczul8tW4D\nn8rC3t6+zMluCoVCoVDUNFSLX6FQKGo46lmmKMrttPhr1Ri/QqFQKBS1HWX4FQqFQlFjUOv4qx5l\n+BUKhUKhqEWoMX6FQqGo4ahnmaIoaoxfoVAoFApFuVCGX6FQKBQ1BjXGX/Uow1+LKTxzXlG9PPjg\ng+zatau6xbhrsLGxsdjC+Xa4nXugtLjx8fHY2NjoJysqFDUJZfitkJaWxraNG1m9cCE/7dnDjRs3\nKj2Pxo0b4+zsbLFd6oQJEyo9H0VxduzYgY2NDR988IGFu7WH9aJFi/RjjyuDUaNGMW3aNAu3X3/9\nlS5dulRaHoV8+eWXtGjRAldXV7y8vHjyySetniFQUayVoTR27tyJra2tvjV1YX3/+eefbyn/u+Xg\nnbtFzpqG2rWv6ql1O/dJKTl79iwnDh9GCEHLhx/Gz89Pv0lPnjxJzEcf8UhuLgF16nBmxw4+X7+e\nkZMn6wf1FKaTnZ2Nvb09dnYVV6MQgg0bNtC9e/dKK9udIj8/H1vb4scbm9O9e3dmzpxZJQbtdomO\njsbd3Z3o6Gh9n3zQ/tOik6gK3e42du7cydSpU9m6dSutWrUiMzOT9evXV5s8Pj4+xU6HvFXu9Ulu\n5bm/FIrboVa1+KWUxCxbxsaZM3Fdv556MTHETJ/Opm++QUpJfn4+6+fPJ7xuXR7396eVpycDGjfm\n0UuX2LpmjZ7OqVOn+Pztt/kkMpI5kZGsXbr0lnoFSnqAFbYyX3/9dYxGI02bNrU4MCcjI4PRo0fj\n4+ODu7s7AwcO1P2ioqIICAigfv369O/fn5SUP44Q3rZtGy1atMBgMPDSSy8Vy/+rr76iZcuWuLu7\n07t3b4sHtY2NDfPmzSMwMJDAwMAKl7Ukdu7cia+vLx9//DGenp74+PiwcOFC3T8rK4vhw4fj4eFB\nkyZN9LPry6Mna1y/fp1Vq1bxz3/+k1OnTvG///1P9+vatSugHabj4uLCvn37eOGFF9i7dy/16tXD\naDQCkJOTw2uvvYa/vz9eXl5ERkZy8+bNMssTFRXF4sWLmTNnDi4uLjz99NMANGnShO3bt5OSkoKz\nszOZmZm6TLGxsTRo0ID8/Hyg9P/InF9++YWOHTvSqlUrvUzDhg3TjxOu7DLcDt27d+evf/0rnTp1\nol69ejw5U8gUAAAgAElEQVT99NOkp6czdOhQXF1dad++fbFybtiwgaZNm+Lh4VHsyOfSdHQ790Bp\ncQsKCnjttddo0KABzZo1Y8OGDRbpZmVl8fzzz+Pt7Y2vry9//etf9fiLFi0iJCSEV199lfr16zNz\n5szbU+hdjhrjr3pqleE/efIkKZs3M9bPj06+voT4+TG2USNOx8QQFxdHYmIirpmZ+Lq6WsR71MuL\n3/bupaCggPj4eGJmz+bPaWlM9vNjYoMG2G/ZwpJ//atSWyL79++nRYsWpKWl8frrrxMREaH7DR06\nlBs3bnD8+HEuXLjAK6+8AsD27duZMmUKq1atIiUlBT8/P/1o1EuXLhEaGsqsWbO4dOkSTZs25ccf\nf9TTjImJYfbs2axdu5aLFy/SuXNnwsPDLWSKiYnhwIED+tG9lUVqaipXrlwhOTmZL774ghdffFE/\nU338+PFcuXKFuLg4duzYQXR0NAsWLCiXnqyxevVq6tWrx6BBg+jZs6fFSXqF4+xZWVlkZWXRoUMH\nPv/8c4KDg7ly5Qrp6ekATJo0idOnT3P48GFOnz5NUlKSxXGxJZVnzJgxPPfcc7zxxhtkZWURExNj\nIZuXlxcdO3Zk9erVutvSpUsZNGgQtra25fqPCmnfvj1btmxhxowZ/PTTT+Tk5Fj4V1UZbpXly5ez\nePFikpOTOX36NB07diQiIoKMjAzuv//+YsZw7dq1/O9//+N///sfMTEx+lh7aTq6nXugrLj//ve/\n2bhxI4cOHeKXX34pdqT1iBEjcHBw4Pfffyc2NpZt27bxxRdf6P4///wzzZo148KFC/qphgpFlVF4\nJvfd/NGKUZyi7qujo+WBMWOknD7d4vPj6NHy29Wr5dmzZ+W/R40q5p89dap8OyJC5ufny8X/+pf8\n7//9n4V/wbRp8h8jRsizZ89alcMajRs3lvXq1ZMGg0G6ublJg8Egv/jiCymllAsXLpQBAQF62OvX\nr0shhDx//rxMSUmRtra28vLly8XSjIiIkJMmTdKvr169Kh0cHGR8fLyMjo6WwcHBFuEbNWokv/zy\nSymllL1795ZfffWV7pefny+dnZ1lQkKClFJKIYTcsWNHucvXrVu3coXfsWOHdHZ2lvn5+bqbh4eH\n/Pnnn2V+fr50cHCQJ06c0P3mz58vu3fvLqW0ricbGxt5/vz5EvN7/PHH5auvviqllHLp0qXSw8ND\n5uXlSSmljIuLkzY2NhayLFy4UHbu3Nkijbp168rff/9dv/7pp59kkyZNyiyPlFKOHDlS/vWvf7VI\nr3HjxvL777+XUkr5xRdfyB49euh+vr6+cs+ePVLKsv+jomzevFk+9dRT0mAwyHr16slXX31VFhQU\nVEkZSmPHjh3SxsZGGgwGi/p+/fp1KaVWV2bNmqWH/8tf/iL79OmjX69fv162adNGvxZCyK1bt+rX\n8+bNk48//niZOrqde6CsuD169JDz58/X/bZu3arXpdTUVOno6Cizs7N1/6VLl1rUY39//1J1WNIz\nTlF7MdWJW7KZtarFX5Cfj62V8VpbISjIz8fX15fLbm4kmlqbhRxISSEwOBgbGxsunDlDEzc3C38h\nBI2F4MKFCxWSJyYmhvT0dDIyMkhPT7dorTZs2FD/7eTkBMDVq1dJTEzEaDTi4uJSLL3k5GT8/f31\n67p162I0GklKSiI5ORlfX1+L8ObX8fHxvPzyyxiNRoxGI+7u7gghSEpK0sOUdRqhwWDAaDRiMBjY\ns2cP/fr1093mzJlTYjx3d3dsbP6ois7Ozly9epVLly6Rl5eHn5+f7ufv728hU1E9SSm5evUqe/bs\n0SeRPfTQQwAkJibyww8/MGTIEACeeuopbty4UaxbtjQuXrzI9evXCQoK0nXVu3dv0tLSyixPeQgN\nDWXfvn2cP39enxTXqVMnoHz/kTlPPPGEXsdiYmJYuHAhX3zxRZWXwRo+Pj6kp6db1PfCeg3g6emp\n/3Zycip2XTRv87ro7+9PcnIyULqObuceKCtuUX/z+zAhIYHc3Fy8vLz0+2PcuHFcunTJaloKRVVT\nqyb3NQ8KYv/27bSWEhvTC0BeQQGxubn0aN0aW1tb+o0dy9KPPuKRy5fxcHTkTHY2cR4ejDSNo7t5\ne5Ny+jQGs4cWQCoQUOSFoCzkLQwN+Pr6kp6eTlZWVjHj7+3tTXx8vH597do10tLS8PHxwcvLq9g4\naWJiokW6b731Voldx1D2LOWMjAz9d48ePZg5c+ZtzYivX78+9vb2xMfHc//99wPaw9nHx6fMuCEh\nIVy5csXC7euvv0ZKSb9+/XTd37x5k0WLFvHUU09ZLV9Rt/r16+Ps7MzRo0fx8vKqcJnK0qGbmxs9\ne/Zk2bJlHD9+XB+qAfDz8yvzPyqJ7t2706NHD3799Veef/75Ki3DnSAxMZEWLVoAWp3w9vYGSq/H\nv/322y3fA2XF9fLysrg2vw99fX2pU6cOaWlpJequJui0prBjxw41s7+KqVUt/gceeIA6nTqx8OxZ\nDp8/z8HUVBbExeHeowcBAQEANG/enIj33kM+8wyn2rfHMyKCcTNm6DP62/fqxXdXrpB2/ToABVKy\nNymJ635+NGvWrMrL0LBhQ3r37k1kZCSZmZnk5eWxe/duAMLDw1mwYAGHDx/m5s2bTJkyhQ4dOuDn\n50ffvn05duwYa9euJT8/n7lz55KamqqnO27cOGbNmqWP31++fLnYOGVFkH8Mw9wyNjY2DBo0iKlT\np3L16lXi4+P5+9//zrBhw24pvejoaGbMmMHBgwc5dOgQhw4dYtWqVWzYsIGMjAwaNGiAjY0NZ86c\n0eN4enpy7tw5cnNzAe0BPWbMGCZOnMjFixcBSEpKYuvWreWSwdPTs8w16OHh4URHR7N69Wq9dwJg\n7Nix5f6P1q1bx/Lly/WJgvv372fnzp0EBwffkTIU5XbrQlE++OADMjMzSUxM5NNPP9VfkEqrx7dz\nD5QVd/DgwXz66ackJSWRkZHB+++/r/s1bNiQnj178sorr3DlyhWklPz+++9q7wZFtVGrDL+NjQ1h\nzz9P29de40RQEKfatSP4jTcIHTbM4o3b3d2dP/fpQ+jIkXQMCbHokmzRogUdXniBL2/cYH5CAp8k\nJHCseXOGTpxo0TVaHvr166evbXZxcSE0NLTEsObyff3119jZ2XH//ffj6enJ3LlzAXjsscd45513\nGDhwID4+Ppw9e5Zly5bpZVq5ciWTJk2ifv36nDlzhpCQED3N/v37M3nyZMLCwnBzc6NVq1YWM+Qr\n2iK5nRaMedzPPvsMZ2dn7rvvPrp06cLQoUMZNWpUhfP9+eefSUhIIDIyEg8PD/3Tr18/AgICWLp0\nKU5OTkydOpVOnTphNBrZv38/PXr04IEHHqBhw4Z4eHgAMHv2bJo1a0aHDh30Fvpvv/1WLpkiIiI4\nevQoRqNRX41RVOannnqKU6dO4eXlpQ9TQNn/kTkGg4GoqCgCAwNxdXVl+PDhTJo0STeQ77//fqWW\noU+fPsyePbvE+CkpKcXW8X/zzTdWy18WQgiefvppgoKCeOSRR+jXrx+jR48uU0e3cw+UFXfMmDE8\n8cQTtG7dmrZt2xa7l6Ojo8nJyaFly5YYjUYGDRpk8eKg+APV2q961CE9t0hubi7nz5/HyckJd3f3\nKslDoVAoQB3SoyiOOqSnGrC3t6dRo0bK6CsUCkUlotbxVz3K8CsUCoVCUYtQXf0KhUJRw1HPMkVR\nVFe/QqFQKBSKcqEMv0KhUChqDGqMv+pRhl+hUCgUilqEGuNXKBSKGo56limKosb4FQqFQqFQlAtl\n+BU6S5YsoVevXtUtxl3DzJkzb3n74KLs3Lmz1INaRo0axbRp0yolL4WiJqPG+KseZfitkJaWxsbN\nG1m4ZCF7ftzDjRs3qiyvbt26YTQa9b3gC7H2oG/SpAnbt2+vlHzj4+OxsbGhoKBAdxsyZEiJW8De\nDklJSTzzzDM0aNAAg8FAq1atiI6Ovu10rZWhLLp164aTk5PFVslPP/30LctQmYerqINaFArFnaDK\nT+cTQvQCPkF7yfhSSvl+Ef+uQAxQeOrHGinluya/OOAyUADkSinb3a48UkrOnj3L4aOHEULw8EMP\n4+fnpz90T548yUcLPiLXI5c6rnXYsWsH67evZ/L4yfpBPYXpZGdnY29vj53drakxPj6ePXv24Obm\nxrp160rdq7+ykVLesXHDYcOG0aZNGxITE3FwcODIkSOVsk/5rZRBCMG8efNK3e//XiI/Px9bW9vq\nFkOhKDdqr/6qp0pb/EIIG+AfwBPAA0C4EOJ+K0F3SSkfMX3eNXMvALpJKdtUltFftmoZM6Nmsj5u\nPTFnY5j++XS+Wf8NUkry8/OZv2Q+dR+pi/8j/ng29aRxcGMuuV1izbdr9HROnTrF2x+9TeRfI4mc\nEsnSlUtvqVcgOjqa4OBgRo4cycKFC3X3qKgoFi9ezJw5c/QW6fDhw0lISNAP9vnwww8B2LdvH506\ndcJgMNCmTRt27typp9O9e3emTZtGSEgILi4u9OrVi/T0dAC6du0KaMfAuri48PPPP7No0SL9GN3I\nyEhef/11C3n79+/PJ598AmiHrjzzzDN4eHjQtGlTPvvssxLLeeDAAUaMGEGdOnWwsbGhdevWPPHE\nE7p/ZZahPJT0olDY3f7BBx/g6emJj48PMTExbNq0iebNm1O/fn3ee+89izg3btwgLCwMFxcX2rZt\ny+HDh3W/0nSUnZ3NyJEjMRqNPPjggxw4cMAi3djYWIKCgnB1dSUsLIzs7GwL/2+//ZY2bdpgMBgI\nCQnhyJEjul+TJk2YM2cOrVu35k9/+lOFekQUCsW9T1V39bcDTkkp46WUucAywFq/akl9nIJKlPHk\nyZNsjt2M32N++D7ki99DfjTq3oiYn2KIi4sjMTGRTJmJq4erRTyv5l7sPbiXgoIC4uPjmf3lbNK8\n0vDr60eDHg3YcnYL//rqXxVuPUdHRzN06FCGDBnCli1b9CNSx4wZw3PPPccbb7xBVlYWMTExREdH\n4+fnx7fffktWVhavvfYaycnJPPnkk0ybNo2MjAw+/PBDQkNDSUtL0/NYunQpixYt4uLFi9y8eVN/\nYSg8EjQrK4usrCzat28P/NHdHB4ezooVK/R0MjMz2bp1K+Hh4fqZ9m3atCElJYXvv/+euXPnsm3b\nNqvlDA4OJjIykuXLl1ucWQ5USRluh9TUVHJyckhOTmbmzJmMGTOGxYsXExsby65du3jnnXcszlpf\nt24dzz77LBkZGYSHh9O/f3/y8/PL1NGMGTM4e/YsZ8+eZcuWLSxatEhPMzc3lwEDBjBixAjS09MZ\nNGgQq1ev1v1jY2OJiIggKiqK9PR0xo4dy1NPPWUxXLRs2TI2bdpEZmZmhU+NVCiqEzXGX/VU9RPB\nBzB/0p8zuRUlWAhxUAixQQjR0sxdAtuEEAeEEGNuV5gDBw/g6O+Ird0fXZ92DnbYNbIj9nBsudLY\ntH0TdvfZYfQxIoTAvo49/o/6czjpsIVBKIs9e/aQkJDA4MGDeeSRR2jWrBlLliwpM575y8V//vMf\n+vbtq7eeH3vsMdq2bcvGjRv1MKNGjaJp06Y4OjoyePBgDh48WGJ65nTu3BkhBHv27AFg1apVdOzY\nEU9PT/bv38+lS5eYOnUqtra2NG7cmOeff14/ArgoK1eupEuXLrz77rvcd999tGnThv/+979VXoaS\neOmllzAajRgMBoxGI9OnT9f9HBwcmDJlCra2toSFhXHp0iUmTpyIs7MzLVu2pGXLlhw6dEgPHxQU\nxIABA7C1teXVV1/l5s2b7Nu3jwMHDpSqo5UrV/LWW2/h6uqKj48PEyZM0NPcu3cveXl5TJgwAVtb\nW0JDQ3n00Ud1/6ioKMaNG0fbtm0RQjBs2DAcHR3Zt2+fHubll1/G29sbR0fHCulGoVDc+1T5GH85\n+C/gJ6W8LoToDawFAk1+naSUKUKIBmgvAMellHusJTJy5EgaN24MaF2/Dz/8cLEw+QX5CJvinQvC\nRpCfn4+vry9uwo3LFy5btPpTTqbQ8eGO2NjYcCbxDG5t3CzjC4EwCC5cuKDLUBbR0dH07NlTnzcQ\nHh7OokWLePnll8sVH7Q5AitWrGD9+vWAZgDz8vJ47LHH9DANGzbUfzs7O3P16tVyp//ss8+ydOlS\nQkJCWLJkiT6DPSEhgaSkJIxGo55vQUEBXbp0sZqOq6srs2bNYtasWaSnp/OXv/yF/v37k5iYWOVl\nsMZnn32mn99eFHd3d73Xw8nJCQAPDw/d38nJySJ/85n4Qgh8fHxITk4GKFVHycnJNGrUSI/r7++v\n/05JScHHx/L92Nw/Pj6e6OhofehASklubq6eL2CRtuLeorBFXDgWfq9dF7rVFHlqynXh77i4OG6X\nqjb8SYCf2XUjk5uOlPKq2e9NQoh5QgijlDJdSplicr8ohPgGbejAquE3HyMviaCHgti+YjuyqdRf\nAAryC8hNyqX1462xtbVl7JCxfLTgIy57XsbRxZHsi9l45HowcOhAALwbeHM67TRO9ZwsE7+qvXCU\nh+zsbFasWEFBQQFeXl4A5OTkkJmZyZEjR3jooYeszvAu6ubr68vw4cOZP39+ufItLS1rhIeH88QT\nTzBp0iR+/vln1q5dq+d73333cfLkyQrnazQaee2114iOjiYjI6PKy1DVmA9dSCk5d+4c3t7e2Nra\nlqojb29vEhMTadGiBYBFb5GXlxdJSRa3CQkJCTRr1gzQ9D916lTefPPNEuWqCbpRVA1FJ7+p69pz\nbf7bfHiwolR1V/8BoJkQwl8I4QCEAevMAwghPM1+t0PbTTBdCOEshPiTyb0u0BP49XaEeeCBB+h0\nXyfO7jjL+TPnST2dStwPcfRo2YOAgAAAmjdvznuvv8czLZ6hvVN7IjpHMOO1GXrLvFe3Xlw5cYXr\nl68DIAskSceS8HPy0x/MZfHNN99gZ2fH8ePHOXToEIcOHeL48eOEhIToy9w8PT35/fffLeI1bNjQ\nwm3o0KGsX7+erVu3UlBQQHZ2Njt37rRo+ZVEgwYNtB6MM2dKDPPwww/j7u7O888/T69evXBxcQGg\nXbt21KtXjzlz5pCdnU1+fj5Hjx7ll19+sZrO5MmTOXr0KPn5+Vy5coV58+bRrFkzDAZDlZehqvnv\nf//L2rVryc/P5+9//zt16tShQ4cOZepo0KBBvPfee2RmZnLu3Dn+8Y9/6GkGBwdjZ2fHZ599Rl5e\nHmvWrGH//v26/5gxY/j88891t2vXrrFx40auXbt2ZwuvUFQBaoy/6qlSwy+lzAfGA1uBo8AyKeVx\nIcRYIcT/mYI9I4T4VQgRi7bs71mTuyewx+S+D1gvpdx6O/LY2Njw/PDnee2Z1whyCKJdnXa8EfYG\nw8KHWbSQ3N3d6dOrDyOHjCSkU4je5QvQokULXuj/Ajf23yDh+wQStibQvKA5E8dOLPckqujoaEaP\nHo2Pjw8eHh76Z/z48SxevJiCggIiIiI4evQoRqORgQO13obJkyfzzjvvYDQa+fjjj2nUqBExMTHM\nmjWLBg0a4O/vz4cffqjP4i6t1efk5MTUqVPp1KkTRqPRwrCYM2TIEL7//nuee+45Cz1+++23HDx4\nkCZNmuDh4cGYMWPIysqymsb169cZMGAABoOBZs2akZiYyLp12vtfZZdhz549+gtKSYwfP15fw1+v\nXj2L8fOiFM2/6PXTTz/N8uXLMRgMLF68mG+++QZbW9sydTR9+nT8/Pxo0qQJvXr1Yvjw4Xqa9vb2\nrFmzhgULFuDu7s7KlSstlnoGBQURFRXF+PHjMRqNBAYGWrz9q9a+QqEoDbVX/y2Sm5vL+fPncXJy\nwt3dvUryUCgUClB79SuKczt79SvDr1AoFDUc9SxTFEUd0qNQKBSKewI1xl/1KMOvUCgUCkUtQnX1\nKxQKRQ1HPcsURVFd/QqFQqFQKMqFMvwKhUKhqDGoMf6qRxl+hUKhUChqEWqMX6FQKGo46lmmKIoa\n46/lvPDCC/ztb38rV9hRo0Yxbdq0KpOlqtOvLLp3785XX31V3WIoFArFHUcZfiukpaWxbeM2Vi9c\nzU97fuLGjRuVmv7s2bPp06ePhVtAQAB9+/a1cAsMDGTFihVlpvevf/2LqVOnVopsNjY2xc4IqCwW\nLVqEnZ2dvl1u06ZNGT16NKdOnaqS/BQKxd2HGuOvemqd4ZdS8vvvv7Nx7UY2xWwiPj7eogvt5MmT\nfPnml4iVgoCfAzj/xXk+n/E5GRkZxdK5ceMGeXl5FZahS5cu7N27V883NTWVvLw8YmNjLdzOnDlT\n4lG3VUVV7/PesWNHsrKyuHz5Mt999x1OTk4EBQVx7NixKs23ssjPz69uERSKGkVOTg5paWnk5ORU\ntyiKclKrDL+UkphlMWycuRHX9a7Ui6lHzPQYNn2zCSkl+fn5rJ+/nvC64Tzu/zitPFsxoPEAHr30\nKFvX/HE+0KlTp/j87c/5JPIT5kTOYe3StRXqFXj00UfJycnh4MGDAOzevZvu3bvTvHlzC7emTZvq\nZ9GfOHGCnj174u7uTosWLVi5cqWeXtHu9Tlz5uDt7U2jRo348ssvi7Xi09PTefLJJ3FxcSE4OJiz\nZ88C0LVrV6SUtGrVChcXFz2Pb7/9ljZt2mAwGAgJCeHIkSN6WrGxsQQFBeHq6kpYWBjZ2dnl0oEQ\ngiZNmvDPf/6Trl27MmPGDN1v3759dOrUCYPBQJs2bdi5c6ful5GRoR9w5O7urh9gBBAVFUVAQAD1\n69enf//+pKSk6H7btm2jRYsWGAwGXnrppWLjpV999RUtW7bE3d2d3r17k5CQoPvZ2Ngwb948AgMD\nCQwMLFf5FIp7nYKCAtZvXM+EaRN4/aPXmTBtAus3rtcP2LpVih5Lq6h8apXhP3nyJCmbUxjrN5ZO\nvp0I8QthbKOxnI45TVxcHImJibhmuuLr6msR71GvR/lt728UFBQQHx9PzOwY/pz2Zyb7TWZig4nY\nb7Fnyb+WlHvyjb29Pe3bt2fXrl0A7Nq1iy5duhASElLMDbTT7Xr27MnQoUO5dOkSy5YtIzIykhMn\nThRLe/PmzXzyySds376d06dPs2PHjmKt+OXLlzNz5kwyMzNp2rSpPkxQaGCPHDlCVlYWgwYNIjY2\nloiICKKiokhPT2fs2LE89dRT5Obmkpuby4ABAxgxYgTp6ekMGjSI1atXV+Af0Rg4cCC7d+8GICkp\niSeffJJp06aRkZHBhx9+SGhoKGlpaYB2FPGNGzc4fvw4Fy5c4JVXXgFg+/btTJkyhVWrVpGSkoKf\nnx9hYWEAXLp0idDQUGbNmsWlS5do2rQpP/74o55/TEwMs2fPZu3atVy8eJHOnTsTHh5uIWNMTAwH\nDhy4a3omFIqqZsPmDazYvwJDFwN+Pf0wdDGwYv8KNmzeUN2iKcqgVhn+YweO8ajjo9jb2utujnaO\ntLVry7HY8j3Qf9z0Iz3setDM2AwhBM72zvTx70P24Wzi4+PLLUvXrl11I7979246d+5sYfh3795N\n165dAa3F3aRJE4YPH44QgtatWxMaGmrR6i9k5cqVjBo1ivvvv586depYtKQLGTBgAEFBQdjY2PDc\nc8/pvQyFmL/AREVFMW7cONq2bYsQgmHDhuHo6Mi+ffvYt28feXl5TJgwAVtbW0JDQ0s94rYkvL29\nSU9PB2Dx4sX07duXJ554AoDHHnuMtm3bsnHjRlJTU9m8eTPz58/HxcUFW1tbOnfuDMCSJUuIiIig\ndevW2Nvb895777Fv3z4SEhLYtGkTDz74IAMGDMDW1paJEyfqPSkA8+fP58033yQwMBAbGxsmT57M\nwYMHSUxM1MNMmTIFV1dXHB0dK1w+heJeIycnhw27NtCoXSMcnbV7wtHZkUbtGrFx98bb6vZXY/xV\nT60y/AX5BdgK22LutsKWgvwCfH19uex2mcTLiRb+B1IOEBisGYULZy7QxK2Jhb8QgsaiMRcuXCi3\nLF26dGHPnj1kZGTordCOHTvy008/kZGRwa+//qq3+OPj49m3bx9GoxGj0YjBYGDJkiWcP3++WLrJ\nycn4+v7RY+Hr61usJ8Lc6Dk7O3P16tUS5YyPj+ejjz6yyPvcuXMkJyeTnJyMj4+PRXh/f/9y66CQ\npKQkjEajnt+KFSss8vvxxx9JSUkhMTERd3d3XFxcrJbbPO+6detiNBpJSkoqphPA4jo+Pp6XX35Z\nz9Pd3R0hBElJSXqYRo0aVbhcCsW9ypUrV8ixydGNfiGOzo7cFDe5cuVKNUmmKA921S3AnaR5UHP2\nb99Pa9kaG6G98+QV5BGbG0uP1j2wtbWl39h+LP1oKY9cfgQPRw/OZJ8hziOOkQNHAuDm7UbK6RQM\nTgaLtFNJJcAtoNyyBAcHk5mZSVRUFJ06dQKgXr16eHt7ExUVhY+Pj27IfH196datG1u2bCkzXS8v\nL86dO6dfJyQk3NaEPV9fX6ZOncqbb75ZzG/Xrl0WxrEwv2bNmlUojzVr1ugvOb6+vgwfPpz58+cX\nC5eamkp6ejpZWVnFjL+3t7dFj8u1a9dIS0vDx8cHLy8vizF7wKI17+vry1tvvVWse9+cqp70qFDc\nTdSrVw+HAgduXr9pYfxvXr+Jo3SkXr16t5y2GuOvempVi/+BBx6gTqc6LDy7kMPnD3Mw9SAL4hbg\n3sOdgADNaDdv3pyI9yKQz0hOtT+FZ4Qn42aMw2DQDH37Xu357sp3pF3XxpwLZAF7k/Zy3e96hQxe\nnTp1aNu2LR9//LHeXQ3QqVMnPv74Y4vZ/E8++SS//fYb//nPf8jLyyM3N5dffvmFkydPFkt38ODB\nLFiwgBMnTnD9+nXefffdCumoYcOGFhMBx4wZw+eff87+/fsBzaBu3LiRa9euERwcjJ2dHZ999hl5\neXmsWbNGD1cShb0PBQUFxMXF8dJLL7Fr1y6mT58OaGP469evZ+vWrRQUFJCdnc3OnTtJTk6mYcOG\n9KyoFkgAACAASURBVO7dm8jISDIzM8nLy9PnBoSHh7NgwQIOHz7MzZs3mTJlCh06dMDPz4++ffty\n7Ngx1q5dS35+PnPnziU1NVWXady4ccyaNUsfv798+TKrVq2qkN4UitqEg4MDfbv05dz+c9y8fhPQ\njP65/efo07kPDg4O1SyhojRqleG3sbEh7Pkw2r7WlhNBJzjV7hTBbwQTOizUokXn7u7On/v8mdCR\noXQM6YiTk5Pu16JFCzq80IEvb3zJ/IT5fJLwCceaH2PoxKHY2FRMnV27duXixYuEhITobp07d+bi\nxYv6+D7An/70J7Zu3cqyZcvw9vbG29ubyZMnc/PmzWJp9urViwkTJtC9e3cCAwMJDg4GKPfY9IwZ\nMxg+fDhGo5FVq1YRFBREVFQU48ePx2g0EhgYyKJFiwBtkuKaNWtYsGAB7u7urFy5ktDQ0FLT37dv\nHy4uLri6utK9e3euXr3KgQMHaNmyJaB1qcfExDBr1iwaNGiAv78/H374oT5T+Ouvv8bOzo77778f\nT09P5s6dC2hzAd555x0GDhyIj48PZ8+eZdmyZQC6bJMmTaJ+/fqcOXPGQuf9+/dn8uTJhIWF4ebm\nRqtWrdi8ebPur1r7CkVx+vbqy+B2g8ncnUnC1gQyd2cyuN1g+vbqW3bkUlBj/FWP2rL3FsnNzeX8\n+fM4OTnh7u5eJXlUBidOnOChhx7i5s2bFX4xUSgUNYOavGVvTk4OV65c0br/rbT0y/Ivyo4dO1R3\nfzm4nS17leG/B1m7di19+vTh2rVrjBw5Ejs7u1taZqdQKGoGd+OzrKCggA2bN7Bh1wZybHJwKNCG\nB/r26qsaIZWA2qtfYcH8+fPx8PAgICAAe3t75s2bV90iKRSKWoZa519zUS1+hUKhqOHcbc+ynJwc\nJkybgKGLodis/8zdmcydObfEbn/V1V8+VItfoVAoFDUGtc6/ZqMMv0KhUCgqFfN1/uaUZ52/au1X\nPcrwKxQKhaJSUev8azb39M59/v7+ag22QqG467mVrbCrm8L1/Bt3b+Sm0Fr6gzuXvc5fjfFXPff0\n5D6FJeqGKh9KT+VH6ap81GQ9VXSdfVWnX5N1VZNQ6/iV4VcoFIoKodbZ393cjuG/p7v6FQqFQmGd\nwnX2jbpoR+vevH6TFftXANCvT79qlk5RlajXulqE2gO7fCg9lR+lq/JR0/SUk5PDhl0baNSukb7k\nztHZkUbtGrFx90ZycnKqTbaapqt7EWX4FQqFopZhbZ19fn4++eRzo+CGWmd/j6PG+BUKhaKWYb6z\nnoOTA7+d/o1T8afIyckhb38ek8ZM4tnQZ6lTp051i6ooATW5Txl+hUKhqBDrN65nxf4V3HC/wW9p\nv+FsdCZ13wVsrjvDNUeaiGa8OG44/fv3VpP9aiBqy15FuVBjZ+VD6an8KF2Vj5qop/9v7+7jo6rv\nvP+/PgPOkEiQiEqRFFjv8GZVwEpttTYqApJG6c0vte3uPmgfW7262Ozltl52tzd22/6uXeu1tHR3\n2W13u9fedau56hZNkypS9apua6EC3lBQq0WNRipoZDAwA8zn+mNmwiQm4ZuQk8zkvJ+PBw/mnDnn\nzDefxySfc87n+/2ehqUNfGDBB9j2n9vgWdi1/jXoPonUzDPpfluOLS9v5ub/eRu3fOVr5HK5Ix4v\nm83S2dlJZ2fnUfURKMdYjTfq1S8iEkOJRIJLL76Ud/zXOzjhnSfwwEOb2X9gGrsPPUVqzhTYBVNO\nO4s7fvFDFvzoXN5/9fv7PU4ul6O1dR1/953v85tXnyGX7OaUk09m5R/8N9637H26W1CGdKtfRGQc\nCpk4J5vNsvLzK0mcneBnm55j95uvM3HmJDgIBzfu57R3XUXXa49wQbKOb9/67X6P09q6jr/6ZjvP\n5baQPQE8keTAvleoS0zga3/451z9vquj/lFjSeP4RUQEyF+Br137Y+6++xHca6mqytLQsICGhkW9\nrr5zuRz3rr+Xjpc6ePqJp3k9vZdcTRU1J80k+1SaE2ecQ46DJKsdTzjpdJpp06b1+qxsNsvdd2/g\nhde3s2/OZKqqziWRSHHMMd107Pkpa/7971m6eKnm5i8zugcTI6qdhVGcwilWYUYqTtlslt27dw9Y\nQ8/lctzyla9x8//8X2x88SmefHE7u7pO4Y47OmlrW99r2+IEPud/7HwWfnAhU8+ZzJuv7iR9z0uc\nOPkcjps9mz17tjOn7gSqElX9PlEvnU6zZ4+zJ7uLqsn5pA8wcWI1x1TN5dmXOtm9e/eQfkZ9p6Kn\nK34RkTIXOr3uD+/+Id+9/585eOZkElVdsB92v/IMFxx/Pe3tm1mypJ5kMnl4Ap/CrH1zT5/Lqb9z\nKuumrOepe5+BY39LJvMqZ5xyAlWvHdPvE/Wy2SzZbJYJE/bi3cfAIXouJXO5g1guRyJbPYpRklBK\n/DGiB1+EUZzCKVZhjjZOIdPrZrNZ1vz7GrrndDNl9skkJkwkd+ggbyZ/y2NP/AsXT7qy53Z9fxP4\nTJw4kasallDzyrGcxEmkEimqXqli2XuW9XqiXi6Xo61tPW1tm8hmq9m9ew+ePkD3r39N9WmnwYQJ\n7Nv7MlWvv84pJ57+lvJA1LGSI1PiFxEpY3v37uXOe+9kxuUz+p1ed8miJSSTSXbv3k3HGx1MOnVS\nz5V3YsJEqk6u5fVHn8V9Qc/t+pqaGpK5JJnuTK/kn92X5Yy3n8Ftn7+NTCbTb8fAtrb1tLTspK5u\nJalUDSedtIeXX/4aLz33c97clcGqDjElWc2s40/jv31S9f1ypBp/jKh2FkZxCqdYhRlOnHK5HK3t\nrdzwhRv42fafcf+d9/PUL57Cc/kRTKnqFBnL9Jpe1w4atTXHksnsIucH88c5cJAD+/dyxRW/25OE\nk8l8qaBjQweZ7gwAme4MHRs6WPaeZUyePJlp06b1e3u/rW0TdXXLSaXyJxGTJk2hoeELLLzgXJZe\n9Lss+t13cdn83+WTH7+EJUvqh/xz6zsVPV3xi4iUoeLt/RlXzGDK5ClMnD6Rrb/aCsDcd87NX617\nqucqftq0acw5aQ4dOzo4fs4E3tj3Mgf3wcGn3uT0GbP48Id7j8Mv3r5vf6idjOWP1fSepl639ftK\np9Nks9U9Sb8okZjE5MkzuOWWD7Nx4+P83//7FD/5ycs89NA3+x1RIGNL4/hFRMpM6Vz6qeoUTz3z\nFFtf2kr1tGoO/vIgl3/gcjo3d9K0sKnXI3Tv+tFdfOOOb7Dn0B5yyRy5fTlqJ9byJx/5E6553zUD\nftaRxvv3alfzKmpr87f5c7kcDz74M7ZufY6DB2+npqab449/J1dd9WdUVR1HJpOmo2MtTU3TaWxc\nPKIxijtN2SsiMo707Xx3xmlncM7Mczj424PseWUPrz7wKk0L33p13riskc985DO8o+4dnD31bC6a\nfRGf/dhne50c9JVMJvu9rT/Qtg0NC+joWEsmk+bBB3/G44/vwSxDXd1KDhx4Ly+88F5+/vMnAEil\naqirW057++YxfdSv9KZb/THy4IMPqsdsAMUpnGIVZqhx6tv5zsyYe/pc3v62t/Pq3lf566/+NZMn\nT37LfolEgsZljSxZtGTAq/ihXOH3p6FhEbCeu+76Jo8//iip1DxOPPHdTJkyn927n2Xy5Hq2bWvn\nkkuyJJNJUqkaMpmqficA6o++U9FT4hcRKTPFznctG1qoW3h4CF/no500XdnUb9Lvu3/fJNt3GF4y\n2T2s+nsikaCxcTGnnDKTBx74NTNn/hmJRJJcLksi0U0icYhcLtWT6DOZNKnUvn4nABoPjvZEaixE\nXuM3s6XAN8mXFb7r7rf2ef+9wF3Ac4VV/+nuXwvZt+QYqvGLyLhSnLSntPNdcUz9cDrKtbauKwzD\nW164Cg+vv/eX3Pbu3cvChZ9gypQ1TJp0AgC7dq3jlVeex30S11//Ydwz47bGP1InUsN1NDX+SBO/\nmSWAp4ErgJeBjcC17r69ZJv3Ap9x96uHum/Jtkr8IjIujcQVZd9OeUWZTJqurjWsXn1jv8c+UnL7\n4hf/ku99bz8nnXQDkyadwL59v2XHjv9BXd0+zj//YlKpfSxbNn9c9uo/mhOpkVDOnfsWAs+4+/Pu\nfgC4Heiva2l/jQ/dVwJpfGwYxSmcYhXmaOI0lM53AxloGN7EiSneeCM34Hz6xcl6amtXMmtWM7W1\nK2lp2dkz7/8tt3yWj31sEun0Dbz88vXs3dvMddedyUMP/W9uu+1jrF59I42Ni4eU9CvhO9XffAaV\n1JEx6hr/TODFkuUO8gm9r3eZ2RbgJeAmd//VEPYVEZFB5O8WdBfq7TW453j6uTa2d6xlnz/GLd/4\nDY31jb3KCIeT28p+ktuannn/v/rVz3HzzXvp7OxkxowZPf0PqqvH7zz9A51IDbUj41gph859jwKz\n3L3bzK4C1gJnDPUgK1asYM6cOQBMnTqVefPm9fQMLZ5BalnLIcvFdeXSnnJerq+vL6v2lPNy0Vh9\nfkPDAlpa1nLo0DReeXULv61+HD9zLydX1bL3+L09c//XVOeT2bnnnks2W01n56MAzJmTP15n56Ps\n3NnRk9zi+Pt34MCBnhOp0vhkMml27XqSTZs2ceWVV47o5xdf79ixg6MVdY3/IuDL7r60sPw5wAfq\npFfY5jfABeSTf9C+qvGLiBzWX7+AYr2+tXUjP328nUkXTuCU09/G2WefwcSJE8l0Z+h6qIvVf766\n5wl+w+kXEBeq8Q9sI3Camc02syRwLXB36QZmNr3k9ULyJyOvhewrQ9P3ykP6pziFU6zCjFaccrkc\n61pbWdXczPduuolVzc2sa20ll8v1DMO75ZYVTJ+dYkJyIr/5TZp77nmEp556lmRVstfc/30n6wF6\nktuyZfMjS/qV8p1qaFhEU9N0urrW8MIL36Kraw1NTdML8xyUt0hv9bv7ITO7AVjH4SF528zs+vzb\n/h3gQ2b2KeAAsA/48GD7RtleEZFKtr6tjZ0tLaysq6MmlSKdybC2pYX1wOLG/Ox9v/jFFjp/A8fP\nnsekmikcPJRh66+2c2D/U5zotb3G2xcn62lvX0MmU0UqtY+mpvkVkdyiVjyRWrKkXuP4x4Ju9YtI\n3GWzWVY1N7Oytpaa1OFH7aYzGdZ0dXHj6tUANDevYlfXKTydaWXKmXVMTKXY372H1554gFs/9SXe\nf/X7+z12pSW38e5obvWXQ+c+EREZxJESbzab5fnnnye1f3+vpA9Qk0pRlTl8Cz+breacuR/imOeq\neGZjO4eOyTDhQIpZE9/BJe+6pN/P728mQKlcSvwxUtpTVgamOIVTrMIMN07F2fvaftpGNpElmctP\n5Vscdlc6wc6+fUle3biNS/fuZ8E5czHLXwx2dXfzujupVIpkMkky2U02+yZzT23ktDlLeur36fQ/\nctxxx43kjz0s+k5Fb3xNpSQiMo603dNGy4YWai+tZdbiWdReWkvLhhba7mnLv9+2nu9//yUmTbqW\nWbNuYOrZn+E7m15k09ancHcefXI7n197HxtenMhnP/s33HvvgyxbNq+nw96ECUkmTEjS2dkeaYc9\nKS+q8YuIlKFsNkvzl5qpvbS25/G8QM+wu1v/9FZ+v+nTJHZO5Dic9IQkk09bRvZAN29s/yZnvq2G\nJ17MceJ513P6OR8im32Tjo61fOhDJ5JIJGhv39zTYa+/aXVV1y9vZTtX/2hR4heRShGaUHfv3s1N\nf3UTsxbPest7L6x7gffMWsiG275L44xFVE9M0X0ww/17Oth1ThOHJm7nwIFXmDXrz6iuPlybLx2D\nD/TbjrF++IyEKedx/FJGKmV87FhTnMIpVmEefPBBcrkcre2tNH+pmZv+6iaav9RMa3t+jH1/ampq\nSOaSZLozvdZnujMcc+gYXti4kcumHEsxZVdPTHH5lDreeOouzPaQSs3slfSh95SyAz0D4Ejz80dN\n36noKfGLiIyCI9Xr+0om8x35OjZ09CT/THeGjg0dXLrgUmrdOf/Mt7Nnz3YOHsy/nwRszzMsWnQ2\nVVXZno57Rfm5+vf1GqtfqtIfPiNhlPhjRD1lwyhO4RSrMO9+97tp+2kbdQvreur1qeoUdQvraH+o\nfcCE2rC0gaaFTXQ91MUL616g66EumhY28cFrPkh3MsmM2TM555zJ7N+/kTfe+AWvvflzpp9eQ1PT\n+4c1617Iw2eipu9U9DScT0QkYul0mmwi26uTHuSTf3Ga3P7GyScSCRqXNXLZpZe95el3CxoauKul\nheVz6jjttDnsSqf58auv8v5rr2XSpEnDmnWv71P8io50p0AqixJ/jGh8bBjFKZxiFWbTpk099fq+\nPfRTnhowofY3jn/Ju5dwybsu4dIrr+SnwJr2dqoyGfalUsy/9loWNTQAw5tStjg/f0vL2n4ePjM6\nw/30nYqeEr+ISMSOOeYYGi5toGVDS8/t/mK9vuk9TQMm1GK/gLpL60hWJXnq8a18Zc3NvGPNLE6d\ncxoLGhr44298gzfffHPAxD7UWfc0P//4p+F8IiKjoHj13v5QOxnLX+kve8+ynln4+uo7jv/Zp55i\n76+28jupavZtOsjXFlxOe2cn05uaeh7AM5I0jr+8aa5+EZEyV6zXL1m0JCihlvYLOHToEJ3PPMOF\nU6aQmjCRrmPeAGB5XR1r2tupX7JkxJOz5ucfv9SrP0Y0PjaM4hROsQpTGqeBxs/3VTqOP5PJcMyh\nQ6QmTCSTOUjqwARqUqm3PIBnPNB3KnpK/CIiZah0HD+H4MCECezp3k/H9j0sm3E6yQkTSGcypCdO\nJJvNaoy9BFONX0SkTJX2C3juxV9z8Onnuf6U8/jQ3HNIZzL8xSOPkK6qYu6MGXQnkyxoaGBRQ/99\nBmR80Vz9SvwiMo707ViXzWZ544032PDQQzx5331UZTI82dnJqfv386l3vpMpkyaRzmRY29ERWWc/\nKS9K/Er8QTQ+NoziFE6xChMap/7G7Tdc2tCr5382m2X37t380y230DxtGjWpw/MCpDMZ1nR1cePq\n1RXbE1/fqTDq1S8iMg6UjtsvjvVv2dACQOOy/FV8MpkkmUxSc/Bgr6QP9Orspx75MhAVgmJEZ9Fh\nFKdwilWYkDhls9ng+fxramroTiZJZ3o/uS9dmMGvkqfW1Xcqekr8IiJlIGQ+/6JkoSPf2o6OnuRf\nrPHPX7asYm/zy+hQ4o8RjY8NoziFU6zChMSpdNx+qYHm81/U0MD0pibWdHXxrRdeYE1XF9Obmnrm\n6q9U+k5FTzV+EZEyUBy3HzqffyKRYHFjI/VLwmYCFClSr34RkTIx1Pn8Jb40nE+JX0TGET0gR47k\naBK/TiFjRLWzMIpTuDjFqjh+fjhT4w41TqHz+Y9HcfpOjRXV+EVEBhEyqY5IJdGtfhGRQbS2t/bf\n4W5hU8+kOiKjTbf6RUQiMJRJdUazTcMtOYiAEn+sqHYWRnEKN95jNZRJdQYzEnHK5XKsa21lVXMz\n37vpJlY1N7OutZVcLnfUxy4n4/07VQ5U4xcRGUDppDqlyX+gSXVGUt+e/evb2tjZ0sLKujpqUqn8\nTH0tLawHPY1PhkQ1fhGRQYx2jT+Xy7G+rY1NbW1UZ7N0J5Ocu2QJj91zD58+/vhx9zQ+GR49nU9E\nRl1cxpo3LM1PgVs6qU7Te5p61o+0/q7s7/j+93n5tdeomTGj17Z6Gp8MhxJ/jOg512EUp8Hlcjna\n2tbT1raJ559/idmzZ9LQsICGhkXjcnhbIpGgcVkjSxYNf2rc0O9UNptlU1tbT9KHfHL/0Jw53Ld1\nK7u7u5lWXd2z/Xh4Gl9f+v2L3vj7LRWRYMPpId7Wtp6Wlp3U1q5k+vQPUlu7kpaWnbS1rY+wpWNv\nNCbVSafTVGezvW7nA0ytrmb2ySdzx44dehqfHDXV+EXKUNS30Uuv2rPZapLJ7qCr9mw2S3PzKmpr\nV5JKHb7KzGTSdHWtYfXqG5WEjkI2m2VVczMra2vfUsv/29df59zFi3nyvvuoKlzpz1+2jEUNmkgo\njlTjFxknShPyvn1JzF7n6qsvYvnyq0b0j3vxqr2uLp/AM5k0LS1rgfU0Ni4ecL90Ok02W90r6QOF\nY1Sp1nyUkskkCxoaWNvSwvLS3vsdHSxoamJxYyNXvu99sehbIdHRaWKMaHxsmLGMU1vbeu64o5Nd\nu85k69YsmzZN5XOfu5Nbbvn6iI3XzmaztLVtoq5ueU8CT6VqqKtbTnv75kFv++eTTTeZTH78+o4d\nDwL5K/5Uat+4qjWPpJDvVLHscumVVzK9qYk1XV1864UXWNPVxfSmJhY15DsTjvd5/PV3Knq64hcp\nE8WEvH//mTz9dJopU1YyeXIN+/fv4o47bmPBgh/z/vcffU/yo7lqTyaTNDQsoKVlLXV1y4F80u/o\nWEtT0/xxm4yi1N/wvQUNDfzxN77Bm2++qSt7GXG64o8R9ZQNM1ZxSqfT7NuXZMeO7UyZspyJE/OJ\nedKkE5g0aQl33/3LEZmmte9Ve1HoVXtDwyKamqbT1bWGROJxurrW0NQ0nYaGRUfdtvFqsO9Uz/C9\n2lqaZ81iZW0tO1ta+Ol9943rK/uB6O9U9HTFL1ImampqMHudbHYqkycfTr4HD2ZIJpO4TxmRGnrf\nq/ZijT/0qj2RSNDYuJglS+pVaz5KAw3fW15Xx5r2duqXLFFsZcTpij9GVDsLM1ZxSiaTXH31Rezf\nv5X9+3cB+aS/Z8925sypoaoqO2I19NKr9hde+NawrtqTySRPPPFEWSWmcn2AzUDfqYGG75VOzBM3\n+jsVPV3xi5SR5cuvYvPmJ7jjjtuYNCl/tXfGGTVUVW1h2bKRq6GPt6v2XC5H2z1ttP20jWwiSzKX\npOHSBhqWjs1Qt9DhmDU1NXQnk6QzmbcM3xtvE/NI+dA4fpEyk8vluOuuH3P33b/EfQpVVVmWLZs/\nbmfGGwmjPZ/+QAbqqDfYWPt1ra3s7Gf43vTC8D2R/hzNOH4lfpEyFZe58I9WNpul+UvN1F5a+5Yn\n6HU91MXqPx+9B9gMJ4kXTxY2t7drYh4JdjSJX9+qGFHtLEy5xKkSxmuXQ6zS6TTZRLZX0gfyV/42\nenXyYke95f101PvBP/zDgP0OEokEixsbuXH1aj52223cuHo1ixsbY5v0y+E7Nd7F85slIuNGTU0N\nyVySTHem1/pMd/5JeqNVJx+so17qwIEjnoBUwomejA+RJ34zW2pm283saTO7eZDtLjSzA2b2gZJ1\nO8zsMTPbbGYbom7reKfxsWEUp3DlEKtkMt+Rr2NDR0/yL9b4l71n9B5gU9pRr1Q6k6FuzpwRPQEp\n19ELI6EcvlPjXaS9+s0sAfwNcAXwMrDRzO5y9+39bPeXwL19DpED6t399SjbKSKVrWFpfkbD9ofa\nyVj+Sr/pPU0960fDYPPsz29qGpETkOF0HhTpK+rhfAuBZ9z9eQAzux24BtjeZ7tPAz8ALuyz3lA5\nYsToOddhFKdw5RKrRCJB47JGlixaMqYdIhc1NLAeWFPaUa+piYnHHjsix++Z5a/0xKKlhfUwbkYA\nlMt3ajyLOvHPBF4sWe4gfzLQw8xOBpa7+2Vm1us9wIH7zOwQ8B13/4dIWysiFa1YJx8rxY569Ut6\nn4CMRIc1zfInI6UcJvD5JlBa+y8dnnCxu3ea2YnkTwC2ufvD/R1kxYoVzJkzB4CpU6cyb968nrPG\n4i+dlrUcslxcVy7tKefl+vr6smpPOS8XDXf/c889l+pslkc7O/PvF/7ePdrZScfOnT3TOZfLz6vf\nv5FdLr7esWMHRyvScfxmdhHwZXdfWlj+HODufmvJNs8VXwInAG8C17n73X2OdQuQdvdV/XyOxvGL\nyLiWzWZZ1dzMytrat8zyt6arixtXj958BTL2ynkc/0bgNDObbWZJ4FqgV0J391MK/36HfJ3/j9z9\nbjOrNrPJAGZ2LLAYeDLi9o5rfa88pH+KUzjFKsxIxKmn82BHR8/IgZ7Og8tGb/RC1PSdil6kt/rd\n/ZCZ3QCsI3+S8V1332Zm1+ff9u/03aXk9XTgh2bmhXZ+z93XRdleEZFyNlDnwUUNozd6QSqfpuwV\nEakwms5ZNFe/Er+IiMRIOdf4pYyodhZGcQqnWIVRnMIpVtFT4hcREYkR3eoXERGpMLrVL3IUxvMD\nT0RE+lLijxHVznrL5XK0tq6juXkVN930PZqbV9Hauo77779/rJtWMfSdCqM4hVOsolcOU/aKjIm2\ntvW0tOykrm4lqVQNmUyalpa1nHXWK1x++eVj3TwRkUgcscZvZme5+7ZRas+wqMYvQ5XNZmluXkVt\nbT7pF2Uyabq61rB69Y0aHy0iZSvqGv8/mdnPzew6M6s58uYi5S+dTpPNVvdK+kDhyr+KdDo9Ri0T\nEYnWERO/u78L+ARwOrDFzP7VzC6LvGUy4lQ7Oyw/41k3mUzvBJ/JpNm160lqanSOG0LfqTCKUzjF\nKnpBnfsKt/pvBj4LXAF8x8x+ZWbXRNk4kaKR7nmfTCZpaFhAR8fanuSfyaTp6FjLRRedrtv8IjJu\nhdT4zwY+DlwNPEj+QTsbzOztwMPuPjvyVh6BavzjVy6Xo61tPW1tm8hmq0kmu2loWEBDwyISiaMb\nlFI8dnv7ZjKZKlKpfSxbNn9Eji0iEqVI5+o3s/8C/hFocfc3+7y3wt3/eTgfPJKU+Mev1tZ1hZ73\ny3t63nd0rKWpaTqNjYtH5DP0wBMRqTRRd+5bBPxLMelb3iSAckj6Eq7SamfZbJa2tk09SR/yne/q\n6pbT3r55RG/7T5s2rSfpV1qcxpJiFUZxCqdYRS8k8d8PHFuyPLmwTiRS6nkvIjLyQhJ/lbv3/IUt\nvK6OrkkSlfr6+rFuwpAM1vM+ldoXWc/7SovTWFKswihO4RSr6IUk/m4zO7+4YGbzgP3RNUkkb7Ce\n98uWzVc9XkRkGEIS/43AD83sATN7ELgTaI60VRKJSqydNTQsoqlpOl1da3jhhW/R1bWGpqbpcPTT\negAAHxFJREFUNDQsiuwzKzFOY0WxCqM4hVOsonfEufrd/RdmdhZwVmHVr9xdjzGTUZFIJGhsXMyS\nJfXqeS8iMgKOOJwPwMzOBM4GJhXXuft/RNiuIdFwPhERiZOjGc53xCt+M/sCsBg4E7gXWAI8DJRN\n4hcREZEwITX+DwOXAZ3u/vvA+fQe3icVQrWzMIpTOMUqjOIUTrGKXkji3+fuh4CDhafzvQKM+TS9\nIiIiMnQhU/Z+m/wDej5Gvjf/HmCbu/9B9M0Loxq/iIjESWRz9ZuZAW9z987C8mnAFHffNKyWRkSJ\nX0RE4iSyufoL2fS+kuVfl1vSl3CqnYVRnMIpVmEUp3CKVfRCavxbzGx+5C0RERGRyIXU+LcCc4Fn\ngTcBI38zYEH0zQujW/0iIhInkY7jB64ezoFFRESk/AQN5xvgn1QY1c7CKE7hFKswilM4xSp6IVf8\nPwGc/C3+ScDbyd/2nxthu0RERCQCQXP199rBbCHwh+5+XTRNGjrV+EVEJE4iG87XH3ffAFw0nA8T\nERGRsXXExG9mzSX//ruZ/RuwcxTaJiNMtbMwilM4xSqM4hROsYpeSI3/xJLXB4H1wP+JpjkiIiIS\npSHX+MuRavwiIhInkdb4zeweM5taslxrZm3D+TAREREZWyGd+97m7l3FBXd/HTg5uiZJVFQ7C6M4\nhVOswihO4RSr6IUk/kNmVldcMLNZEbZHREREIhQyV38DsAa4n/wkPvXAp9z9x5G3LpBq/CIiEidH\nU+MP6txnZtOBdxUWf+buvx3Oh0VFiV9EROIk6s59VwP73X2tu68Fsmb2vuF8mIytSqudZbNZdu/e\nTTabHdXPrbQ4jSXFKoziFE6xil7IOP6vuPu84oK7d5nZV4EfRdcsibNcLkdb23ra2jaRzVaTTHbT\n0LCAhoZFJBJDnmxSRERKhNT4H3P38/use8Ldz420ZUOgW/3jS2vrOlpadlJXt5xUqoZMJk1Hx1qa\nmqbT2Lh4rJsnIjLmop6rf7OZfd3MZhf+3QZsHs6HiRxJNpulrW1TT9IHSKVqqKtbTnv75lG/7S8i\nMt6EJP4bCtvdVfgH8KnIWiSRqYTaWTqdJput7kn6Rfkr/yrS6XTkbaiEOJULxSqM4hROsYreERO/\nu+9198+6+7xCrf/zQPD9VjNbambbzexpM7t5kO0uNLMDZvaBoe4r40dNTQ3JZDeZTO8En8mkSaX2\nUVNTM8CeIiISInQ4XwJYBHwEuAp4xN2XB+73NHAF8DKwEbjW3bf3s919wD7gn9z9P0P3LeyvGv84\nohq/iMjgjqbGP2ivfjO7GPgo0Ei+rn8RcKq77w08/kLgGXd/vnC824FrgL7J+9PAD4ALh7GvjDMN\nDYuA9bS3ryGTqSKV2kdT0/zCehERORoD3uo3s+eB/wX8EjjP3a8BuoeQ9AFmAi+WLHcU1pV+zsnA\ncnf/O/IzAwbvK0NTKbWzRCJBY+NiVq++kdtu+xirV99IY+PiURvKVylxKgeKVRjFKZxiFb3B/pK2\nkk+01wCLzawKiOJ++jcB1e/lLZLJJNOmTSOZTI51U0RExo0Bb/W7+w1m1ky+xv4R4BvAlELnu3vc\nvTvg+C8BpQ/1qSusK/UO4HYzM+AE4CozOxi4b48VK1YwZ84cAKZOncq8efOor68HDp9BalnLIcvF\ndeXSnnJerq+vL6v2lPNyUbm0p1yXi+vKpT3lslx8vWPHDo5WUOc+ADNLAsvInwRc4e4nBOwzAXiK\n/MlDJ7AB+Ii7bxtg+/8NtBY69wXvq859IiISJ1FP4AOAu2cL8/V/GJgduM8h8vMArAO2Are7+zYz\nu97MrutvlyPtG9peeau+Vx7SP8UpnGIVRnEKp1hFL2Su/rdw9zeHsO09wNw+6749wLafONK+IiIi\nMnzBt/rLmW71i4hInET9WN4PhKwTERGR8hdS4/9CP+s+P9INkeipdhZGcQqnWIVRnMIpVtEbsMZv\nZkuApcBMM1tV8tYUIBd1w0RERGTkDVjjN7P5wALgS8BXSt5KA/e7+67omxdGNX4REYmTo6nxH7Fz\nn5lNIn+FP8vdfz2cD4maEr+IiMRJ1OP4rwCeIP/0PMxsnpn9cDgfJmNLtbMwilM4xSqM4hROsYpe\nSOL/CvBOoAvA3bcAp0XZKBEREYlGyK3+R9z9IjPb7O7zC+sed/fzRqWFAXSrX0RE4uRobvWHzNy3\nzcyagISZ/Q7QDDwynA8TERGRsRVyq/8G4ALyHfx+CGSB/x5loyQaqp2FUZzCKVZhFKdwilX0jnjF\nX5iX/2bgZjOrcfd09M0SERGRKAw2jv/zwJ3uvr3wSN4fAQuBDPnH494/es0cnGr8IiISJ1EN5/so\n8FTh9R8Ak4ATgcuBvxjOh4mIiMjYGizxZ0suo5cC/+HuB9x9K3BM9E2TkabaWRjFKZxiFUZxCqdY\nRW+wxJ8xs7PMbBr5q/x1Je9VRdssERERicJgNf6LgX8GTgBWu/uXC+uXASvcvWmU2nhEqvGLiEic\nRDpXfyVQ4hcRkTiJeq5+GSdUOwujOIVTrMIoTuEUq+gp8YuIiMRIyFz9E9394JHWjSXd6hcRkTiJ\n+lb/hsB1IiIiUuYGTPxmdpKZnQ9Umdm5ZnZe4d8lQPXoNVFGimpnYRSncIpVGMUpnGIVvcHm6m8A\nPgHUAX8LFG8ppIEvRtwuERERiUBIjb/J3VtGqT3Dohq/iIjESdQ1/pPMbErhg/7ezDaY2RXD+TAR\nEREZWyGJ/zp332Nmi4EZwCeBr0fbLImCamdhFKdwilUYxSmcYhW9kMRfvIe+DPhXd38scD8REREp\nMyE1/n8lP1//GcB55JP+T919QfTNC6Mav4iIxEmkc/Wb2QTgAuDX7v6amZ0AvN3dNw/nA6OgxC8i\nInESaec+dz8EnAJ8qrCqKmQ/KT+qnYVRnMIpVmEUp3CKVfSOmMDN7G+Ay4DfK6x6E/j7KBslIiIi\n0Qi51b/J3ReY2WZ3n19Y95i7nz8qLQygW/0iIhInUY/jP2BmCQq9+81sGpAbzoeJiIjI2Bpsrv7i\ndL5/C9wJnGhmfw48DNw6Cm2TEabaWRjFKZxiFUZxCqdYRW+wufo3AAvc/V/N7FFgEfn5+v8/d39y\nVFonIiIiI2rAGn9pTb/cqcYvIiJxcjQ1/sGu+E80sz8Z6E13XzWcDxQREZGxM1jnvgnAZKBmgH9S\nYVQ7C6M4hVOswihO4RSr6A12xd/p7l8ZtZaIiIhI5FTjFxERqTCRzNVvZse7+2tH1bJRosQvIiJx\nEskEPpWS9CWcamdhFKdwilUYxSmcYhU9PWxHREQkRo44V38l0K1+ERGJk6jn6hcREZFxQok/RlQ7\nC6M4hVOswihO4RSr6EWe+M1sqZltN7Onzezmft6/2sweM7PNZrbBzC4ueW9H6XtRt1VERGS8i7TG\nX3ic79PAFcDLwEbgWnffXrJNtbt3F16fC7S4+1mF5eeAC9z99SN8jmr8IiISG+Vc418IPOPuz7v7\nAeB24JrSDYpJv2AykCtZtlFoo4iISGxEnVRnAi+WLHcU1vViZsvNbBvQCnyi5C0H7jOzjWb2yUhb\nGgOqnYVRnMIpVmEUp3CKVfQGm6t/1Lj7WmCtmV0CfA24svDWxe7eaWYnkj8B2ObuD/d3jBUrVjBn\nzhwApk6dyrx586ivrwcOf5HivlxULu0p1+UtW7aUVXu0XPnLW7ZsKav2lPOyfv/6Xy6+3rFjB0cr\n6hr/RcCX3X1pYflzgLv7rYPs8yxwYd+ZA83sFiDd3+OAVeMXEZE4Keca/0bgNDObbWZJ4Frg7tIN\nzOzUktcLgKS7v2Zm1WY2ubD+WGAx8GTE7RURERnXIk387n4IuAFYB2wFbnf3bWZ2vZldV9jsg2b2\npJltAv4aaCqsnw48bGabgUeAVndfF2V7x7vSW0YyMMUpnGIVRnEKp1hFL/Iav7vfA8zts+7bJa+/\nDny9n/1+A8yLun0iIiJxorn6RUREKkw51/hFRESkjCjxx4hqZ2EUp3CKVRjFKZxiFT0lfhERkRhR\njV9ERKTCqMYvIiIiQZT4Y0S1szCKUzjFKoziFE6xip4Sv4iISIyoxi8iIlJhVOMXERGRIEr8MaLa\nWRjFKZxiFUZxCqdYRU+JX0REJEZU4xcREakwqvGLiIhIECX+GFHtLIziFE6xCqM4hVOsoqfELyIi\nEiOq8YuIiFQY1fhFREQkiBJ/jKh2FkZxCqdYhVGcwilW0VPiFxERiRHV+EVERCqMavwiIiISRIk/\nRlQ7C6M4hVOswihO4RSr6Cnxi4iIxIhq/CIiIhVGNX4REREJosQfI6qdhVGcwilWYRSncIpV9JT4\nRUREYkQ1fhERkQqjGr+IiIgEUeKPEdXOwihO4RSrMIpTOMUqekr8IiIiMaIav4iISIVRjV9ERESC\nKPHHiGpnYRSncIpVGMUpnGIVPSV+ERGRGFGNX0REpMKoxi8iIiJBlPhjRLWzMIpTOMUqjOIUTrGK\nnhK/iIhIjKjGLyIiUmFU4xcREZEgSvwxotpZGMUpnGIVRnEKp1hFT4lfREQkRlTjFxERqTCq8YuI\niEgQJf4YUe0sjOIUTrEKoziFU6yiF3niN7OlZrbdzJ42s5v7ef9qM3vMzDab2QYzuzh0XxERERma\nSGv8ZpYAngauAF4GNgLXuvv2km2q3b278PpcoMXdzwrZt+QYqvGLiEhslHONfyHwjLs/7+4HgNuB\na0o3KCb9gslALnRfERERGZqoE/9M4MWS5Y7Cul7MbLmZbQNagU8MZV8Jp9pZGMUpnGIVRnEKp1hF\nb+JYNwDA3dcCa83sEuBrwJVDPcaKFSuYM2cOAFOnTmXevHnU19cDh79IcV8uKpf2lOvyli1byqo9\nWq785S1btpRVe8p5Wb9//S8XX+/YsYOjFXWN/yLgy+6+tLD8OcDd/dZB9nkWuBA4I3Rf1fhFRCRO\nyrnGvxE4zcxmm1kSuBa4u3QDMzu15PUCIOnur4XsKyIiIkMTaeJ390PADcA6YCtwu7tvM7Przey6\nwmYfNLMnzWwT8NdA02D7Rtne8a70lpEMTHEKp1iFUZzCKVbRi7zG7+73AHP7rPt2yeuvA18P3VdE\nRESGT3P1i4iIVJhyrvGLiIhIGVHijxHVzsIoTuEUqzCKUzjFKnpK/CIiIjGiGr+IiEiFUY1fRERE\ngijxx4hqZ2EUp3CKVRjFKZxiFT0lfhERkRhRjV9ERKTCqMYvIiIiQZT4Y0S1szCKUzjFKoziFE6x\nip4Sv4iISIyoxi8iIlJhVOMXERGRIEr8MaLaWRjFKZxiFUZxCqdYRU+JX0REJEZU4xcREakwqvGL\niIhIECX+GFHtLIziFE6xCqM4hVOsoqfELyIiEiOq8YuIiFQY1fhFREQkiBJ/jKh2FkZxCqdYhVGc\nwilW0VPiFxERiRHV+EVERCqMavwiIiISRIk/RlQ7C6M4hVOswihO4RSr6Cnxi4iIxIhq/CIiIhVG\nNX4REREJosQfI6qdhVGcwilWYRSncIpV9JT4RUREYkQ1fhERkQqjGr+IiIgEUeKPEdXOwihO4RSr\nMIpTOMUqekr8IiIiMaIav4iISIVRjV9ERESCKPHHiGpnYRSncIpVGMUpnGIVPSV+ERGRGFGNX0RE\npMKoxi8iIiJBlPhjRLWzMIpTOMUqjOIUTrGKnhK/iIhIjKjGLyIiUmFU4xcREZEgSvwxotpZGMUp\nnGIVRnEKp1hFL/LEb2ZLzWy7mT1tZjf38/5Hzeyxwr+Hzey8kvd2FNZvNrMNUbdVRERkvIu0xm9m\nCeBp4ArgZWAjcK27by/Z5iJgm7u/YWZLgS+7+0WF954DLnD314/wOarxi4hIbJRzjX8h8Iy7P+/u\nB4DbgWtKN3D3R9z9jcLiI8DMkrdtFNooIiISG1En1ZnAiyXLHfRO7H39IfDjkmUH7jOzjWb2yQja\nFyuqnYVRnMIpVmEUp3CKVfQmjnUDiszsMuDjwCUlqy92904zO5H8CcA2d3+4v/1XrFjBnDlzAJg6\ndSrz5s2jvr4eOPxFivtyUbm0p1yXt2zZUlbt0XLlL2/ZsqWs2lPOy/r963+5+HrHjh0crahr/BeR\nr9kvLSx/DnB3v7XPducBdwJL3f3ZAY51C5B291X9vKcav4iIxEY51/g3AqeZ2WwzSwLXAneXbmBm\ns8gn/d8vTfpmVm1mkwuvjwUWA09G3F4REZFxLdLE7+6HgBuAdcBW4HZ332Zm15vZdYXNvggcD6zp\nM2xvOvCwmW0m3+mv1d3XRdne8a70lpEMTHEKp1iFUZzCKVbRi7zG7+73AHP7rPt2yetPAm/puOfu\nvwHmRd0+ERGRONFc/SIiIhWmnGv8IiIiUkaU+GNEtbMwilM4xSqM4hROsYqeEr+IiEiMqMYvIiJS\nYVTjFxERkSBK/DGi2lkYxSmcYhVGcQqnWEVPiV9ERCRGVOMXERGpMKrxi4iISBAl/hhR7SyM4hRO\nsQqjOIVTrKKnxC8iIhIjqvGLiIhUGNX4RUREJIgSf4yodhZGcQqnWIVRnMIpVtFT4hcREYkR1fhF\nREQqjGr8IiIiEkSJP0ZUOwujOIVTrMIoTuEUq+gp8cfIgQMH2L17N9lsdqybIiIiY0Q1/hjI5XKs\nb1vPprZNVGer6U52s6BhAYsaFpFI6NxPRKTSHE2NX4l/HMlms6TTaWpqakgmkz3r17WuY2fLTpbX\nLacmVUM6k2Ztx1qmN01ncePiMWyxiIgMhzr3xVwul2Nd6zpWNa/iezd9j1XNq1jXuo5cLkc2m2VT\n2yaW1y3n0c5HAahJ1bC8bjmb2zfrtn8/VGMMp1iFUZzCKVbRmzjWDZCjt75tPTtbdrKybuXhK/qW\ntaxnPRe8+wKqs9XUpGp67VOTqqEqU0U6nWbatGlj1HIRERltuuKvcKVX9MXkXnpFn0ql6E52k86k\nqZ9T37NfOpNmX2ofNTU1Axw5vurr68e6CRVDsQqjOIVTrKKnxF/h0un0oFf0mUyGBQ0LWNuxlnQm\nnd+nUOOfv2x+r74AIiIy/inxV7iampqeK/pSpVf0ixoWMb1pOp/Z+hm+9cK3WNO1hulN01nUsGiM\nWl3eVGMMp1iFUZzCKVbRU42/wiWTyfwVfcvat/Tan990+Ip+ceNibJKxYMGCt/T6FxGR+NBwvnGg\nOE5/c/tmqjJV7EvtY/6y+RqnLyIyTmkcf8wTf9FA4/hFRGR80Th+AfK3/adNmzZg0lftLIziFE6x\nCqM4hVOsoqfELyIiEiO61S8iIlJhdKtfREREgijxx4hqZ2EUp3CKVRjFKZxiFT0lfhERkRhRjV9E\nRKTCqMYvIiIiQZT4Y0S1szCKUzjFKoziFE6xip4Sv4iISIyoxi8iIlJhVOMXERGRIEr8MaLaWRjF\nKZxiFUZxCqdYRU+JX0REJEZU4xcREakwqvGLiIhIECX+GFHtLIziFE6xCqM4hVOsohd54jezpWa2\n3cyeNrOb+3n/o2b2WOHfw2Z2Xui+MjRbtmwZ6yZUBMUpnGIVRnEKp1hFL9LEb2YJ4G+AJcA5wEfM\n7Mw+mz0HXOru5wNfA74zhH1lCLq6usa6CRVBcQqnWIVRnMIpVtGL+op/IfCMuz/v7geA24FrSjdw\n90fc/Y3C4iPAzNB9RUREZGiiTvwzgRdLljs4nNj784fAj4e5rxzBjh07xroJFUFxCqdYhVGcwilW\n0Yt0OJ+ZfRBY4u7XFZZ/D1jo7s39bHsZ+Vv7l7j760PcV2P5REQkVoY7nG/iSDekj5eAWSXLdYV1\nvRQ69H0HWOrurw9lXxj+Dy8iIhI3Ud/q3wicZmazzSwJXAvcXbqBmc0C7gR+392fHcq+IiIiMjSR\nXvG7+yEzuwFYR/4k47vuvs3Mrs+/7d8BvggcD6wxMwMOuPvCgfaNsr0iIiLj3biYsldERETCVMzM\nfQETAc01s5+Z2X4z+5OxaGO5GMakSeeORTvHWkCcri7EaLOZbTCzi8einWMtdCItM7vQzA6Y2QdG\ns33lJOA79V4z6zKzTYV/XxiLdo61kO+UmdUXfveeNLMHRruN5SLgO/XZQpw2mdkTZnbQzKYOelB3\nL/t/5E9Qfg3MBo4BtgBn9tnmBOAC4KvAn4x1m8s8VhcBxxVeLwUeGet2l2mcqktenwtsG+t2l2Oc\nSrb7CfAj4ANj3e5yjRXwXuDusW5rBcTpOGArMLOwfMJYt7tcY9Vn+/cB64903Eq54g+ZCGiXuz8K\nHByLBpaRo5k0KU5C4tRdsjgZyI1i+8pF6ERanwZ+APx2NBtXZkJjFfdRSCFx+ihwp7u/BPm/76Pc\nxnIx1InsPgJ8/0gHrZTEr8l8wh3NpElxEhQnM1tuZtuAVuATo9S2cnLEOJnZycByd/874p3UQn/3\n3mVmW8yszczOHp2mlZWQOJ0BHG9mD5jZRjP7/VFrXXkJ/ntuZlXk7+DeeaSDRj2OX8pYYdKkjwOX\njHVbypW7rwXWmtkl5J8lceUYN6kcfRMorT3GOfkfyaPALHfvNrOrgLXkk5z0NhFYAFwOHAv83Mx+\n7u6/HttmlbVG4GF3P+LDDiol8QdP5iNHNWlSnAzpO+XuD5vZKWZ2vLu/FnnrykdInN4B3F4YjnsC\ncJWZHXD3uM27ccRYufvektc/NrM1+k71+53qAHa5+35gv5n9FDiffL07Tobyd+paAm7zQ+Xc6h/q\nZD5xvuI4mkmT4iQkTqeWvF4AJGP2BxoC4uTupxT+/Q75Ov8fxTDpQ9h3anrJ64Xkh1TrO/XWv+d3\nAZeY2QQzqwbeCcRxHpeg3Gdmx5HvOHpXyEEr4orfAyYCKvxC/RKoAXJm9sfA2aVn2HEQEisGmDRp\n7Fo9+gLj9EEz+wMgC+wDmsauxWMjME69dhn1RpaJwFh9yMw+BRwg/5368Ni1eGyExMndt5vZvcDj\nwCHgO+7+qzFs9pgYwu/fcuBed98XclxN4CMiIhIjlXKrX0REREaAEr+IiEiMKPGLiIjEiBK/iIhI\njCjxi4iIxIgSv4iISIwo8YtEzMyOL3lsZqeZdZQsB82lYWbfNbPTj7DNH5nZR0aozdcU2ril8FjU\nQZ9TYGaXFSakGWybH5nZQyPRPhEZPo3jFxlFZvYlYK+7r+rnPfMy+IUszBD2G2CBu+80s2OA2YPN\nk25mXyU/xerqAd6vJf9I0X3AInfviKDpmNkEdz8UxbFFxgtd8YuMrp7ppM3sVDPbamb/bmZPAm8z\ns2+b2QYze8LMvlCy7UNmdl5hCtPXzewvClfj/2VmJxS2+aqZNZds/xdm9gsz22ZmFxXWV5vZDwpX\n8f+n8OSz8/q08bjC/10A7n6gmPTN7CQzu7PQxkfMbKGZnUL+KY+fLdzFuKifn/tDwA+BO8g/OrT4\nc003s7Vm9ljhDsOFhfUfL1n33cK6fzOzq0v2TRf+v8LyT3FrJT/TG2Z2d+Fne6L0boWZNZjZo4XY\n3WN5z5jZ1ML7CTN7trgsMh5VxJS9IuPYXOD33H0zgJnd7O5dZjYBeMDMfuDu2/vscxzwgLv/qZn9\nFfnHBX+9v4O7+zvNrBG4BbgK+DTQ6e4fKiT8R/vZ51UzWwc8b2Y/If9I4jsKdyO+Bdzq7hvMbDbw\nI3c/18z+EXjV3b81wM/5EeBzQBr4HnBbYf3fkp9q9O/MLAFUF9p1E/Aud39jkCRcenfkAuCs4vPb\ngT8oxLEK+KWZ3QlMAtYAF7t7h5lNdXc3s/8APlZoyxJgQ8gTzkQqlRK/yNh6tpj0Cz5WuEKdCMwA\nzgb6Jv5ud19XeP0oAz9W+T9LtpldeH0J8JcA7v64mW3tb0d3/7iZ/S6wiPwjdy8Hrissn2FmxTsX\nx5lZarAf0MxmkH8U7YbCcsLMznD3p4F6CvPVu3sO2Gtml5M/0XijsD4kCf+8JOkDfKZwwgP555ef\nSv4pZ/cXywwlx/0noIV84v8E8A8BnydSsZT4RcbWm8UXZnYa0Ay8w93TZvZv5K9S+8qWvD7EwL/H\nmYBtBnySpbs/CTxpZt8HfkU+8RtwYd86+uHzgH59GJhmZs8V9p9C/g7An5O/ag/t13CQQnmycHeg\n9GcqjeMV5E9wFrp7ttChsBjHtzTU3Z8vlE/qgXklJ1Ui45Jq/CJjqzQRTQH2kL/qnUH+tvOR9hmq\n/6JwhW1m5wJnveXgZjVm9p6SVfOB5wuv7yNfLihue37hZbrQ/v58BLii5NG97wQ+WnjvAeBThWMl\nzKwGuB/4cKFDYLFjIMAO4B2F1x8AJgzweccBrxWS/jnAhYX1PwPqLf9Y6tLjQv6q/3sEPs9cpJIp\n8YuMrZ6rXXffRP6Z49uAfwYe7m87wq6QB9rmr4GTC50Jv0j+Sv6NPtsY8KeFToGbgD8jfwsc4Abg\n4kLHuyfJd+qD/HPAmwod53o69xU6/r2t8LMVf85fA/vMbH7heEvM7HHyzx6f6+6Pk++z8NPC5xf7\nL3wbuNLMNgPzOHxHo6824NhC+74CPFL43N+SP8m4q3CMfy/Z54fkT1z+ZYBjiowbGs4nEiOFToMT\n3T1TKC3cC5xeqK/HVuFk5f939yvGui0iUVONXyReJgM/scMTB12npG9/BnySQglEZLzTFb+IiEiM\nqMYvIiISI0r8IiIiMaLELyIiEiNK/CIiIjGixC8iIhIj/w9WA2BCHKvafgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f228f316828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Results of cross validation exercise\n",
    "asean_train = np.array([0.543,0.6616,0.5774,0.4004,0.2604,0.3802,0.2948,0.5766,0.3454,0.346,0.2648,0.5794,0.5758,0.5482,0.5514,0.5618,0.5654,0.5334,0.5398,0.5816,0.5724,0.5594])\n",
    "asean_test = np.array([0.491,0.5006,0.5128,0.4632,0.405,0.4612,0.4378,0.5042,0.4606,0.4598,0.4326,0.5114,0.5046,0.5022,0.4954,0.4894,0.5002,0.492,0.5112,0.5054,0.508,0.514])\n",
    "en_train = np.array([0.5384,0.5316,0.5272,0.5322,0.5264,0.5184,0.5278,0.5136,0.496])\n",
    "en_test = np.array([0.4952,0.4898,0.4838,0.4796,0.4668,0.4652,0.4496,0.459,0.4542])\n",
    "se_train = np.array([0.4968,0.5134,0.4366,0.473,0.4972,0.4804,0.4894,0.5004])\n",
    "se_test = np.array([0.467,0.4742,0.4286,0.4482,0.4624,0.471,0.4692,0.4776])\n",
    "sea_train = np.array([0.5864,0.56,0.5756,0.5568,0.5522,0.5232,0.5796,0.5538,0.5254,0.4506,0.5048,0.5214,0.4814,0.5232,0.5382,0.5172,0.5388,0.5534])\n",
    "sea_test = np.array([0.5264,0.5138,0.5334,0.5148,0.4978,0.4844,0.5122,0.5108,0.5094,0.4552,0.4884,0.5064,0.4694,0.492,0.509,0.4774,0.5098,0.5188])\n",
    "wdec_train = np.array([0.201,0.1906])\n",
    "wdec_test = np.array([0.2252,0.2228])\n",
    "\n",
    "# Comparison of models\n",
    "plt.figure(figsize=(8,8))\n",
    "area = 40\n",
    "colors = 'Blue'\n",
    "plt.scatter(asean_train,asean_test, s=area, c='Blue', alpha=0.5,label='Encoder + Attentive Sent. Embedder')\n",
    "plt.scatter(en_train,en_test, s=area, c='Red', alpha=0.5,label='Encoder + non-Attentive Sent. Embededder')\n",
    "plt.scatter(sea_train,sea_test, s=area, c='Green', alpha=0.5,label='Attentive Sent. Embedder')\n",
    "plt.scatter(wdec_train,wdec_test, s=area, c= 'Magenta', alpha=0.5,label='Weighted Decoder')\n",
    "plt.xlabel('Training Set Accuracy')\n",
    "plt.ylabel('Test Set Accuracy')\n",
    "plt.title('Informal Model Comparison', fontsize=20)\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f228f55f240>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEZCAYAAACTsIJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f228f452940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting a histogram of the counts of the error rate per sentence\n",
    "try:\n",
    "    boolarr=dev_predicted==test_feed_dict[model.order] #test_orders\n",
    "except:\n",
    "    boolarr=dev_predicted==test_feed_dict['order'] \n",
    "n_correct_per_story = list(boolarr.sum(axis=1))\n",
    "import matplotlib.pyplot as plt\n",
    "x=np.array(n_correct_per_story[:1800])\n",
    "% matplotlib inline\n",
    "plt.hist(x,np.arange(7)-0.5)#bins=5)\n",
    "plt.title('Histogram of accuracy of predictions')\n",
    "plt.xlabel('Number of correctly predicted orders per sentence')\n",
    "plt.ylabel('Number of occurances')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix C: Code graveyard\n",
    "Graveyard of fully-functioning model components that weren't ultimately used (RIP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =========================== COMPONENT GRAVEYARD ===========================\n",
    "\n",
    "class Attention(object):\n",
    "    def __init__(self, scorer_size, encoder_size, sent_embed_size):\n",
    "        \"\"\"\n",
    "        Builds an attention mechanism based on Logeswaran et al. (2017)\n",
    "        Uses a relu instead of a tanh for the activation in the attention MLP, which has\n",
    "        input size sent_embed_size + encoder.cell_size, hidden size scorer_size, and output size 1\n",
    "        :param scorer_size:\n",
    "        :param encoder_size:\n",
    "        :param sent_embed_size:\n",
    "        \"\"\"\n",
    "\n",
    "        self.hidden_size = scorer_size\n",
    "        self.input_size = encoder_size + sent_embed_size\n",
    "        self.sent_embed_size = sent_embed_size\n",
    "        self.n_sents = 5\n",
    "        self.output_size = 1\n",
    "        self.initializer = tf.contrib.layers.xavier_initializer(uniform=True, seed=None, dtype=tf.float32)\n",
    "\n",
    "        with tf.variable_scope('Attn', reuse=None):\n",
    "            with tf.variable_scope('Hidden', reuse=None):\n",
    "                self.HiddenW = tf.get_variable('weights', [self.input_size, self.hidden_size], initializer=self.initializer)\n",
    "                self.HiddenB = tf.get_variable('biases', [self.hidden_size], initializer=tf.zeros_initializer)\n",
    "                # self.HiddenW = tf.get_variable(\n",
    "                #     'weights', initializer=np.load('pretrained/N500/Attn_Hidden_weights.npy'), trainable=False)\n",
    "                # self.HiddenB = tf.get_variable(\n",
    "                #     'biases', initializer=np.load('pretrained/N500/Attn_Hidden_biases.npy'), trainable=False)\n",
    "\n",
    "            with tf.variable_scope('Output', reuse=None):\n",
    "                self.OutputW = tf.get_variable('weights', [self.hidden_size, self.output_size], initializer=self.initializer)\n",
    "                self.OutputB = tf.get_variable('biases', [1, self.output_size], initializer=tf.zeros_initializer)\n",
    "                # self.OutputW = tf.get_variable(\n",
    "                #     'weights', initializer=np.load('pretrained/N500/Attn_Output_weights.npy'), trainable=False)\n",
    "                # self.OutputB = tf.get_variable(\n",
    "                #     'biases', initializer=np.load('pretrained/N500/Attn_Output_biases.npy'), trainable=False)\n",
    "\n",
    "    @property\n",
    "    def l2_loss(self):\n",
    "        return tf.nn.l2_loss(self.HiddenW) + tf.nn.l2_loss(self.OutputW)\n",
    "\n",
    "    def attention_weights(self, s_t, h_t):\n",
    "        \"\"\"\n",
    "        Computes the attention weights given the sentence embedding matrix and last read state vector.\n",
    "        The attention weight is a scalar for each sentence in a story.\n",
    "        The softmax-scaled weights are used as probabilities for positions.\n",
    "        :param s_t: [batch_size x sent_embed_size]\n",
    "        :param h_t: [batch_size x encoder.cell_size]\n",
    "        :return: Not-softmaxed attention weights\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size = get_this_batch_size(h_t)\n",
    "\n",
    "        # expand the context [batch_size x 5 x sent_embed_size]\n",
    "        context = tf.tile(tf.expand_dims(h_t, 1), [1, 5, 1])\n",
    "\n",
    "        # concatenate sentence embeddings and context:[batch_size x 5 x (cell_size + sent_embed_size)]\n",
    "        concatenated = tf.concat(2, [s_t, context])\n",
    "        inputs = tf.reshape(concatenated, [-1, self.input_size])  # [batch_size*5 x 1 x input_size]\n",
    "\n",
    "        # hidden: [batch_size*5 x 1 x hidden_size]\n",
    "        with tf.variable_scope('Attn/Hidden', reuse=True):\n",
    "            affine = tf.matmul(inputs, self.HiddenW) + self.HiddenB  # [batch_size*5 x 1 x hidden_size]\n",
    "            hidden = tf.nn.relu(affine)\n",
    "\n",
    "        # output: [batch_size x 5] (squeezed off last dimension)\n",
    "        # not softmaxed\n",
    "        with tf.variable_scope('Attn/Output', reuse=True):\n",
    "            affine = tf.matmul(hidden, self.OutputW) + self.OutputB\n",
    "            output = tf.reshape(tf.squeeze(affine), [batch_size, self.n_sents])\n",
    "\n",
    "        return output\n",
    "\n",
    "    def attention_readout(self, s_t, h_t):\n",
    "        \"\"\"\n",
    "        Computes the attention readout given the sentence embedding matrix and last read state vector.\n",
    "        The attention readout is computed by:\n",
    "        - softmaxing sentence attention weights for each story (normalisation by story)\n",
    "        - broadcast multiplying each sentence embedding by the softmaxed weight corresponding to it\n",
    "        - sum over sentences in a story\n",
    "        :param s_t: [batch_size x sent_embed_size]\n",
    "        :param h_t: [batch_size x encoder/decoder_cell_size]\n",
    "        :return: [batch_size x sent_embed_size]\n",
    "        \"\"\"\n",
    "        # s_t is [batch_size x 5 x sent_embed_size]\n",
    "\n",
    "        # batch_size x 5\n",
    "        output = self.attention_weights(s_t, h_t)\n",
    "\n",
    "        # softmax and add dimension to multiply back on s_t\n",
    "        # batch_size x 5 x 1\n",
    "        softmaxed_output = tf.expand_dims(tf.nn.softmax(output), 2)\n",
    "\n",
    "        # elementwise multiplication with broadcasting\n",
    "        attn_arr = tf.mul(softmaxed_output, s_t)\n",
    "\n",
    "        # rowwise sum: batch_size x sent_embed_size\n",
    "        attn_readout = tf.reduce_sum(attn_arr, 1)\n",
    "\n",
    "        return attn_readout\n",
    "\n",
    "\n",
    "class Encoder(object):\n",
    "    def __init__(self, encoder_size, sent_embed_size, read_cycles, attention):\n",
    "        \"\"\"\n",
    "        :param encoder_size: typically sent_embed_size\n",
    "        :param read_cycles:\n",
    "        \"\"\"\n",
    "        self.cell_size = encoder_size\n",
    "        self.sent_embed_size = sent_embed_size\n",
    "        self.output_size = sent_embed_size + encoder_size\n",
    "        self.read_cycles = read_cycles\n",
    "        self.attention = attention\n",
    "        init = tf.contrib.layers.xavier_initializer(uniform=True, seed=None, dtype=tf.float32)\n",
    "        with tf.variable_scope('Encoder', reuse=None):\n",
    "            self.encoder_cell = tf.nn.rnn_cell.GRUCell(encoder_size, activation=tf.nn.relu)\n",
    "            self.state_projector = tf.get_variable(\n",
    "                'StateProjector', [sent_embed_size, encoder_size], initializer=init)\n",
    "            self.output_projector = tf.get_variable(\n",
    "                'OutputProjector', [sent_embed_size, self.output_size], initializer=init)\n",
    "            self.skipW = tf.get_variable('SkipWeights', initializer=[0.1, 0.1, 0.1, 0.1, 0.1, 0.5])\n",
    "\n",
    "    @property\n",
    "    def l2_loss(self):\n",
    "        return tf.nn.l2_loss(self.state_projector) + tf.nn.l2_loss(self.output_projector)\n",
    "\n",
    "    def encode(self, embedded, context):\n",
    "        \"\"\"\n",
    "        :param context:\n",
    "        :param embedded:  [batch_size x 5 x sent_embed_size]\n",
    "        :return:\n",
    "        h_t: encoding after self.read_cycles [batch_size x (sent_embed_size+cell_size)]\n",
    "        context: [batch_size x cell_size]\n",
    "        \"\"\"\n",
    "        batch_size = get_this_batch_size(embedded)\n",
    "\n",
    "        h_t = tf.zeros([batch_size, self.output_size])\n",
    "        state = tf.matmul(context, self.state_projector)  # [batch_size x cell_size]\n",
    "\n",
    "        for t in range(self.read_cycles):\n",
    "            # print(t, h_t.get_shape(), context.get_shape())\n",
    "            # raw_output: [batch_size x cell_size]\n",
    "\n",
    "            if t == 0:\n",
    "                reuse_bool = None\n",
    "            else:\n",
    "                reuse_bool = True\n",
    "\n",
    "            with tf.variable_scope('Encoder', reuse=reuse_bool):\n",
    "                raw_output, state = self.encoder_cell(\n",
    "                    inputs=h_t, state=state)\n",
    "\n",
    "            # attn_vec: [batch_size x sent_embed_size]\n",
    "            attn_readout = self.attention.attention_readout(embedded, raw_output)\n",
    "            # attn_readout = tf.zeros(shape=[batch_size, self.sent_embed_size], dtype=tf.float32)\n",
    "\n",
    "            h_t = tf.concat(1, [raw_output, attn_readout])\n",
    "\n",
    "        return h_t, state\n",
    "\n",
    "    def encode_with_skip(self, embedded, context):\n",
    "        h_t, state = self.encode(embedded, context)\n",
    "        w = self.skipW / tf.reduce_sum(self.skipW)\n",
    "        projected_embeddings = [\n",
    "            w[i] * tf.matmul(tensor, self.output_projector) for i, tensor in enumerate(tf.unpack(embedded, axis=1))]\n",
    "        h_w = tf.add_n(projected_embeddings) + (w[5] * h_t)\n",
    "        # embed = [skipW[0] * embed_attn[i] + skipW[1] * embed_init[i] for i in range(len(embed_attn))]\n",
    "        return h_w, state\n",
    "\n",
    "\n",
    "class EncoderDecoder(object):\n",
    "    def __init__(self, encoder_size, sent_embed_size, read_cycles, scorer_size, affine_decoder=True):\n",
    "        \"\"\"\n",
    "        :param encoder_size: typically sent_embed_size\n",
    "        :param read_cycles:\n",
    "        :param scorer_size:\n",
    "        \"\"\"\n",
    "        self.sent_embed_size = sent_embed_size\n",
    "        self.cell_size = encoder_size\n",
    "        self.affine_decoder = affine_decoder\n",
    "\n",
    "        self.attention = Attention(\n",
    "            scorer_size=scorer_size,\n",
    "            encoder_size=encoder_size,\n",
    "            sent_embed_size=sent_embed_size)\n",
    "\n",
    "        self.encoder = Encoder(encoder_size, sent_embed_size, read_cycles, self.attention)\n",
    "        if affine_decoder:\n",
    "            self.decoder = AffineDecoder(encoder_size)\n",
    "        else:\n",
    "            self.decoder = Decoder(encoder_size, sent_embed_size, self.attention)\n",
    "\n",
    "    @property\n",
    "    def l2_loss(self):\n",
    "        return self.decoder.l2_loss + self.encoder.l2_loss\n",
    "\n",
    "    def encode(self, *args):\n",
    "        return self.encoder.encode(*args)\n",
    "\n",
    "    def encode_with_skip(self, *args):\n",
    "        return self.encoder.encode_with_skip(*args)\n",
    "\n",
    "    def loss(self, *args):\n",
    "        # self.reg * (self.decoder.l2_loss + self.encoder.l2_loss)\n",
    "        return self.decoder.loss(*args)\n",
    "\n",
    "    def predict(self, *args):\n",
    "        return self.decoder.predict(*args)\n",
    "\n",
    "\n",
    "class Decoder(object):\n",
    "    def __init__(self, encoder_size, sent_embed_size, attention):\n",
    "        self.cell_size = encoder_size\n",
    "        self.sent_embed_size = sent_embed_size\n",
    "        self.attention = attention\n",
    "\n",
    "        with tf.variable_scope('Decoder', reuse=None):\n",
    "            self.decoder_cell = tf.nn.rnn_cell.GRUCell(self.cell_size, activation=tf.nn.relu)\n",
    "\n",
    "    def decode(self, embedded, context, pos_order_list, train_mode=True):\n",
    "        \"\"\"\n",
    "            Decoder.\n",
    "            :param embedded: [batch_size x target_size x sent_embed_size]\n",
    "            :param context:\n",
    "            :param pos_order_list: [target_size x batch_size] Can be none if train=False\n",
    "            :param train_mode: flag, used to determine:\n",
    "                    - what input to use for the decoder at each step\n",
    "            :return: unsoftmaxed logits [batch_size x 5 x 5] with\n",
    "                    story x output sentence position x probabilities of input sentence indices\n",
    "            \"\"\"\n",
    "        # batch_size = THIS_BATCH_SIZE\n",
    "        # context = bw_state\n",
    "\n",
    "        this_batch_size = get_this_batch_size(embedded)\n",
    "        static_batch_size = embedded.get_shape()[0].value\n",
    "        target_size = 5\n",
    "\n",
    "        x_prev = tf.zeros([this_batch_size, self.sent_embed_size], dtype=embedded.dtype)\n",
    "        embedded_flat = tf.reshape(embedded, [-1, self.sent_embed_size])\n",
    "\n",
    "        logits_list = []\n",
    "\n",
    "        for t in range(target_size):\n",
    "            # print(t)\n",
    "            # if not training, reuse weights. if training, do not reuse weights at t = 0\n",
    "            reuse_bool = True\n",
    "            if train_mode is True and t == 0:\n",
    "                reuse_bool = None\n",
    "\n",
    "            with tf.variable_scope('Decoder', reuse=reuse_bool):\n",
    "                raw_output, context = self.decoder_cell(\n",
    "                    inputs=x_prev,\n",
    "                    state=context)\n",
    "\n",
    "            # attn_output [batch_size x 5] (trailing x1 squeezed off)\n",
    "            # attn_output[i,j] at time t is prob of jth sent in ith story having position t\n",
    "            # always reuse attention weights when decoding\n",
    "            attn_output = self.attention.attention_weights(embedded, raw_output)\n",
    "\n",
    "            # append the unsoftmaxed attention weights for cross-entropy calculations\n",
    "            # save for later cross entropy\n",
    "            logits_list.append(attn_output)\n",
    "\n",
    "            # Next input\n",
    "            # At training time, use the true sentence at the previous time\n",
    "            # For testing, use the predicted sentence at the previous time\n",
    "            if train_mode:\n",
    "                i_prev = pos_order_list[t]\n",
    "            else:\n",
    "                # argmax seems to automatically return int64 indices\n",
    "                softmax_attn_output = tf.nn.softmax(attn_output)  # I think softmax is monotonic, but just in case...\n",
    "                i_prev = tf.to_int32(tf.arg_max(softmax_attn_output, 1))\n",
    "\n",
    "            i_prev.set_shape([static_batch_size, ])\n",
    "\n",
    "            index = (tf.range(0, this_batch_size) * target_size) + i_prev\n",
    "            x_prev = tf.gather(embedded_flat, index)  # input into next step\n",
    "            # print(x_prev.get_shape())\n",
    "\n",
    "        logits = tf.pack(logits_list, 2)\n",
    "        logits.set_shape([static_batch_size, target_size, target_size])\n",
    "\n",
    "        # always return unsoftmaxed logits from decoder\n",
    "        return logits\n",
    "\n",
    "    @property\n",
    "    def l2_loss(self):\n",
    "        return 0\n",
    "\n",
    "    @staticmethod\n",
    "    def loss_from_logits(logits, order):\n",
    "        return tf.reduce_sum(tf.nn.sparse_softmax_cross_entropy_with_logits(logits, order))\n",
    "\n",
    "    @staticmethod\n",
    "    def predict_from_logits(logits):\n",
    "        softmaxed_logits = tf.pack([tf.nn.softmax(tensor) for tensor in tf.unpack(logits, axis=1)], axis=1)\n",
    "        return tf.arg_max(softmaxed_logits, 2)\n",
    "\n",
    "    def loss(self, embedded, context, pos_order_list, order):\n",
    "        \"\"\"\n",
    "        Computes logits using the decoder in training mode.\n",
    "        Then computes softmax cross entropy with the true order to get loss.\n",
    "        :param embedded:\n",
    "        :param context:\n",
    "        :param pos_order_list: 5 * [batch_size, ]\n",
    "        :param order: [batch_size x 5] This size means we have to use sparse\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # get unsoftmaxed logits from decoder\n",
    "        logits = self.decode(embedded, context, pos_order_list, train_mode=True)\n",
    "\n",
    "        # pass unsoftmaxed decoder logits into crossentropy\n",
    "        # do not make negative because of other dependencies\n",
    "        return self.loss_from_logits(logits, order)\n",
    "\n",
    "    def predict(self, embedded, context):\n",
    "        \"\"\"\n",
    "        Computes logits using the decoder in prediction mode.\n",
    "        Then returns for each story in the batch a prediction vector.\n",
    "        :param embedded: [batch_size x target_size x sent_embed_size]\n",
    "        :param context: [batch_size x encoder.cell_size]\n",
    "        :return: predict [batch_size x target_size]\n",
    "        \"\"\"\n",
    "        logits = self.decode(embedded, context, None, train_mode=False)\n",
    "        # story x output sentence position x probabilities of input sentence indices\n",
    "        # need to unpack and repack because can't specify axis for softmax\n",
    "        return self.predict_from_logits(logits)\n",
    "\n",
    "\n",
    "class Skip2Decoder(Decoder):\n",
    "    def __init__(self, encoder_size, sent_embed_size, attention):\n",
    "        super(Skip2Decoder, self).__init__(encoder_size, sent_embed_size, attention)\n",
    "        initializer = tf.contrib.layers.xavier_initializer(uniform=True, seed=None, dtype=tf.float32)\n",
    "        with tf.variable_scope('Decoder', reuse=None):\n",
    "            self.skipW = tf.get_variable('SkipWeights', initializer=[0.5, 0.5])\n",
    "            self.projector = tf.get_variable('Projector', [self.sent_embed_size, 5], initializer=initializer)\n",
    "\n",
    "    def decode_with_skip(self, embedded, context, pos_order_list, train_mode):\n",
    "        decoded = self.decode(embedded, context, pos_order_list, train_mode)\n",
    "        w = self.skipW / tf.reduce_sum(self.skipW)\n",
    "        projected_embeddings = [\n",
    "            tf.nn.relu(tf.matmul(tensor, self.projector)) for i, tensor in enumerate(tf.unpack(embedded, axis=1))]\n",
    "        logits = w[0] * tf.pack(projected_embeddings, axis=1) + (w[1] * decoded)\n",
    "        return logits\n",
    "\n",
    "    def loss(self, embedded, context, pos_order_list, order):\n",
    "        logits = self.decode_with_skip(embedded, context, pos_order_list, train_mode=True)\n",
    "        self.loss_from_logits(logits, order)\n",
    "\n",
    "    def predict(self, embedded, context):\n",
    "        logits = self.decode_with_skip(embedded, context, None, train_mode=False)\n",
    "        # story x output sentence position x probabilities of input sentence indices\n",
    "        # need to unpack and repack because can't specify axis for softmax\n",
    "        return self.predict_from_logits(logits)\n",
    "\n",
    "    @property\n",
    "    def l2_loss(self):\n",
    "        return tf.nn.l2_loss(self.projector)\n",
    "\n",
    "\n",
    "class AffineDecoder(object):\n",
    "    def __init__(self, encoder_size):\n",
    "\n",
    "        with tf.variable_scope('Decoder', reuse=None):\n",
    "            self.projector_weights = tf.get_variable('weights', [encoder_size, 25])\n",
    "            self.projector_biases = tf.get_variable('biases', [1, 25])\n",
    "            # self.projector_weights = tf.get_variable(\n",
    "            #     'weights', initializer=np.load('pretrained/N500/Decoder_weights.npy'), trainable=False)\n",
    "            # self.projector_biases = tf.get_variable(\n",
    "            #     'biases', initializer=np.load('pretrained/N500/Decoder_biases.npy'), trainable=False)\n",
    "\n",
    "    def decode(self, context):\n",
    "        logits_flat = tf.matmul(context, self.projector_weights) + self.projector_biases\n",
    "        logits = tf.reshape(logits_flat, [-1, 5, 5])\n",
    "        return logits\n",
    "\n",
    "    def loss(self, embedded, context, pos_order_list, order):\n",
    "        \"\"\"Takes extra dummy arguments for consistency with the main Decoder function.\"\"\"\n",
    "        logits = self.decode(context)\n",
    "        return tf.reduce_sum(tf.nn.sparse_softmax_cross_entropy_with_logits(logits, order))\n",
    "\n",
    "    def predict(self, embedded, context):\n",
    "        \"\"\"Takes extra dummy arguments for consistency with the main Decoder function.\"\"\"\n",
    "        logits = self.decode(context)\n",
    "        softmaxed_logits = tf.pack([tf.nn.softmax(tensor) for tensor in tf.unpack(logits, axis=1)], axis=1)\n",
    "        return tf.arg_max(softmaxed_logits, 2)\n",
    "\n",
    "    @property\n",
    "    def l2_loss(self):\n",
    "        return tf.nn.l2_loss(self.projector_weights)\n",
    "\n",
    "\n",
    "class WeightedDecoder(object):\n",
    "    def __init__(self, encoder_size, sent_embed_size, attention):\n",
    "        self.affine = AffineDecoder(encoder_size)\n",
    "        self.decoder = Decoder(encoder_size, sent_embed_size, attention)\n",
    "        with tf.variable_scope('Decoder', reuse=None):\n",
    "            self.skipW = tf.get_variable('SkipWeights',\n",
    "                                         [2], initializer=tf.random_normal_initializer(stddev=0.1))\n",
    "\n",
    "    def decode(self, embedded, context, pos_order_list, train_mode=True):\n",
    "        logits = self.decoder.decode(embedded, context, pos_order_list, train_mode)\n",
    "        skip_logits = self.affine.decode(context)\n",
    "        w = self.skipW / tf.reduce_sum(self.skipW)\n",
    "        w_logits = (w[0] * logits) + (w[1] * skip_logits)\n",
    "        return w_logits\n",
    "\n",
    "    def loss(self, embedded, context, pos_order_list, order):\n",
    "        logits = self.decode(embedded, context, pos_order_list, train_mode=True)\n",
    "        return tf.reduce_sum(tf.nn.sparse_softmax_cross_entropy_with_logits(logits, order))\n",
    "\n",
    "    def predict(self, embedded, context):\n",
    "        logits = self.decode(embedded, context, None, train_mode=False)\n",
    "        softmaxed_logits = tf.pack([tf.nn.softmax(tensor) for tensor in tf.unpack(logits, axis=1)], axis=1)\n",
    "        return tf.arg_max(softmaxed_logits, 2)\n",
    "\n",
    "    @property\n",
    "    def l2_loss(self):\n",
    "        return self.affine.l2_loss + self.decoder.l2_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =========================== MODEL GRAVEYARD ===========================\n",
    "# Non-attentive sentence embedder\n",
    "class SentEmbedderModel(Model):\n",
    "    def build(self):\n",
    "        self.worder = WordEmbedder(self.word_embed_size, self.vocab_size)\n",
    "        self.embedder = SentenceEmbedder(self.sent_embed_size)\n",
    "\n",
    "        # WORD EMBEDDINGS: list 5 *[batch_size x word_embed_size]\n",
    "        words_embedded = self.worder.embed(self.story)\n",
    "\n",
    "        # SENTENCE EMBEDDINGS: list 5*[batch_size x sent_embed_size]\n",
    "        output_list, _, output_state = self.embedder.embed(words_embedded, self.seq_lens, None)\n",
    "        embedded = tf.pack(output_list, axis=1)\n",
    "        self.loss_op = self.simple_loss(embedded, self.order)\n",
    "        self.predict_op = self.simple_predict(embedded)\n",
    "\n",
    "        return None\n",
    "\n",
    "\n",
    "# Attentive sentence embedding model with skip connection: same as MODEL\n",
    "class AttnSentEmbedderModel(Model):\n",
    "    def build(self):\n",
    "        self.worder = WordEmbedder(self.word_embed_size, self.vocab_size)\n",
    "        self.embedder = AttnSentenceEmbedder(self.sent_embed_size)\n",
    "        self.classifier = NonLinearClassifier(5*self.sent_embed_size, 25)\n",
    "\n",
    "        static_batch_size = self.story.get_shape()[0].value\n",
    "\n",
    "        # WORD EMBEDDINGS: list 5 *[batch_size x word_embed_size]\n",
    "        words_embedded = self.worder.embed(self.story)\n",
    "\n",
    "        # SENTENCE EMBEDDINGS: list 5*[batch_size x sent_embed_size]\n",
    "        output_list, _ = self.embedder.embed_with_skip(words_embedded, self.seq_lens, None)\n",
    "        embedded = tf.pack(output_list, axis=1)\n",
    "        embedded.set_shape([static_batch_size, self.target_size, self.sent_embed_size])\n",
    "        embedded = self.classifier.classify(embedded)\n",
    "\n",
    "        reg_loss = self.reg * (\n",
    "            self.classifier.l2_loss + self.embedder.l2_loss)\n",
    "\n",
    "        self.loss_op = self.simple_loss(embedded, self.order) + reg_loss\n",
    "        self.predict_op = self.simple_predict(embedded)\n",
    "\n",
    "        return None\n",
    "\n",
    "\n",
    "# Attentive skip encoder with non-attentive sentence embedding\n",
    "class SkipEncoderModel(Model):\n",
    "    def build(self):\n",
    "        self.worder = WordEmbedder(self.word_embed_size, self.vocab_size)\n",
    "        self.embedder = SentenceEmbedder(cell_size=self.sent_embed_size)\n",
    "        self.encoder = EncoderDecoder(\n",
    "            encoder_size=self.encoder_size,\n",
    "            sent_embed_size=self.sent_embed_size,\n",
    "            read_cycles=self.read_cycles,\n",
    "            scorer_size=self.attn_scorer_size,\n",
    "            affine_decoder=True)\n",
    "\n",
    "        pos_order_list = [tf.squeeze(tensor) for tensor in tf.unpack(self.pos_order, axis=0)]\n",
    "\n",
    "        # WORD EMBEDDINGS: list 5 *[batch_size x word_embed_size]\n",
    "        words_embedded = self.worder.embed(self.story)\n",
    "\n",
    "        # # SENTENCE EMBEDDINGS: list 5*[batch_size x sent_embed_size]\n",
    "        output_list, _, output_state = self.embedder.embed(\n",
    "            words_embedded, self.seq_lens, None)\n",
    "        embedded = tf.pack(output_list, axis=1)\n",
    "\n",
    "        # ENCODING\n",
    "        read_output, read_state = self.encoder.encode_with_skip(embedded, output_state)\n",
    "\n",
    "        # DECODING, SCORING, PREDICTING\n",
    "        self.loss_op = self.encoder.loss(embedded, read_state, pos_order_list, self.order)\n",
    "        self.predict_op = self.encoder.predict(embedded, read_state)\n",
    "\n",
    "        return None\n",
    "\n",
    "    \n",
    "# Attentive skip encoder with attentive sentence embedding\n",
    "class AttnSkipEncoderModel(Model):\n",
    "    def build(self):\n",
    "        self.worder = WordEmbedder(self.word_embed_size, self.vocab_size)\n",
    "        self.embedder = AttnSentenceEmbedder(self.sent_embed_size)\n",
    "        self.encoder = EncoderDecoder(\n",
    "            encoder_size=self.encoder_size,\n",
    "            sent_embed_size=self.sent_embed_size,\n",
    "            read_cycles=self.read_cycles,\n",
    "            scorer_size=self.attn_scorer_size,\n",
    "            affine_decoder=True)\n",
    "\n",
    "        pos_order_list = [tf.squeeze(tensor) for tensor in tf.unpack(self.pos_order, axis=0)]\n",
    "\n",
    "        # WORD EMBEDDINGS: list 5 *[batch_size x word_embed_size]\n",
    "        words_embedded = self.worder.embed(self.story)\n",
    "\n",
    "        # # SENTENCE EMBEDDINGS: list 5*[batch_size x sent_embed_size]\n",
    "        output_list, output_state = self.embedder.embed_with_skip(\n",
    "            words_embedded, self.seq_lens, None)\n",
    "        embedded = tf.pack(output_list, axis=1)\n",
    "\n",
    "        # ENCODING\n",
    "        read_output, read_state = self.encoder.encode_with_skip(embedded, output_state)\n",
    "\n",
    "        reg_loss = self.reg * (self.embedder.l2_loss + self.encoder.l2_loss)\n",
    "\n",
    "        # DECODING, SCORING, PREDICTING\n",
    "        self.loss_op = self.encoder.loss(embedded, read_state, pos_order_list, self.order) + reg_loss\n",
    "        self.predict_op = self.encoder.predict(embedded, read_state)\n",
    "\n",
    "        return None\n",
    "\n",
    "\n",
    "# Basic non-affine decoder model\n",
    "class DecoderModel(Model):\n",
    "    def build(self):\n",
    "        self.worder = WordEmbedder(self.word_embed_size, self.vocab_size)\n",
    "        self.embedder = AttnSentenceEmbedder(self.sent_embed_size)\n",
    "        self.encoder = EncoderDecoder(\n",
    "            encoder_size=self.encoder_size,\n",
    "            sent_embed_size=self.sent_embed_size,\n",
    "            read_cycles=self.read_cycles,\n",
    "            scorer_size=self.attn_scorer_size,\n",
    "            affine_decoder=False)\n",
    "\n",
    "        pos_order_list = [tf.squeeze(tensor) for tensor in tf.unpack(self.pos_order, axis=0)]\n",
    "\n",
    "        # WORD EMBEDDINGS: list 5 *[batch_size x word_embed_size]\n",
    "        words_embedded = self.worder.embed(self.story)\n",
    "\n",
    "        # # SENTENCE EMBEDDINGS: list 5*[batch_size x sent_embed_size]\n",
    "        output_list, output_state = self.embedder.embed_with_skip(\n",
    "            words_embedded, self.seq_lens, None)\n",
    "        embedded = tf.pack(output_list, axis=1)\n",
    "\n",
    "        # ENCODING\n",
    "        read_output, read_state = self.encoder.encode_with_skip(embedded, output_state)\n",
    "\n",
    "        # DECODING, SCORING, PREDICTING\n",
    "        self.loss_op = self.encoder.loss(embedded, read_state, pos_order_list, self.order)\n",
    "        self.predict_op = self.encoder.predict(embedded, read_state)\n",
    "\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =========================== UNUSED FUNCTIONS ===========================\n",
    "# These were not needed for the final model implementation, but were essential during the\n",
    "# development process\n",
    "\n",
    "def argparser(verbose=True):\n",
    "    parser = argparse.ArgumentParser(description='Help me')\n",
    "    parser.add_argument('-W', '--word', dest='word_embed_size', action='store', default=300, type=int)\n",
    "    parser.add_argument('-S', '--sent', dest='sent_embed_size', action='store', default=100, type=int)\n",
    "    parser.add_argument('-M', '--scorer', dest='attn_scorer_size', action='store', default=500, type=int)\n",
    "    parser.add_argument('-N', '--encoder', dest='encoder_size', action='store', default=1000, type=int)\n",
    "    parser.add_argument('-R', '--read', dest='read_cycles', action='store', default=5, type=int)\n",
    "    parser.add_argument('-E', '--epochs', dest='n_epochs', action='store', default=25, type=int)\n",
    "    parser.add_argument('-L', '--learn', dest='learn_rate', action='store', default=0.001, type=float)\n",
    "    parser.add_argument('-B', '--batch', dest='batch_size', action='store', default=50, type=int)\n",
    "    parser.add_argument('-T', '--train', dest='n_train', action='store', default=1000, type=int)\n",
    "    parser.add_argument('-D', '--dev', dest='n_dev', action='store', default=100, type=int)\n",
    "    parser.add_argument('-P', '--permute', dest='permute', action='store', default=0, type=int)\n",
    "    parser.add_argument('-f', '--full', dest='full_run_flag', action='store_true')\n",
    "    parser.add_argument('-s', '--save', dest='save_flag', action='store_true')\n",
    "    parser.add_argument('-w', '--write', dest='write_flag', action='store_true')\n",
    "    parser.add_argument('-sd', '--savedir', dest='save_dir', action='store', default='model/')\n",
    "    parser.add_argument('-wd', '--writedir', dest='write_dir', action='store', default='res/')\n",
    "    parser.add_argument('-i', '--import', dest='saved_path', action='store', default=None)\n",
    "    parser.add_argument('-d', '--do-not-stop', dest='stop_flag', action='store_false')\n",
    "    parser.add_argument('-r', '--reg', dest='reg', action='store', default=0, type=float)\n",
    "    parser.add_argument('-p', '--permutefrac', dest='permute_frac', action='store', default=0, type=float)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # the full run flag overrides specification of training/dev sizes\n",
    "    if args.full_run_flag:\n",
    "        args.n_train = None\n",
    "        args.n_dev = None\n",
    "\n",
    "    # Create the parameter string for use in write_to and model save_to\n",
    "    params = args.encoder_size, args.word_embed_size, args.sent_embed_size, args.attn_scorer_size, args.read_cycles, \\\n",
    "             args.n_epochs, args.learn_rate, args.batch_size, args.n_train, args.n_dev, args.permute, args.reg, \\\n",
    "             args.permute_frac\n",
    "    param_str = 'N{}-W{}-S{}-M{}-R{}-E{}-L{}-B{}-T{}-D{}-P{}-r{}-p{}'.format(*params)\n",
    "    if verbose is False:\n",
    "        param_str = 'W{}-S{}-E{}-L{}-B{}-r{}-p{}'.format(\n",
    "            args.word_embed_size, args.sent_embed_size, args.n_epochs,\n",
    "            args.learn_rate, args.batch_size, args.reg, args.permute_frac)\n",
    "\n",
    "    # Set result print destination. If writing not enabled, set write_to None should print to stdout\n",
    "    if args.write_flag is True:\n",
    "        if not os.path.exists(args.write_dir):\n",
    "            os.mkdir(args.write_dir)\n",
    "        write_path = ''.join([args.write_dir, 'res_', param_str, '.txt'])\n",
    "        write_to = open(write_path, 'a')\n",
    "    else:\n",
    "        write_to = None\n",
    "\n",
    "    # Set model save destination\n",
    "    if args.save_flag is True:\n",
    "        if not os.path.exists(args.save_dir):\n",
    "            os.mkdir(args.save_dir)\n",
    "        save_path = ''.join([args.save_dir, 'model_', param_str, '.ckpt'])\n",
    "    else:\n",
    "        save_path = None\n",
    "\n",
    "    # Print parameters at start of results file in human readable format\n",
    "    args_dict = vars(args)\n",
    "    if verbose:\n",
    "        print('===== Parameters =====', file=write_to)\n",
    "        [print(key, args_dict[key], file=write_to) for key in sorted(args_dict.keys())]\n",
    "\n",
    "    return args, args_dict, write_to, save_path\n",
    "\n",
    "\n",
    "def save_trained_vars(model, scope):\n",
    "    save_vars = [v for v in tf.all_variables() if v.name.startswith(scope)]\n",
    "\n",
    "    for v in save_vars:\n",
    "        computed = model.sess.run(v)\n",
    "        save_name = 'pretrained/' + str(v.name).replace('/', '_').split(':')[0] + '.npy'\n",
    "        print(save_name, computed.shape)\n",
    "        np.save(save_name, computed)\n",
    "\n",
    "\n",
    "def retrieve_weights(SubModel, scopes):\n",
    "    \"\"\"\n",
    "\n",
    "    :param SubModel: class of model to retrieve weights for\n",
    "    :param scopes: the scopes to retrieve\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    args, args_dict, _, _ = argparser()\n",
    "    model = SubModel(args_dict, None)\n",
    "    model.build()\n",
    "    model.load()\n",
    "    for scope in scopes:\n",
    "        save_trained_vars(model, scope)\n",
    "\n",
    "\n",
    "def main_predict(SubModel, args_dict, feed_dict):\n",
    "    # Minimum args_dict at test time has keys: word_embed_size, sent_embed_size, attn_scorer_size, saved_path\n",
    "    model = SubModel(args_dict)\n",
    "    model.build()\n",
    "    model.load()\n",
    "    return model.predict(feed_dict)\n",
    "\n",
    "\n",
    "def main(SubModel):\n",
    "    \"\"\"\n",
    "    Build, train, save, write models.\n",
    "    :param SubModel: a subclass of Model with at least an overriding build method\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Retrieve arguments\n",
    "    args, args_dict, write_to, save_path = argparser()\n",
    "\n",
    "    # ===== DATA LOADING ======\n",
    "    # Load data of required size\n",
    "    pipeline = Preprocess(args.batch_size, args.n_train, args.n_dev, args.permute, args.permute_frac)\n",
    "    train_batches, dev_batches = pipeline.pipeline()\n",
    "    args_dict['vocab_size'] = pipeline.vocab_size\n",
    "\n",
    "    # ===== FINALLY, START MODELLING =====\n",
    "    # Initialise model (starts a session)\n",
    "    model = SubModel(args_dict, save_path)\n",
    "    assert model.sess is not None\n",
    "\n",
    "    # Build model using training vocabulary size\n",
    "    model.build()\n",
    "\n",
    "    # Prepare full train and dev feed_dicts for accuracy reporting\n",
    "    train_feed_dict = pipeline.stack_batches(*train_batches, model=model)\n",
    "    dev_feed_dict = pipeline.stack_batches(*dev_batches, model=model)\n",
    "\n",
    "    # Train model\n",
    "    model.train(args_dict, train_feed_dict, dev_feed_dict, train_batches, write_to)\n",
    "\n",
    "    # Closing\n",
    "    if args.save_flag is True:\n",
    "        model.save()\n",
    "\n",
    "    if write_to is not None:\n",
    "        write_to.close()\n",
    "\n",
    "    if model.sess is not None:\n",
    "        model.sess.close()\n",
    "\n",
    "\n",
    "def validate_main(SubModel):\n",
    "    \"\"\"\n",
    "    Build, train, save, write models.\n",
    "    :param SubModel: a subclass of Model with at least an overriding build method\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Retrieve arguments\n",
    "    args, args_dict, write_to, save_path = argparser(verbose=False)\n",
    "\n",
    "    # ===== DATA LOADING ======\n",
    "    # Load data of required size\n",
    "    pipeline = Preprocess(args.batch_size, args.n_train, args.n_dev, args.permute)\n",
    "\n",
    "    for k in range(5):\n",
    "        train_batches, dev_batches = pipeline.validate()\n",
    "\n",
    "        # ===== FINALLY, START MODELLING =====\n",
    "        # Initialise model (starts a session)\n",
    "        model = SubModel(args_dict, save_path)\n",
    "        assert model.sess is not None\n",
    "\n",
    "        # Build model using training vocabulary size\n",
    "        model.build()\n",
    "\n",
    "        # Prepare full train and dev feed_dicts for accuracy reporting\n",
    "        train_feed_dict = pipeline.stack_batches(*train_batches, model=model)\n",
    "        dev_feed_dict = pipeline.stack_batches(*dev_batches, model=model)\n",
    "\n",
    "        # Train model\n",
    "        model.train(args_dict, train_feed_dict, dev_feed_dict, train_batches, write_to, False)\n",
    "\n",
    "        if model.sess is not None:\n",
    "            model.sess.close()\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "\n",
    "    if write_to is not None:\n",
    "        write_to.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script for extracting GloVe embeddings for our vocabulary from pretrained:\n",
    "```\n",
    "from shared import Preprocess\n",
    "import numpy as np\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser(description='Extract GloVe embeddings using our data vocabulary.')\n",
    "parser.add_argument('-W', '--word', dest='word_embed_size', action='store', default=100, type=int)\n",
    "parser.add_argument('--src', dest='src_path', action='store', default=None)\n",
    "parser.add_argument('--save', dest='save_path', action='store', default=None)\n",
    "args = parser.parse_args()\n",
    "\n",
    "pipeline = Preprocess()\n",
    "data_train, data_dev = pipeline.load_data()\n",
    "data_train.extend(data_dev)\n",
    "train_lists = pipeline.build_vocab(data_train)\n",
    "vocab = pipeline.vocab\n",
    "print(len(vocab))\n",
    "word_embed_size = args.word_embed_size\n",
    "\n",
    "if args.src_path is None:\n",
    "    args.src_path = 'glove.6B.300d.txt'\n",
    "if args.save_path is None:\n",
    "    args.save_path = 'embeddings/GloVe300.npy'\n",
    "\n",
    "# 2. Load GloVe embeddings\n",
    "embed_file = open(args.src_path, 'r')\n",
    "\n",
    "# 3. Read data in a dictionary, keep a log of\n",
    "# not found words (the index to the words)\n",
    "myGlove = {}\n",
    "for line in embed_file:\n",
    "    items = line.replace('\\r', '').replace('\\n', '').split(' ')\n",
    "    splitLine = line.split()\n",
    "    word = splitLine[0]\n",
    "    embed = [float(val) for val in splitLine[1:]]\n",
    "    myGlove[word] = embed\n",
    "\n",
    "embed_file.close()\n",
    "\n",
    "# 4. Bring the embeddings corresponding to all words of our vocabulary\n",
    "# from GLoVe to a dictionary (named 'found')\n",
    "# keep a list of all words not found in the GLoVe files in a second\n",
    "# directory named 'not_found'\n",
    "\n",
    "not_found = []\n",
    "found = np.zeros([len(vocab), word_embed_size])\n",
    "oov = np.zeros([1, word_embed_size])\n",
    "for word in vocab:\n",
    "    if word in myGlove:\n",
    "        found[vocab[word],] = myGlove[word]\n",
    "        oov += myGlove[word]\n",
    "    else:\n",
    "        not_found.append(vocab[word])\n",
    "# calculate the embedding of the <OOV> token as the mean value of imported vectors\n",
    "oov /= len(found)\n",
    "\n",
    "# 5. Set all not found words (~2% of dictionary) to the oov token\n",
    "for i in range(len(not_found)):\n",
    "    found[not_found[i],] = not_found[i]\n",
    "\n",
    "# 6. Save the embedding vector for later use\n",
    "# CHANGE FILE_NAME ACCORDINGLY\n",
    "\n",
    "from tempfile import TemporaryFile\n",
    "\n",
    "outfile = TemporaryFile()\n",
    "np.save(args.save_path, found, allow_pickle=True, fix_imports=True)\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Assessment 2</font>: Assess Description (30 pts) \n",
    "\n",
    "We will mark the description along the following dimensions: \n",
    "\n",
    "* Clarity (10pts: very clear, 0pts: we can't figure out what you did, or you did nothing)\n",
    "* Creativity (10pts: we could not have come up with this, 0pts: Use only the provided model)\n",
    "* Substance (10pts: implemented complex state-of-the-art classifier, compared it to a simpler model, 0pts: Only use what is already there)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='orange'>Mark</font>:  Your solution to Task 2 is marked with ** __ points**.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='orange'>Final mark</font>: Your solution to Assignment 3 is marked with ** __points**. "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
