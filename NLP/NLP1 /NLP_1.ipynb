{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "In this assignment you will build a language model for the [OHHLA corpus](http://ohhla.com/) we are using in the book. You will train the model on the available training set, and can tune it on the development set. After submission we will run your notebook on a different test set. Your mark will depend on \n",
    "\n",
    "* whether your language model is **properly normalized**,\n",
    "* its **perplexity** on the unseen test set,\n",
    "* your **description** of your approach. \n",
    "\n",
    "To develop your model you have access to:\n",
    "\n",
    "* The training and development data in `data/ohhla`.\n",
    "* The code of the lecture, stored in a python module [here](/edit/statnlpbook/lm.py).\n",
    "* Libraries on the [docker image](https://github.com/uclmr/stat-nlp-book/blob/python/Dockerfile) which contains everything in [this image](https://github.com/jupyter/docker-stacks/tree/master/scipy-notebook), including scikit-learn and tensorflow. \n",
    "\n",
    "As we have to run the notebooks of all students, and because writing efficient code is important, **your notebook should run in 5 minutes at most**, on your machine. Further comments:\n",
    "\n",
    "* We have tested a possible solution on the Azure VMs and it ran in seconds, so it is possible to train a reasonable LM on the data in reasonable time. \n",
    "\n",
    "* Try to run your parameter optimisation offline, such that in your answer notebook the best parameters are already set and don't need to be searched."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Instructions\n",
    "It is important that this file is placed in the **correct directory**. It will not run otherwise. The correct directory is\n",
    "\n",
    "    DIRECTORY_OF_YOUR_BOOK/assignments/2016/assignment1/problem/\n",
    "    \n",
    "where `DIRECTORY_OF_YOUR_BOOK` is a placeholder for the directory you downloaded the book to. After you placed it there, **rename the file** to your UCL ID (of the form `ucxxxxx`). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Instructions\n",
    "This notebook will be used by you to provide your solution, and by us to both assess your solution and enter your marks. It contains three types of sections:\n",
    "\n",
    "1. **Setup** Sections: these sections set up code and resources for assessment. **Do not edit these**. \n",
    "2. **Assessment** Sections: these sections are used for both evaluating the output of your code, and for markers to enter their marks. **Do not edit these**. \n",
    "3. **Task** Sections: these sections require your solutions. They may contain stub code, and you are expected to edit this code. For free text answers simply edit the markdown field.  \n",
    "\n",
    "Note that you are free to **create additional notebook cells** within a task section. \n",
    "\n",
    "Please **do not share** this assignment publicly, by uploading it online, emailing it to friends etc. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Instructions\n",
    "\n",
    "To submit your solution:\n",
    "\n",
    "* Make sure that your solution is fully contained in this notebook. \n",
    "* **Rename this notebook to your UCL ID** (of the form \"ucxxxxx\"), if you have not already done so.\n",
    "* Download the notebook in Jupyter via *File -> Download as -> Notebook (.ipynb)*.\n",
    "* Upload the notebook to the Moodle submission site.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>Setup 1</font>: Load Libraries\n",
    "This cell loads libraries important for evaluation and assessment of your model. **Do not change it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#! SETUP 1\n",
    "import sys, os\n",
    "_snlp_book_dir = \"../../../../\"\n",
    "sys.path.append(_snlp_book_dir) \n",
    "import statnlpbook.lm as lm\n",
    "import statnlpbook.ohhla as ohhla\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>Setup 2</font>: Load Training Data\n",
    "\n",
    "This cell loads the training data. We use this data for assessment to define the reference vocabulary: the union of the words of the training and set set. You can use the dataset to train your model, but you are also free to load the data in a different way, or focus on subsets etc. However, when you do this, still **do not edit this setup section**. Instead refer to the variables in your own code, and slice and dice them as you see fit.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load ../../../..//data/ohhla/train/www.ohhla.com/anonymous/nas/distant/tribal.nas.txt.html\n"
     ]
    }
   ],
   "source": [
    "#! SETUP 2\n",
    "_snlp_train_dir = _snlp_book_dir + \"/data/ohhla/train\"\n",
    "_snlp_dev_dir = _snlp_book_dir + \"/data/ohhla/dev\"\n",
    "_snlp_train_song_words = ohhla.words(ohhla.load_all_songs(_snlp_train_dir))\n",
    "_snlp_dev_song_words = ohhla.words(ohhla.load_all_songs(_snlp_dev_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to file encoding issues this code produces one error `Could not load ...`. **Ignore this error**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Task 1</font>: Develop and Train the Model\n",
    "\n",
    "This is the core part of the assignment. You are to code up, train and tune a language model. Your language model needs to be subclass of the `lm.LanguageModel` class. You can use some of the existing language models developed in the lecture, or develop your own extensions. \n",
    "\n",
    "Concretely, you need to return a better language model in the `create_lm` function. This function receives a target vocabulary `vocab`, and it needs to return a language model defined over this vocabulary. \n",
    "\n",
    "The target vocab will be the union of the training and test set (hidden to you at development time). This vocab will contain words not in the training set. One way to address this issue is to use the `lm.OOVAwareLM` class discussed in the lecture notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Below is modified OOVAware which will work with my create_lm language model situated directly below\n",
    "class MYOOVAwareLM(lm.LanguageModel):\n",
    "    \"\"\"\n",
    "    This LM converts out of vocabulary tokens to a special OOV token before their probability is calculated.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_lm, missing_words):\n",
    "        \"\"\"\n",
    "        Create an OOV Aware LM that uniformly assigns the mass of the OOV symbol\n",
    "         to the missing words outside of the training vocabulary.\n",
    "        Args:\n",
    "            base_lm: the base LM to get word and OOV probabilities from.\n",
    "            missing_words: a set of words that are not in the base_lm vocab but expected\n",
    "            in the vocab of this LM.\n",
    "        \"\"\"\n",
    "        super().__init__(base_lm.vocab | missing_words, base_lm.order)\n",
    "        self.base_lm = base_lm\n",
    "        self.missing_words = missing_words\n",
    "\n",
    "    def probability(self, word, *history):\n",
    "        \"\"\"\n",
    "        Returns the weighted probability of the word under the base_lm if the word\n",
    "        is in the vocab of the base_lm. If the word is in the set of missing words,\n",
    "        it assigns it prob missng word (equal to aprox. 0.022) / len(missing_words). \n",
    "        Else 0 is returned.\n",
    "        Args:\n",
    "            word: the word to estimate the probability of.\n",
    "            *history: the history to condition on.\n",
    "\n",
    "        Returns: Adjusted OOV Aware probability of the word given the context in the ohhla set.\n",
    "\n",
    "        \"\"\"\n",
    "        if word in self.base_lm.vocab:\n",
    "            return self.base_lm.probability(word, *history)*0.978\n",
    "        elif word in self.missing_words:\n",
    "            return 0.022/ len(self.missing_words)\n",
    "        else:\n",
    "            return 0.0\n",
    "\n",
    "        \n",
    "#set data for model training \n",
    "OOVdat=_snlp_train_song_words\n",
    "\n",
    "def create_lm(vocab):\n",
    "    \"\"\"\n",
    "    Return an instance of `lm.LanguageModel` defined over the given vocabulary.\n",
    "    Args:\n",
    "        vocab: the vocabulary the LM should be defined over. It is the union of the training and test words.\n",
    "    Returns:\n",
    "        a language model, instance of `lm.LanguageModel`.\n",
    "    \"\"\"\n",
    "    #SETUP LM -create NGrams up Quadrigram\n",
    "    \n",
    "    Unigram=lm.NGramLM(OOVdat,1)\n",
    "    Bigram=lm.NGramLM(OOVdat,2)\n",
    "    Trigram=lm.NGramLM(OOVdat,3)\n",
    "    Qgram=lm.NGramLM(OOVdat,4) \n",
    "        \n",
    "    #Interpolate with tuned parameters: \n",
    "        #note nested structure is needed due to the defintion of the Interp function\n",
    "    \n",
    "    Interp1=lm.InterpolatedLM(Bigram,Unigram,0.68087)\n",
    "    Interp2=lm.InterpolatedLM(Trigram,Interp1,0.156601)\n",
    "    Interp3=lm.InterpolatedLM(Qgram,Interp2,0.116918)\n",
    "    \n",
    "    #CALCULATE MISSING WORDS\n",
    "    miss=set(vocab)-set(OOVdat)\n",
    "    \n",
    "    #Call my vesion of OOV aware which assigns non zero probabilty to previously unseen words \n",
    "    sol=MYOOVAwareLM(Interp3,miss)\n",
    "\n",
    "    return sol\n",
    "\n",
    "\n",
    "#######################-SUPLEMENTARY-MATERIAL-########################\n",
    "\n",
    "########-Code-for-parameter-optimisation-#########\n",
    "\n",
    "#Outline:\n",
    "#1.Modify create_lm function to include and additional imput; \n",
    "#vector of parameters to be optimised\n",
    "#2.Itterate over the modified create_lm function using different parameters until \n",
    "#minimum perplexity is reached.\n",
    "#  Optimisation performed using the Twiddle algorithm, which is similar to gradient \n",
    "#  descent but does not require \n",
    "#  differentaion to be performed on any of teh models functions. \n",
    "#  Reference: Adapted from  Martin Thoma website: https://martin-thoma.com/twiddle/\n",
    "#\n",
    "####-1-MODIFIED-FUNCTION:\n",
    "#\n",
    "#def create_lm(vocab,p):\n",
    "#    \n",
    "#    #Initialise parameters as variables:\n",
    "#\n",
    "#    b1=p[0]\n",
    "#    b2=p[1]\n",
    "#    b3=p[2]\n",
    "#    \n",
    "#    #SETUP LM -create NGrams up Quadrigram\n",
    "#\n",
    "#    Unigram=lm.NGramLM(OOVdat,1)\n",
    "#    Bigram=lm.NGramLM(OOVdat,2)\n",
    "#    Trigram=lm.NGramLM(OOVdat,3)\n",
    "#    Qgram=lm.NGramLM(OOVdat,4) \n",
    "#\n",
    "#    #Interpolate with parameters as varaibles:\n",
    "#\n",
    "#    Interp1=lm.InterpolatedLM(Bigram,Unigram,b1)\n",
    "#    Interp2=lm.InterpolatedLM(Trigram,Interp1,b2)\n",
    "#    Interp3=lm.InterpolatedLM(Qgram,Interp2,b3)\n",
    "#    \n",
    "#    #CALCULATE MISSING WORDS\n",
    "#\n",
    "#    miss=set(vocab)-set(OOVdat)\n",
    "#     \n",
    "#    sol=MYOOVAwareLM(Interp3,miss)\n",
    "#    \n",
    "#    return sol\n",
    "#\n",
    "#####-2-Modified-TWIDDLE:\n",
    "#\n",
    "#    #Choose an initialization parameter vector\n",
    "#    p = [0.4, 0.1, 0.1]\n",
    "#\n",
    "#    # Define potential changes\n",
    "#    dp = [0.05, 0.05, 0.05]\n",
    "#\n",
    "#    # Calculate the error\n",
    "#\n",
    "#    best_err = lm.perplexity(create_lm(vocab,p), _snlp_test_song_words)\n",
    "#\n",
    "#    c=0  #initailaise counter \n",
    "#\n",
    "#    while (best_err>140 and c<20):\n",
    "#        for i in range(0,len(p)):\n",
    "#            p[i] += dp[i]\n",
    "#            err = lm.perplexity(create_lm(vocab,p), _snlp_test_song_words)\n",
    "#            if err < best_err:  # There was some improvement\n",
    "#                best_err = err\n",
    "#                dp[i] *= 1.1\n",
    "#            else:   # There was no improvement\n",
    "#                p[i] -= 2*dp[i]  # Go into the other direction\n",
    "#                err = lm.perplexity(create_lm(vocab,p), _snlp_test_song_words)\n",
    "#\n",
    "#                if err < best_err:  # There was an improvement\n",
    "#                    best_err = err\n",
    "#                    dp[i] *= 1.05\n",
    "#                else:  # There was no improvement\n",
    "#                    p[i] += dp[i]\n",
    "#                    # As there was no improvement, the step size in either\n",
    "#                    # direction, the step size might simply be too big.\n",
    "#                    dp[i] *= 0.95\n",
    "#       c+=1\n",
    "#       print(c)\n",
    "#       print(p)\n",
    "#       print(dp)\n",
    "#       print(best_err) \n",
    "# Output is such that can visualy inspect the convergence of a solution\n",
    "#\n",
    "# Final note: to guard agians optimising on local minima (missing the global minmum)\n",
    "# various configurations of the start parameter vector were checked \n",
    "# Final parameters are found to be aporx. [0.68087, 0.156601, 0.116918]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>Setup 3</font>: Specify Test Data\n",
    "This cell defines the directory to load the test songs from. When we evaluate your notebook we will point this directory elsewhere and use a **hidden test set**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#! SETUP 3\n",
    "_snlp_test_dir = _snlp_book_dir + \"/data/ohhla/dev\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>Setup 4</font>: Load Test Data and Prepare Language Model\n",
    "In this section we load the test data, prepare the reference vocabulary and then create your language model based on this vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#! SETUP 4\n",
    "_snlp_test_song_words = ohhla.words(ohhla.load_all_songs(_snlp_test_dir))\n",
    "_snlp_test_vocab = set(_snlp_test_song_words)\n",
    "_snlp_dev_vocab = set(_snlp_dev_song_words)\n",
    "_snlp_train_vocab = set(_snlp_train_song_words)\n",
    "_snlp_vocab = _snlp_test_vocab | _snlp_train_vocab | _snlp_dev_vocab\n",
    "_snlp_lm = create_lm(_snlp_vocab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Assessment 1</font>: Test Normalization (20 pts)\n",
    "Here we test whether the conditional distributions of your language model are properly normalized. If probabilities sum up to $1$ you get full points, you get half of the points if probabilities sum up to be smaller than 1, and 0 points otherwise. Due to floating point issues we will test with respect to a tolerance $\\epsilon$ (`_eps`).\n",
    "\n",
    "Points:\n",
    "* 10 pts: $\\leq 1$\n",
    "* 20 pts: $\\approx 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum: 0.9999999999997496, ~1: True, <=1: True\n",
      "Sum: 0.9999999999998356, ~1: True, <=1: True\n",
      "Sum: 0.9999999999995576, ~1: True, <=1: True\n"
     ]
    }
   ],
   "source": [
    "#! ASSESSMENT 1\n",
    "_snlp_test_token_indices = [100, 1000, 10000]\n",
    "_eps = 0.000001\n",
    "for i in _snlp_test_token_indices:\n",
    "    result = sum([_snlp_lm.probability(word,*_snlp_test_song_words[i-_snlp_lm.order:i]) for word in _snlp_vocab])\n",
    "    print(\"Sum: {sum}, ~1: {approx_1}, <=1: {leq_1}\".format(sum=result, \n",
    "                                                            approx_1=abs(result - 1.0) < _eps, \n",
    "                                                            leq_1=result - _eps <= 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above solution is marked with **\n",
    "<!-- ASSESSMENT 2: START_POINTS -->\n",
    "10\n",
    "<!-- ASSESSMENT 2: END_POINTS --> \n",
    "points **."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Assessment 2</font>: Apply to Test Data (50 pts)\n",
    "\n",
    "We assess how well your LM performs on some unseen test set. Perplexities are mapped to points as follows.\n",
    "\n",
    "* 0-10 pts: uniform perplexity > perplexity > 550, linear\n",
    "* 10-30 pts: 550 > perplexity > 140, linear\n",
    "* 30-50 pts: 140 > perplexity > *Best-Result*, linear\n",
    "\n",
    "The **linear** mapping maps any perplexity value between the lower and upper bound linearly to a score. For example, if uniform perplexity is $U$ and your model's perplexity is $P\\leq550$, then your score is $10\\frac{P-U}{550-U}$. \n",
    "\n",
    "The *Best-Result* perplexity is the minimum of the best perplexity the course organiser achieved, and the submitted perplexities.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141.73813181366467"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.perplexity(_snlp_lm, _snlp_test_song_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above solution is marked with **\n",
    "<!-- ASSESSMENT 3: START_POINTS -->\n",
    "0\n",
    "<!-- ASSESSMENT 3: END_POINTS --> points**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Task 2</font>: Describe your Approach\n",
    "\n",
    "The main problem to overcome when designing a language model (LM) is that of assigning zero probability to previously unseen words or combinations of words. This does not reflect reality and yields infinite perplexity. Thus, in designing a robust LM I focused on developing strategies to re-distribute probabilities and my approach is outlined below.\n",
    "\n",
    "* Data exploration and Dealing with Unseen Words:\n",
    "\n",
    "    The initial approach was to inject out-of-vocabulary tokens (OOV’s ) to the training set for each first new word instance and using the lm.OOVAware function to distribute probability away from ‘seen’ words to ‘unseen’ words. This method paired with the design of my LM (paragraph below) yelled perplexities up to 156. However, the missing words vocabulary was substantial and amounted to 23342 as compared with the 43801 words in the entire vocabulary. Clearly, many words in the ohhla corpus only occur once and substantial information is lost using the OOVs technique. Missing words are approximately 2.24% of the entire dataset (23342 /1041496). I implemented this finding in my own version of OOVAware: where I assigned (0.022/count of unseen words) probability to previously unseen words and weighted the probability of the remaining words by 0.978. Departing from the use of OOV’s, my missing words are the difference between the test (dev) and train sets of vocabulary (at training = 3109 words).I assume that for any test vocabulary coming from the ohhla set the model will scale well as the proportion of unseen words will still be about 2.2%. I do acknowledge that if a drastically different test set were used this model may not perform well. \n",
    "\n",
    "\n",
    "* Base Language Model:\n",
    "\n",
    "    NGram LM’s, where the probability of seeing a word depends on the history of n-1 previous words were used as the basis for my LM. NGrams of order from 1 to 4 were used, higher orders were discarded for fear of overfitting.\n",
    "\n",
    "\n",
    "* Dealing with Combinations of Unseen Words:\n",
    "\n",
    "    Transferring probabilities from’ seen’ word combinations to all combinations was achieved through nested interpolation. Probabilities of unseen word combinations are expressed as the weight average of the probability of the NGram model and lower order NGram models (backing-off down to the simplest unigram model).\n",
    "\n",
    "\n",
    "* Parameter Selection:\n",
    "\n",
    "    In order to achieve the lowest perplexity scores optimal weighting parameters needed to be chosen for each interpolation stage. For instance, the bigram ‘New York’ may appear often but the unigram ‘York’ is highly unlikely, in this case some probability should be taken away from the unigram model, and this is mathematically achieved by the interpolation parameters. I used the twiddle algorithm to find optimal interpolation parameters for the ohhla corpus and checked that the global minimum was found.\n",
    "\n",
    "\n",
    "* Improvements:\n",
    "\n",
    "    If time and programming skills allowed I would improve my LM based on Kneser Nay smoothing , which deals better with data sparsity and would be adequate for the ohhla corpus.\n",
    "\n",
    "\n",
    "* Check and Result:\n",
    "\n",
    "    In my language model probabilities sum to 1 and the perplexity reaches just under 142.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Assessment 3</font>: Assess Description (30 pts) \n",
    "\n",
    "We will mark the description along the following dimensions: \n",
    "\n",
    "* Clarity (10pts: very clear, 0pts: we can't figure out what you did)\n",
    "* Creativity (10pts: we could not have come up with this, 0pts: Use the unigram model from the lecture notes)\n",
    "* Substance (10pts: implemented complex state-of-the-art LM, 0pts: Use the unigram model from the lecture notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above solution is marked with **\n",
    "<!-- ASSESSMENT 1: START_POINTS -->\n",
    "0\n",
    "<!-- ASSESSMENT 1: END_POINTS --> points**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
